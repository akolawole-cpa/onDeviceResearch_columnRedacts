{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "566aaab3-ec7f-4b46-b960-716fb14053ee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install pyyaml>=6.0 -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b7566b84-4277-4e34-8a4a-c7c8ea000116",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.join(os.path.dirname(os.getcwd()), 'src'))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Import yaml with error handling\n",
    "try:\n",
    "    import yaml\n",
    "except ImportError:\n",
    "    raise ImportError(\n",
    "        \"PyYAML is not installed. Please run the previous cell to install it, \"\n",
    "        \"or run: %pip install pyyaml>=6.0\"\n",
    "    )\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Import our modular functions\n",
    "from eda.feature_engineering import (\n",
    "    create_time_features,\n",
    "    create_task_speed_features,\n",
    "    create_respondent_behavioral_features,\n",
    "    add_wonky_features,\n",
    "    create_fraud_risk_score,\n",
    "    create_wonky_risk_score\n",
    ")\n",
    "from eda.statistical_tests import (\n",
    "    compare_groups_statistically,\n",
    "    compare_groups_with_both_tests,\n",
    "    analyze_thresholds\n",
    ")\n",
    "from eda.visualizations import (\n",
    "    create_histogram,\n",
    "    create_box_plot,\n",
    "    create_scatter_plot,\n",
    "    create_bar_plot\n",
    ")\n",
    "\n",
    "# Load configuration files\n",
    "with open('../configs/feature_engineering.yaml', 'r') as f:\n",
    "    feature_config = yaml.safe_load(f)\n",
    "\n",
    "with open('../configs/statistical_tests.yaml', 'r') as f:\n",
    "    stats_config = yaml.safe_load(f)\n",
    "\n",
    "with open('../configs/data_paths.yaml', 'r') as f:\n",
    "    paths_config = yaml.safe_load(f)\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "print(\"âœ“ Imports and configs loaded successfully\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f1c38d56-93e9-4cb5-9bc2-ef786af50c36",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### File Definitions\n",
    "\n",
    "- **user_info_df**: DataFrame of respondent x task level data for all users (not just wonky studies)\n",
    "- **wonky_studies_df**: DataFrame of respondents involved in studies with unexpected outcomes (negative impacts when positive expected)\n",
    "\n",
    "A study is \"wonky\" if the outcome is unexpected (e.g., advertisement showed negative impacts of media, which is counter-intuitive).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "16f52c87-8b48-473a-9e72-fd6ffc9eff72",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7b39bb0f-203b-49c3-a86d-9d1ef0d84005",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "notebook_path = os.getcwd() \n",
    "repo_root = os.path.abspath(os.path.join(notebook_path, \"..\"))\n",
    "misc_dir = os.path.join(repo_root, \"misc\")\n",
    "os.makedirs(misc_dir, exist_ok=True)\n",
    "\n",
    "output_path = os.path.join(misc_dir,\n",
    "                           os.path.basename(paths_config['output_files']['user_info_df']))\n",
    "wonky_path = os.path.join(misc_dir,\n",
    "                          os.path.basename(paths_config['output_files']['wonky_user_counts']))\n",
    "\n",
    "\n",
    "user_info_df = pd.read_parquet(output_path)\n",
    "wonky_studies_df = pd.read_parquet(wonky_path)\n",
    "\n",
    "print(\"Files loaded successfully:\")\n",
    "print(f\"  - {output_path}\")\n",
    "print(f\"  - {wonky_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cc086073-cde3-4547-8c26-d7dffaa84ab1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cb5cb33e-6d9d-44e6-a1ca-f3e0078d7899",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create time features using modular function\n",
    "user_info_df = create_time_features(user_info_df, date_col=\"date_completed\")\n",
    "\n",
    "print(f\"Night tasks: {user_info_df['is_night'].mean()*100:.1f}%\")\n",
    "print(f\"Weekend tasks: {user_info_df['is_weekend'].mean()*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a6d4ca7c-c549-4c81-817a-d048aa8ebd70",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create task speed features using modular function\n",
    "user_info_df = create_task_speed_features(\n",
    "    user_info_df,\n",
    "    task_time_col=\"task_time_taken_s\",\n",
    "    suspicious_threshold=feature_config['time_thresholds']['suspicious_fast_seconds'],\n",
    "    very_fast_threshold=feature_config['time_thresholds']['very_fast_seconds'],\n",
    "    very_slow_threshold=feature_config['time_thresholds']['very_slow_minutes'] * 60\n",
    ")\n",
    "\n",
    "print(f\"Suspiciously fast (<{feature_config['time_thresholds']['suspicious_fast_seconds']}s): {user_info_df['is_suspiciously_fast'].sum():,} ({user_info_df['is_suspiciously_fast'].mean()*100:.2f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0e81c78c-3e3e-463e-9615-2e5f83d5b8e0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create respondent-level behavioral features\n",
    "respondent_features = create_respondent_behavioral_features(\n",
    "    user_info_df,\n",
    "    respondent_id_col=\"respondentPk\",\n",
    "    date_col=\"date_completed\",\n",
    "    config={\n",
    "        'high_volume_percentile': feature_config['volume_thresholds']['high_volume_percentile'],\n",
    "        'extreme_volume_percentile': feature_config['volume_thresholds']['extreme_volume_percentile'],\n",
    "        'velocity_bins': feature_config['velocity_bins'],\n",
    "        'velocity_labels': feature_config['velocity_labels']\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"Aggregated to {respondent_features.shape[0]:,} respondents\")\n",
    "print(f\"Avg tasks per respondent: {respondent_features['total_tasks'].mean():.2f}\")\n",
    "print(f\"Avg suspicious fast rate: {respondent_features['suspicious_fast_rate'].mean()*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5cb0bec3-ec25-4319-b561-151883ca5ee0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Add wonky features using modular function\n",
    "respondent_features = add_wonky_features(\n",
    "    respondent_features,\n",
    "    wonky_studies_df,\n",
    "    respondent_id_col=\"respondentPk\"\n",
    ")\n",
    "\n",
    "print(f\"Wonky features added\")\n",
    "print(f\"Respondents with wonky tasks: {(respondent_features['wonky_task_ratio'] > 0).sum():,}\")\n",
    "print(f\"High wonky concentration (>50%): {respondent_features['is_high_wonky'].sum():,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "435a6a6b-7164-41a0-9085-c9d74afcb688",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create fraud risk score using modular function\n",
    "respondent_features = create_fraud_risk_score(\n",
    "    respondent_features,\n",
    "    config={\n",
    "        'fraud_score_weights': feature_config['fraud_score_weights'],\n",
    "        'fraud_score_thresholds': feature_config['fraud_score_thresholds'],\n",
    "        'fraud_score_bins': feature_config['fraud_score_bins'],\n",
    "        'fraud_score_labels': feature_config['fraud_score_labels'],\n",
    "        'suspected_fraud_threshold': feature_config['suspected_fraud_threshold']\n",
    "    }\n",
    ")\n",
    "\n",
    "# Create wonky risk score\n",
    "respondent_features = create_wonky_risk_score(\n",
    "    respondent_features,\n",
    "    config={\n",
    "        'wonky_score_weights': feature_config['wonky_score_weights'],\n",
    "        'wonky_score_thresholds': feature_config['wonky_score_thresholds'],\n",
    "        'wonky_score_bins': feature_config['wonky_score_bins'],\n",
    "        'wonky_score_labels': feature_config['wonky_score_labels']\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"Fraud risk distribution:\")\n",
    "print(respondent_features['fraud_risk_tier'].value_counts().sort_index())\n",
    "print(f\"Suspected fraud rate: {respondent_features['suspected_fraud'].mean()*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4deb5513-3592-44aa-8daf-2efb2d88965b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Hypothesis Testing\n",
    "\n",
    "Running Mann-Whitney U test and Welch's t-test for validation.\n",
    "\n",
    "Check if Mann-Whitney U and Welch's t-test agree on significance.\n",
    "When both tests agree, we have higher confidence in the results.\n",
    "When they disagree, it signals need for further investigation.\n",
    "\n",
    "Compare wonky vs non-wonky users using statistical tests.\n",
    "- Mann-Whitney U test (non-parametric, primary test)\n",
    "- Welch's t-test (parametric validator/sense check)\n",
    "Uses `compare_groups_with_both_tests()` to run both tests simultaneously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aab5bd3c-cefe-4d99-94db-16cae34cd01c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create binary flag for wonky users\n",
    "respondent_features['has_wonky_tasks'] = (respondent_features['wonky_task_ratio'] > 0).astype(int)\n",
    "\n",
    "print(f\"Wonky users: {respondent_features['has_wonky_tasks'].sum():,} ({respondent_features['has_wonky_tasks'].mean()*100:.2f}%)\")\n",
    "print(f\"Non-wonky users: {(respondent_features['has_wonky_tasks'] == 0).sum():,} ({(respondent_features['has_wonky_tasks'] == 0).mean()*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d208e815-db6e-4709-8182-7b42ad5af3dc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Perform statistical tests using modular function\n",
    "statistical_results = compare_groups_with_both_tests(\n",
    "    respondent_features,\n",
    "    group_col=stats_config['group_comparison']['group_col'],\n",
    "    metrics=stats_config['test_metrics'],\n",
    "    group1_value=stats_config['group_comparison']['group1_value'],\n",
    "    group2_value=stats_config['group_comparison']['group2_value'],\n",
    "    significance_level=stats_config['significance_level']\n",
    ")\n",
    "\n",
    "print(\"Statistical Test Results (Mann-Whitney U + Welch's t-test):\")\n",
    "print(\"=\" * 100)\n",
    "display(statistical_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d1ad1333-68b3-42f9-9c7f-5434af9e2c3a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Analyze test agreement\n",
    "if 'tests_agree' in statistical_results.columns:\n",
    "    agreement_stats = statistical_results['tests_agree'].value_counts()\n",
    "    print(\"Test Agreement Analysis:\")\n",
    "    print(f\"Metrics where tests agree: {agreement_stats.get(True, 0)}\")\n",
    "    print(f\"Metrics where tests disagree: {agreement_stats.get(False, 0)}\")\n",
    "    \n",
    "    # Show metrics where tests disagree\n",
    "    disagree = statistical_results[statistical_results['tests_agree'] == False]\n",
    "    if len(disagree) > 0:\n",
    "        print(\"\\nMetrics where tests disagree (need investigation):\")\n",
    "        display(disagree[['metric', 'mw_p_value', 'welch_p_value', 'mw_significant', 'welch_significant']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "efdf385d-5be8-4899-ab0f-f0fd82844641",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Analyze thresholds for key features\n",
    "print(\"Threshold Analysis: Task Volume\")\n",
    "print(\"=\" * 80)\n",
    "volume_thresholds = analyze_thresholds(\n",
    "    respondent_features,\n",
    "    feature='total_tasks',\n",
    "    bins=stats_config['threshold_analysis']['default_bins'],\n",
    "    target_col='has_wonky_tasks'\n",
    ")\n",
    "display(volume_thresholds)\n",
    "\n",
    "print(\"\\nThreshold Analysis: Suspicious Fast Rate\")\n",
    "print(\"=\" * 80)\n",
    "speed_thresholds = analyze_thresholds(\n",
    "    respondent_features,\n",
    "    feature='suspicious_fast_rate',\n",
    "    bins=stats_config['threshold_analysis']['default_bins'],\n",
    "    target_col='has_wonky_tasks'\n",
    ")\n",
    "display(speed_thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0b74a098-f760-43ae-9169-7bb54e2f3216",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Example visualizations using modular functions\n",
    "\n",
    "# Histogram of fraud risk score\n",
    "fig_fraud_risk = create_histogram(\n",
    "    respondent_features,\n",
    "    x='fraud_risk_score',\n",
    "    color='fraud_risk_tier',\n",
    "    nbins=11,\n",
    "    title='Fraud Risk Score Distribution',\n",
    "    labels={'fraud_risk_score': 'Fraud Risk Score (0-10)'}\n",
    ")\n",
    "fig_fraud_risk.show()\n",
    "\n",
    "# Box plot comparing wonky vs non-wonky users\n",
    "fig_speed = create_box_plot(\n",
    "    respondent_features,\n",
    "    x='has_wonky_tasks',\n",
    "    y='avg_task_time',\n",
    "    color='has_wonky_tasks',\n",
    "    title='Average Task Time: Wonky vs Non-Wonky Users',\n",
    "    labels={'has_wonky_tasks': 'Has Wonky Tasks (1=Yes, 0=No)', 'avg_task_time': 'Average Task Time (seconds)'},\n",
    "    category_orders={'has_wonky_tasks': [0, 1]},\n",
    "    boxmean='sd'\n",
    ")\n",
    "fig_speed.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fff57faa-c32f-4ce9-a388-d54e04f07247",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Summary\n",
    "\n",
    "**Key Findings:**\n",
    "- Statistical tests help identify significant differences between wonky and non-wonky users\n",
    "- Feature engineering creates actionable behavioral indicators\n",
    "- Fraud risk scores combine multiple signals into interpretable metrics\n",
    "- Both Mann-Whitney U and Welch's t-test provide validation of findings\n",
    "\n",
    "**Next Steps:**\n",
    "- Use significant features from EDA for model training\n",
    "- Apply fraud risk thresholds to filter suspicious users\n",
    "- Build models using features identified as significant\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ec763b35-0e7f-4c22-99b0-30642a498194",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "resoondent_eda_refactored",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
