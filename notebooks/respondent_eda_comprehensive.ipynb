{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "68811a8d-1b53-4b40-a738-7f32c0ffd8bd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Comprehensive Respondent-Level EDA for Wonky Study Detection\n",
    "\n",
    "This notebook contains expanded EDA analysis on `respondent_features` dataframe to identify features that help distinguish users involved in wonky studies.\n",
    "\n",
    "**Key Sections:**\n",
    "- Comprehensive statistical testing on behavioral features\n",
    "- Feature ranking and importance analysis\n",
    "- Correlation and multicollinearity detection\n",
    "- Interaction feature creation and testing\n",
    "- Threshold analysis for optimal cutpoints\n",
    "- Final feature list organized by tiers\n",
    "- Modeling recommendations\n",
    "\n",
    "---\n",
    "\n",
    "Exec Summary\n",
    "\n",
    "-\n",
    "-\n",
    "-\n",
    "-\n",
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "566aaab3-ec7f-4b46-b960-716fb14053ee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install pyyaml>=6.0 -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b7566b84-4277-4e34-8a4a-c7c8ea000116",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.join(os.path.dirname(os.getcwd()), 'src'))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "try:\n",
    "    import yaml\n",
    "except ImportError:\n",
    "    raise ImportError(\n",
    "        \"PyYAML is not installed. Please run the previous cell to install it, \"\n",
    "        \"or run: %pip install pyyaml>=6.0\"\n",
    "    )\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from eda.feature_engineering import (\n",
    "    create_time_features,\n",
    "    create_task_speed_features,\n",
    "    create_respondent_behavioral_features,\n",
    "    add_wonky_features,\n",
    "    create_fraud_risk_score,\n",
    "    create_wonky_risk_score\n",
    ")\n",
    "from eda.statistical_tests import (\n",
    "    compare_groups_statistically,\n",
    "    compare_groups_with_both_tests,\n",
    "    analyze_thresholds,\n",
    "    perform_chi_square_tests,\n",
    "    compare_demographic_groups\n",
    ")\n",
    "from eda.visualizations import (\n",
    "    create_histogram,\n",
    "    create_box_plot,\n",
    "    create_scatter_plot,\n",
    "    create_bar_plot,\n",
    "    create_temporal_breakdown_summary,\n",
    "    create_task_speed_breakdown_summary,\n",
    "    create_chi_squared_bar_chart,\n",
    "    create_dual_axis_statistical_chart,\n",
    "    create_feature_breakdown_table,\n",
    "    create_distribution_comparison,\n",
    "    calculate_temporal_feature_deltas,       \n",
    "    create_chi_squared_delta_dual_axis_chart,\n",
    ")\n",
    "\n",
    "# Load configs\n",
    "with open('../configs/feature_engineering.yaml', 'r') as f:\n",
    "    feature_config = yaml.safe_load(f)\n",
    "\n",
    "with open('../configs/statistical_tests.yaml', 'r') as f:\n",
    "    stats_config = yaml.safe_load(f)\n",
    "\n",
    "with open('../configs/data_paths.yaml', 'r') as f:\n",
    "    paths_config = yaml.safe_load(f)\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "print(\"\u2713 Imports and configs loaded successfully\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f1c38d56-93e9-4cb5-9bc2-ef786af50c36",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### File Definitions\n",
    "\n",
    "- **user_info_df**: DataFrame of respondent x task level data for all users (not just wonky studies)\n",
    "- **wonky_studies_df**: DataFrame of respondents involved in studies with unexpected outcomes (negative impacts when positive expected)\n",
    "\n",
    "A study is \"wonky\" if the outcome is unexpected (e.g., advertisement showed negative impacts of media, which is counter-intuitive).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "16f52c87-8b48-473a-9e72-fd6ffc9eff72",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7b39bb0f-203b-49c3-a86d-9d1ef0d84005",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load data directly from misc folder\n",
    "notebook_path = os.getcwd() \n",
    "repo_root = os.path.abspath(os.path.join(notebook_path, \"..\"))\n",
    "misc_dir = os.path.join(repo_root, \"misc\")\n",
    "\n",
    "# Direct paths to CSV files in misc folder\n",
    "user_info_df = pd.read_csv(os.path.join(misc_dir, \"user_info_df.csv\"))\n",
    "wonky_counts = pd.read_csv(os.path.join(misc_dir, \"wonky_user_counts.csv\"))\n",
    "wonky_respondent_df = pd.read_csv(os.path.join(misc_dir, \"wonky_respondent_df.csv\"))\n",
    "wonky_respondent_summary = pd.read_csv(os.path.join(misc_dir, \"wonky_respondent_summary.csv\"))\n",
    "\n",
    "# Parse date columns if they exist (with error handling)\n",
    "if 'date_completed' in user_info_df.columns:\n",
    "    user_info_df['date_completed'] = pd.to_datetime(user_info_df['date_completed'], errors='coerce')\n",
    "    print(f\"\u2713 Parsed date_completed column: {user_info_df['date_completed'].dtype}\")\n",
    "    if user_info_df['date_completed'].isna().all():\n",
    "        print(\"\u26a0 Warning: All date_completed values are NaT. Check date format.\")\n",
    "else:\n",
    "    print(\"\u26a0 Warning: 'date_completed' column not found in user_info_df\")\n",
    "    print(f\"Available columns: {list(user_info_df.columns)[:10]}...\")\n",
    "\n",
    "if 'first_task_date' in wonky_respondent_summary.columns:\n",
    "    wonky_respondent_summary['first_task_date'] = pd.to_datetime(wonky_respondent_summary['first_task_date'], errors='coerce')\n",
    "if 'last_task_date' in wonky_respondent_summary.columns:\n",
    "    wonky_respondent_summary['last_task_date'] = pd.to_datetime(wonky_respondent_summary['last_task_date'], errors='coerce')\n",
    "\n",
    "print(f\"\\n\u2713 Loaded data from {misc_dir}\")\n",
    "print(f\"  - user_info_df: {len(user_info_df):,} rows, {len(user_info_df.columns)} columns\")\n",
    "print(f\"  - wonky_counts: {len(wonky_counts):,} rows\")\n",
    "print(f\"  - wonky_respondent_df: {len(wonky_respondent_df):,} rows\")\n",
    "print(f\"  - wonky_respondent_summary: {len(wonky_respondent_summary):,} rows\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b82547e1-a9d4-4d6f-a38d-964d2d0b2b61",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "wonky_respondent_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b6c3b8aa-d07f-4c91-9497-bca8081dcc90",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(user_info_df.head())\n",
    "\n",
    "print(wonky_respondent_df.head())\n",
    "\n",
    "df = pd.DataFrame(user_info_df.isnull().sum(), columns=['null_count'])\n",
    "display(df.reset_index())\n",
    "\n",
    "print(\"\\nwonky_studies_df - Missing values:\")\n",
    "missing_wonky = wonky_respondent_df.isnull().sum()\n",
    "print(missing_wonky[missing_wonky > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d86925fc-03d4-4041-a181-4ca8e5576e5c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "wonky_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "05abc98f-56cb-4741-97a6-2a9acdd9adee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "key_numeric_cols = ['task_time_taken_s', 'task_points', 'risk', 'quality', 'task_completed']\n",
    "available_cols = [col for col in key_numeric_cols if col in user_info_df.columns]\n",
    "print(user_info_df[available_cols].describe())\n",
    "\n",
    "if 'wonky_study_flag' in user_info_df.columns:\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"COMPARISON BY wonky_study_flag (Task Level)\")\n",
    "    print(\"=\" * 80)\n",
    "    comparison_cols = ['task_time_taken_s', 'task_points', 'risk', 'quality']\n",
    "    comparison_cols = [col for col in comparison_cols if col in user_info_df.columns]\n",
    "    \n",
    "    if len(comparison_cols) > 0:\n",
    "        wonky_study_tasks = user_info_df[user_info_df['wonky_study_flag'] == 1]\n",
    "        non_wonky_study_tasks = user_info_df[user_info_df['wonky_study_flag'] == 0]\n",
    "        \n",
    "        print(\"\\nWonky Study Tasks (wonky_study_flag=1):\")\n",
    "        print(wonky_study_tasks[comparison_cols].describe())\n",
    "        \n",
    "        print(\"\\nNon-Wonky Study Tasks (wonky_study_flag=0):\")\n",
    "        print(non_wonky_study_tasks[comparison_cols].describe())\n",
    "        \n",
    "        if 'wonky_studies_count' in user_info_df.columns:\n",
    "            wonky_user_tasks = user_info_df[user_info_df['wonky_studies_count'] > 0]\n",
    "            print(\"\\nTasks from Users with Wonky Studies (wonky_studies_count > 0):\")\n",
    "            print(wonky_user_tasks[comparison_cols].describe())\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STATISTICAL SUMMARY: wonky_studies_df\")\n",
    "print(\"=\" * 80)\n",
    "print(wonky_counts.describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cc086073-cde3-4547-8c26-d7dffaa84ab1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cb5cb33e-6d9d-44e6-a1ca-f3e0078d7899",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create time features using modular function\n",
    "# Verify date column exists and is datetime type\n",
    "if 'date_completed' not in user_info_df.columns:\n",
    "    raise ValueError(\"Column 'date_completed' not found in user_info_df. Available columns: \" + str(list(user_info_df.columns)[:20]))\n",
    "\n",
    "if not pd.api.types.is_datetime64_any_dtype(user_info_df['date_completed']):\n",
    "    print(\"\u26a0 Warning: date_completed is not datetime type. Attempting to convert...\")\n",
    "    print(f\"Current dtype: {user_info_df['date_completed'].dtype}\")\n",
    "    print(f\"Sample values: {user_info_df['date_completed'].head(3).tolist()}\")\n",
    "    user_info_df['date_completed'] = pd.to_datetime(user_info_df['date_completed'], errors='coerce')\n",
    "    if user_info_df['date_completed'].isna().all():\n",
    "        raise ValueError(\"Failed to parse date_completed column. All values are NaT.\")\n",
    "    print(f\"\u2713 Converted to datetime: {user_info_df['date_completed'].dtype}\")\n",
    "\n",
    "user_info_df = create_time_features(user_info_df, date_col=\"date_completed\")\n",
    "\n",
    "print(f\"Night tasks: {user_info_df['is_night'].mean()*100:.1f}%\")\n",
    "print(f\"Weekend tasks: {user_info_df['is_weekend'].mean()*100:.1f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "535fca63-38e0-47ab-bfbe-6d82c74e7873",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Behavioural Stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "70cf541f-80dd-42e7-a1a3-4a21aa22518a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Temporal Feature Analysis & Breakdowns - STRONG HYPOTHESIS\n",
    "\n",
    "Analyzing temporal patterns to identify differences between wonky and non-wonky study tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ef64d4d5-3f60-40f8-bb45-2e33aebffe8f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "user_info_df['wonky_task_instances'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d8f9f8ae-daa1-4275-ab4f-d88c5a94b630",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "temporal_features = [\n",
    "    \"is_weekday\",\n",
    "    \"is_weekend\",\n",
    "    \"is_night\",\n",
    "    \"is_business_hour\",\n",
    "    \"is_business_hour_weekday\",\n",
    "    \"is_business_hour_weekend\",\n",
    "    \"is_monday\",\n",
    "    \"is_tuesday\",\n",
    "    \"is_wednesday\",\n",
    "    \"is_thursday\",\n",
    "    \"is_friday\",\n",
    "    \"is_saturday\",\n",
    "    \"is_sunday\",\n",
    "]\n",
    "\n",
    "print(\n",
    "    create_temporal_breakdown_summary(\n",
    "        user_info_df,\n",
    "        temporal_features=temporal_features,\n",
    "        group_col=\"wonky_task_instances\",\n",
    "        group_threshold=0,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7de3c8b2-fc0f-4beb-9f21-972bd13c314b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Task complete time - definately good gauge. Majority takes place during business hours, relatively evenly spread across the work week LARGEST detla where wonky is more prevalent is in business hours suggesting professional behaviours\n",
    "**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d98f42a0-2879-495a-9ecb-5675f1628929",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##### Chi-Squared Tests for Temporal Features\n",
    "\n",
    "Testing independence between temporal features and wonky study participation.\n",
    "Chi-squared test determines if temporal patterns differ significantly between wonky and non-wonky groups.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ddf136e0-8a81-4f0f-96ca-a4e3f08ec403",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "chi_square_results = perform_chi_square_tests(\n",
    "    user_info_df,\n",
    "    feature_set=temporal_features,\n",
    "    group_var='wonky_task_instances',\n",
    "    significance_level=0.01\n",
    ")\n",
    "\n",
    "chi_square_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f4871aad-769d-462c-a4bf-4295673e5630",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Strong significance for all subsets but wednesday and friday although this doesn't taken into consideration directionality -> simple separators are business hours**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ac025e77-9b06-4028-878a-79c78c0a5605",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "STRONG SIGNIFICANT READ AT 99% LEVEL LARGEST MAGNITUDE FOUND AT NIGHT. LOWEST MAGNITUDE DURING WEEKEND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5251fa82-b4cb-4ed6-910c-4a9b9bca4ee3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Summary\n",
    "if len(chi_square_results) > 0:\n",
    "    significant_features = chi_square_results[chi_square_results['significant'] == True]\n",
    "    print(f\"\\nSignificant temporal features (p < 0.01): {len(significant_features)}\")\n",
    "    if len(significant_features) > 0:\n",
    "        print(\"Features:\", ', '.join(significant_features.index.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d779cd52-dfc4-4e68-87f9-bb87a5636e8d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Visualize chi-squared statistics\n",
    "if len(chi_square_results) > 0:\n",
    "    fig_chi2 = create_chi_squared_bar_chart(\n",
    "        chi_square_results,\n",
    "        chi2_col='chi2',\n",
    "        p_value_col='chi_p_value',\n",
    "        significance_level=0.01,\n",
    "        title=\"Chi-Squared Statistic by Temporal Feature\"\n",
    "    )\n",
    "    fig_chi2.show()\n",
    "else:\n",
    "    print(\"No chi-squared test results available for visualization\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e0336f6c-a4d5-403f-a558-542119dd3b68",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "if len(chi_square_results) > 0:\n",
    "    delta_results = calculate_temporal_feature_deltas(\n",
    "      user_info_df,\n",
    "      temporal_features=temporal_features,\n",
    "      group_col='wonky_task_instances',  \n",
    "      group_threshold=0 \n",
    ")\n",
    "    \n",
    "    if len(delta_results) > 0:\n",
    "        fig_dual = create_chi_squared_delta_dual_axis_chart(\n",
    "            chi_square_results,\n",
    "            delta_results,\n",
    "            chi2_col='chi2',\n",
    "            p_value_col='chi_p_value',\n",
    "            delta_col='delta_pct',\n",
    "            significance_level=0.01,\n",
    "            title=\"Chi-Squared Statistic and Delta % by Temporal Feature\"\n",
    "        )\n",
    "        fig_dual.show()\n",
    "    else:\n",
    "        print(\"No delta results available for visualization\")\n",
    "else:\n",
    "    print(\"No chi-squared test results available for visualization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7d89c1bc-3445-45af-98a3-d32efbfd4638",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Bar is the level of siginficance between the wonky and non wonky, the line are the delta's between wonky and non wonky in terms of when tasks are complete.\n",
    "\n",
    "positive delta means wonky participants are more prevalent and negative delta means they are less prevalent.\n",
    "\n",
    "Business hours, Night time, Saturdays look like the overall best separators between wonky and non wonky participants in terms of task complete time\n",
    "**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "437bdf73-4a93-4116-b26a-38493a0b2a96",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Task speed features - OKAY HYPOTHESIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1b14d3ff-1a10-46e7-9b3e-9b912e58b234",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "user_info_df['task_time_taken_s_capped'] = np.where(user_info_df['task_time_taken_s'] < user_info_df['task_time_taken_s'].quantile(0.9999), user_info_df['task_time_taken_s'], user_info_df['task_time_taken_s'].quantile(0.9999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7d9063f8-4d25-4c98-a1ed-52ff6ecc56cc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "user_info_df = create_task_speed_features(\n",
    "    user_info_df,\n",
    "    task_time_col=\"task_time_taken_s_capped\",\n",
    "    use_std_dev=True\n",
    ")\n",
    "\n",
    "mean_time = user_info_df[\"task_time_taken_s_capped\"].mean()\n",
    "std_time = user_info_df[\"task_time_taken_s_capped\"].std()\n",
    "print(f\"Task time statistics:\")\n",
    "print(f\"  Mean: {mean_time:.2f} seconds ({mean_time/60:.2f} minutes)\")\n",
    "print(f\"  Std Dev: {std_time:.2f} seconds ({std_time/60:.2f} minutes)\")\n",
    "print(f\"  Fast threshold (mean - 1\u03c3): {mean_time - std_time:.2f}s\")\n",
    "print(f\"  Suspiciously fast threshold (mean - 2\u03c3): {mean_time - 2*std_time:.2f}s\")\n",
    "print(f\"  Slow threshold (mean + 1\u03c3): {mean_time + std_time:.2f}s\")\n",
    "print(f\"  Suspiciously slow threshold (mean + 2\u03c3): {mean_time + 2*std_time:.2f}s\")\n",
    "print()\n",
    "\n",
    "# Display breakdown with wonky vs non-wonky comparison\n",
    "print(create_task_speed_breakdown_summary(\n",
    "    user_info_df,\n",
    "    group_col='wonky_task_instances',\n",
    "    group_threshold=0\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0c58953f-e755-4a93-85df-e34fa15c7eb4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Wonky participants are usually suspcisouly fast to normal non wonky participants tend to be normal to supcisouly slow in terms of delta **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0f3fd6ea-c147-4dd5-9c6f-e765bcf7c132",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "user_info_df = create_task_speed_features(\n",
    "    user_info_df,\n",
    "    task_time_col=\"task_time_taken_s\",\n",
    "    use_std_dev=True\n",
    ")\n",
    "\n",
    "fast_threshold = user_info_df[\"task_time_taken_s\"].quantile(0.16)\n",
    "suspiciously_fast_threshold = user_info_df[\"task_time_taken_s\"].quantile(0.025)\n",
    "slow_threshold = user_info_df[\"task_time_taken_s\"].quantile(0.84)\n",
    "suspiciously_slow_threshold = user_info_df[\"task_time_taken_s\"].quantile(0.975)\n",
    "\n",
    "# Also calculate trimmed mean/std for reference (trimming extreme outliers)\n",
    "trimmed_data = user_info_df[\"task_time_taken_s\"].clip(\n",
    "    lower=user_info_df[\"task_time_taken_s\"].quantile(0.01),\n",
    "    upper=user_info_df[\"task_time_taken_s\"].quantile(0.99)\n",
    ")\n",
    "mean_time = trimmed_data.mean()\n",
    "std_time = trimmed_data.std()\n",
    "\n",
    "print(f\"Task time statistics (using percentiles, robust to outliers):\")\n",
    "print(f\"  Mean (trimmed 1%-99%): {mean_time:.2f} seconds ({mean_time/60:.2f} minutes)\")\n",
    "print(f\"  Std Dev (trimmed 1%-99%): {std_time:.2f} seconds ({std_time/60:.2f} minutes)\")\n",
    "print(f\"  Fast threshold (16th percentile): {fast_threshold:.2f}s ({fast_threshold/60:.2f} min)\")\n",
    "print(f\"  Suspiciously fast threshold (2.5th percentile): {suspiciously_fast_threshold:.2f}s ({suspiciously_fast_threshold/60:.2f} min)\")\n",
    "print(f\"  Slow threshold (84th percentile): {slow_threshold:.2f}s ({slow_threshold/60:.2f} min)\")\n",
    "print(f\"  Suspiciously slow threshold (97.5th percentile): {suspiciously_slow_threshold:.2f}s ({suspiciously_slow_threshold/60:.2f} min)\")\n",
    "print()\n",
    "\n",
    "# Display breakdown with wonky vs non-wonky comparison\n",
    "group_col_to_use = 'wonky_task_instances' if 'wonky_task_instances' in user_info_df.columns else 'wonky_study_count'\n",
    "print(create_task_speed_breakdown_summary(\n",
    "    user_info_df,\n",
    "    group_col=group_col_to_use,\n",
    "    group_threshold=0\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b715724b-3912-45af-854b-c4a999cb048f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from eda.statistical_tests import compare_speed_categories_proportions\n",
    "\n",
    "# Statistical tests for speed categories: Chi-squared and Two-Proportion Z-Test\n",
    "speed_features = ['is_suspiciously_fast', 'is_fast', 'is_normal_speed', 'is_slow', 'is_suspiciously_slow']\n",
    "\n",
    "# Ensure we have the correct group column\n",
    "group_col_to_use = 'wonky_task_instances' if 'wonky_task_instances' in user_info_df.columns else 'wonky_study_count'\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"STATISTICAL TESTS: Speed Categories vs Wonky Status\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "\n",
    "# 1. Chi-squared test (overall association)\n",
    "print(\"1. CHI-SQUARED TEST (Overall Association)\")\n",
    "print(\"-\" * 80)\n",
    "print(\"Tests if speed category distribution is independent of wonky task status\")\n",
    "print()\n",
    "\n",
    "chi2_speed_results = perform_chi_square_tests(\n",
    "    user_info_df,\n",
    "    feature_set=speed_features,\n",
    "    group_var=group_col_to_use,\n",
    "    significance_level=0.01\n",
    ")\n",
    "\n",
    "if len(chi2_speed_results) > 0:\n",
    "    print(\"Results:\")\n",
    "    display(chi2_speed_results)\n",
    "    print()\n",
    "    \n",
    "    significant_features = chi2_speed_results[chi2_speed_results['significant']]\n",
    "    if len(significant_features) > 0:\n",
    "        print(f\"\u2713 Significant association found for {len(significant_features)} speed category(ies)\")\n",
    "        print(f\"  Features: {', '.join(significant_features.index.tolist())}\")\n",
    "    else:\n",
    "        print(\"\u2717 No significant association found (p > 0.05)\")\n",
    "else:\n",
    "    print(\"No results available (check if speed features exist in DataFrame)\")\n",
    "print()\n",
    "\n",
    "# 2. Two-proportion Z-test (individual category comparisons)\n",
    "print(\"2. TWO-PROPORTION Z-TEST (Individual Category Comparisons)\")\n",
    "print(\"-\" * 80)\n",
    "print(\"Tests if proportion differs significantly for each speed category\")\n",
    "print()\n",
    "\n",
    "ztest_speed_results = compare_speed_categories_proportions(\n",
    "    user_info_df,\n",
    "    speed_features=speed_features,\n",
    "    group_col=group_col_to_use,\n",
    "    group_threshold=0,\n",
    "    significance_level=0.01\n",
    ")\n",
    "\n",
    "if len(ztest_speed_results) > 0:\n",
    "    print(\"Results:\")\n",
    "    display(ztest_speed_results.reset_index(drop=True))\n",
    "    print()\n",
    "    \n",
    "    # Format results for easier interpretation\n",
    "    print(\"Summary:\")\n",
    "    for _, row in ztest_speed_results.iterrows():\n",
    "        feature_name = row['feature'].replace('is_', '').replace('_', ' ').title()\n",
    "        sig_marker = \"***\" if row['significant'] else \"\"\n",
    "        print(f\"  {feature_name}:\")\n",
    "        print(f\"    Wonky: {row['wonky_proportion']*100:.2f}% ({row['wonky_count']:,}/{row['wonky_total']:,})\")\n",
    "        print(f\"    Non-wonky: {row['non_wonky_proportion']*100:.2f}% ({row['non_wonky_count']:,}/{row['non_wonky_total']:,})\")\n",
    "        print(f\"    Difference: {row['proportion_diff']*100:+.2f}%\")\n",
    "        print(f\"    Z-statistic: {row['z_statistic']:.3f}, p-value: {row['p_value']:.4f} {sig_marker}\")\n",
    "        print()\n",
    "    \n",
    "    significant_categories = ztest_speed_results[ztest_speed_results['significant']]\n",
    "    if len(significant_categories) > 0:\n",
    "        print(f\"\u2713 Significant differences found for {len(significant_categories)} category(ies):\")\n",
    "        for _, row in significant_categories.iterrows():\n",
    "            feature_name = row['feature'].replace('is_', '').replace('_', ' ').title()\n",
    "            direction = \"higher\" if row['proportion_diff'] > 0 else \"lower\"\n",
    "            print(f\"  - {feature_name}: Wonky tasks have {abs(row['proportion_diff']*100):.2f}% {direction} proportion\")\n",
    "    else:\n",
    "        print(\"\u2717 No significant differences found (p > 0.05 for all categories)\")\n",
    "else:\n",
    "    print(\"No results available (check if speed features exist in DataFrame)\")\n",
    "print()\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"Interpretation:\")\n",
    "print(\"- Chi-squared test: Overall test of independence (all categories together)\")\n",
    "print(\"- Two-proportion Z-test: Individual tests for each category\")\n",
    "print(\"- Significant results (p < 0.01) indicate wonky and non-wonky groups differ\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9bde2f0c-36da-460e-9051-0227a63f117e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "TODO -> rethink Viz for this section all significant across z test and chi squared test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f995edea-c859-45c3-bfb8-31994d052ea0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Task and Point categroy - WEAK HYPOTHESIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d03c83fa-bcb0-4371-9260-2d67850e5f34",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "user_info_df['defined_task_category'] = user_info_df['taskCategory'].astype(str) + \"_points_\" + user_info_df['payoutPoints'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "96c1ae12-00d2-411a-9180-5c0767c2df03",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "user_info_df = user_info_df.merge(wonky_respondent_df[['balance_respondentPk', 'task_pk', 'wonky_study_count']], left_on=['balance_respondentPk', 'taskPk'], right_on=['balance_respondentPk', 'task_pk'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dd9792b0-8c8c-44bf-9de9-3cd582f658c2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Import the function\n",
    "from eda.statistical_tests import compare_task_category_wonky_rates\n",
    "\n",
    "# Create the summary table directly from user_info_df\n",
    "# Why: Analyzes wonky rates by task category to identify which categories have higher fraud rates\n",
    "category_wonky_summary = compare_task_category_wonky_rates(\n",
    "    df=user_info_df,\n",
    "    category_col=\"defined_task_category\",\n",
    "    respondent_id_col=\"respondentPk\",\n",
    "    wonky_col=\"wonky_study_count\"\n",
    ")\n",
    "\n",
    "# Display the results\n",
    "print(\"Wonky Rates by Task Category:\")\n",
    "print(\"=\" * 100)\n",
    "display(category_wonky_summary)\n",
    "\n",
    "# Format for better readability\n",
    "category_wonky_summary_formatted = category_wonky_summary.copy()\n",
    "category_wonky_summary_formatted['wonky_pct'] = category_wonky_summary_formatted['wonky_pct'].round(2)\n",
    "category_wonky_summary_formatted['non_wonky_pct'] = category_wonky_summary_formatted['non_wonky_pct'].round(2)\n",
    "category_wonky_summary_formatted['proportion_delta'] = category_wonky_summary_formatted['proportion_delta'].round(2)\n",
    "\n",
    "display(category_wonky_summary_formatted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "501ecc69-a343-4bff-8a88-571f63248474",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "category_wonky_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4488b129-013a-488a-9273-e336f7874622",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "####\u00a0Device & Platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bf8d444f-22db-4ed6-b5a8-a4e15af70a82",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "sorted(user_info_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cbb96a06-e2cc-4335-8147-fa7bf1ba24e1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "user_info_df['hardware_version2'] = user_info_df['hardware_version'].fillna('unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cdf66c39-937f-4ab7-8eed-3f46b12bf38e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "a = user_info_df[\n",
    "    [\"respondentPk\", \"hardware_version\", \"platform_name\", \"wonky_study_count\", \"wonky_task_instances\"]\n",
    "].groupby([\"hardware_version\", \"platform_name\"]).agg({'wonky_study_count': 'sum',\n",
    "                                                      'respondentPk': 'count'})\n",
    "\n",
    "a['wonky_rate'] = a['wonky_study_count'] / a['respondentPk']\n",
    "\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "146b2e05-524c-42c1-a28e-c5741ef6e6b4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Demographic stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bf111f0e-8d51-43c0-b299-ba0dcf74c773",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# user_info_df_shortened = user_info_df[['respondentPk', 'taskPk', 'device', 'employer_annual_revenue', 'fulcrum_employment_status', 'fulcrum_household_income', 'gambling_participation_mc', 'gender', 'home_owner', 'wonky_study_count', 'wonky_task_instances']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "201e2117-c66b-42d3-8dbe-8c56964f6f2d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "series = user_info_df['gambling_participation_mc']\n",
    "\n",
    "# One-hot encode each gambling mode\n",
    "gambling_dummies = (\n",
    "    series.explode()                    \n",
    "     .str.strip()                   \n",
    "     .pipe(pd.get_dummies)          \n",
    "     .groupby(level=0).sum()     \n",
    ")\n",
    "\n",
    "gambling_cols = gambling_dummies.columns\n",
    "\n",
    "user_info_df = user_info_df.join(gambling_dummies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f3b51391-7fd2-46bc-9154-ec635f5975d4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "gambling_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1b34861a-4223-4b1c-9883-6ac4d153bd9c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "income_map = {\n",
    "    \"A\": \"Less than \u00a315,000\",\n",
    "    \"B\": \"\u00a315,000 to \u00a319,999\",\n",
    "    \"C\": \"\u00a320,000 to \u00a324,999\",\n",
    "    \"D\": \"\u00a325,000 to \u00a329,999\",\n",
    "    \"E\": \"\u00a330,000 to \u00a334,999\",\n",
    "    \"F\": \"\u00a335,000 to \u00a339,999\",\n",
    "    \"G\": \"\u00a340,000 to \u00a344,999\",\n",
    "    \"H\": \"\u00a345,000 to \u00a349,999\",\n",
    "    \"I\": \"\u00a350,000 to \u00a359,999\",\n",
    "    \"J\": \"\u00a360,000 to \u00a374,999\",\n",
    "    \"K\": \"\u00a375,000 to \u00a384,999\",\n",
    "    \"L\": \"\u00a385,000 to \u00a399,999\",\n",
    "    \"M\": \"\u00a3100,000 to \u00a3124,999\",\n",
    "    \"N\": \"\u00a3125,000 to \u00a3149,999\",\n",
    "    \"O\": \"\u00a3150,000 to \u00a3174,999\",\n",
    "    \"P\": \"\u00a3175,000 to \u00a3199,999\",\n",
    "    \"Q\": \"\u00a3200,000 and above\",\n",
    "    \"R\": \"Prefer not to answer\",\n",
    "}\n",
    "\n",
    "user_info_df[\"fulcrum_household_income_mapped\"] = (\n",
    "    user_info_df[\"fulcrum_household_income\"].map(income_map)\n",
    ")\n",
    "\n",
    "user_info_df[\"fulcrum_household_income_mapped\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3b38deef-2ffd-46ef-892f-56b1a56201f7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "demographic_cols = [\n",
    "    \"platform_name\",\n",
    "    \"hardware_version\",\n",
    "    \"survey_locale\",\n",
    "    \"gender\",\n",
    "    \"fulcrum_household_income_mapped\",\n",
    "    \"device\",\n",
    "    \"home_owner\",\n",
    "] + list(gambling_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "832b6e01-6d1d-4989-a04f-953452c7ff0d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create respondent-level behavioral features\n",
    "import importlib\n",
    "\n",
    "if \"eda.feature_engineering\" in sys.modules:\n",
    "    importlib.reload(sys.modules[\"eda.feature_engineering\"])\n",
    "    from eda.feature_engineering import create_respondent_behavioral_features\n",
    "\n",
    "respondent_features = create_respondent_behavioral_features(\n",
    "    user_info_df,\n",
    "    respondent_id_col=\"respondentPk\",\n",
    "    date_col=\"date_completed\",\n",
    "    config={\n",
    "        \"high_volume_percentile\": feature_config[\"volume_thresholds\"][\n",
    "            \"high_volume_percentile\"\n",
    "        ],\n",
    "        \"extreme_volume_percentile\": feature_config[\"volume_thresholds\"][\n",
    "            \"extreme_volume_percentile\"\n",
    "        ],\n",
    "        \"velocity_bins\": feature_config[\"velocity_bins\"],\n",
    "        \"velocity_labels\": feature_config[\"velocity_labels\"],\n",
    "    },\n",
    "    demographic_cols= demographic_cols,\n",
    ")\n",
    "\n",
    "print(f\"Aggregated to {respondent_features.shape[0]:,} respondents\")\n",
    "print(f\"Avg tasks per respondent: {respondent_features['total_tasks'].mean():.2f}\")\n",
    "print(\n",
    "    f\"Avg suspicious fast rate: {respondent_features['suspicious_fast_rate'].mean()*100:.2f}%\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "87b5913a-42db-4138-9c2e-81af4d2dd386",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "respondent_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f2d8521f-d7cb-4749-a19b-80971dda65de",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Add wonky features using modular function\n",
    "respondent_features = add_wonky_features(\n",
    "    respondent_features, wonky_counts, respondent_id_col=\"respondentPk\"\n",
    ")\n",
    "\n",
    "print(f\"Wonky features added\")\n",
    "print(\n",
    "    f\"Respondents with wonky tasks: {(respondent_features['wonky_task_ratio'] > 0).sum():,}\"\n",
    ")\n",
    "print(\n",
    "    f\"High wonky concentration (>50%): {respondent_features['is_high_wonky'].sum():,}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "respondent_features.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "respondent_features.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create binary target variables for wonky study detection\n",
    "# has_wonky_tasks: based on wonky_task_instances (any wonky task involvement)\n",
    "# has_wonky_studies: based on wonky_study_count (task-specific wonky studies)\n",
    "\n",
    "# Fill NaN values in wonky columns with 0 for binary classification\n",
    "if 'wonky_task_instances' in respondent_features.columns:\n",
    "    respondent_features['wonky_task_instances'] = respondent_features['wonky_task_instances'].fillna(0)\n",
    "if 'wonky_study_count' in respondent_features.columns:\n",
    "    respondent_features['wonky_study_count'] = respondent_features['wonky_study_count'].fillna(0)\n",
    "if 'wonky_task_ratio' in respondent_features.columns:\n",
    "    respondent_features['wonky_task_ratio'] = respondent_features['wonky_task_ratio'].fillna(0)\n",
    "\n",
    "# Create binary flags\n",
    "respondent_features['has_wonky_tasks'] = (respondent_features['wonky_task_instances'] > 0).astype(int)\n",
    "respondent_features['has_wonky_studies'] = (respondent_features['wonky_study_count'] > 0).astype(int)\n",
    "\n",
    "# Create severity tiers based on wonky_task_ratio\n",
    "respondent_features['wonky_severity'] = pd.cut(\n",
    "    respondent_features['wonky_task_ratio'],\n",
    "    bins=[-0.01, 0.01, 0.2, 0.5, 1.0],\n",
    "    labels=['None', 'Low', 'Medium', 'High'],\n",
    "    include_lowest=True\n",
    ")\n",
    "respondent_features['wonky_severity'] = respondent_features['wonky_severity'].fillna('None')\n",
    "\n",
    "# Check class balance\n",
    "print(\"=\" * 80)\n",
    "print(\"TARGET VARIABLE DISTRIBUTION\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nTotal respondents: {len(respondent_features):,}\")\n",
    "\n",
    "print(f\"\\nhas_wonky_tasks distribution:\")\n",
    "wonky_tasks_dist = respondent_features['has_wonky_tasks'].value_counts().sort_index()\n",
    "for val, count in wonky_tasks_dist.items():\n",
    "    pct = (count / len(respondent_features)) * 100\n",
    "    label = \"Has wonky tasks\" if val == 1 else \"No wonky tasks\"\n",
    "    print(f\"  {label}: {count:,} ({pct:.2f}%)\")\n",
    "\n",
    "print(f\"\\nhas_wonky_studies distribution:\")\n",
    "wonky_studies_dist = respondent_features['has_wonky_studies'].value_counts().sort_index()\n",
    "for val, count in wonky_studies_dist.items():\n",
    "    pct = (count / len(respondent_features)) * 100\n",
    "    label = \"Has wonky studies\" if val == 1 else \"No wonky studies\"\n",
    "    print(f\"  {label}: {count:,} ({pct:.2f}%)\")\n",
    "\n",
    "print(f\"\\nWonky severity distribution:\")\n",
    "severity_dist = respondent_features['wonky_severity'].value_counts()\n",
    "for severity, count in severity_dist.items():\n",
    "    pct = (count / len(respondent_features)) * 100\n",
    "    print(f\"  {severity}: {count:,} ({pct:.2f}%)\")\n",
    "\n",
    "# Check data quality\n",
    "print(f\"\\n{'=' * 80}\")\n",
    "print(\"DATA QUALITY CHECK\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nMissing values per column:\")\n",
    "missing = respondent_features.isnull().sum()\n",
    "missing_pct = (missing / len(respondent_features)) * 100\n",
    "missing_df = pd.DataFrame({\n",
    "    'missing_count': missing,\n",
    "    'missing_pct': missing_pct\n",
    "})\n",
    "missing_df = missing_df[missing_df['missing_count'] > 0].sort_values('missing_count', ascending=False)\n",
    "if len(missing_df) > 0:\n",
    "    display(missing_df)\n",
    "else:\n",
    "    print(\"  No missing values found!\")\n",
    "\n",
    "print(f\"\\nData shape: {respondent_features.shape}\")\n",
    "print(f\"Total columns: {len(respondent_features.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "respondent_features.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "respondent_features.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "respondent_features.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "respondent_features.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "respondent_features.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "respondent_features.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "respondent_features.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "respondent_features.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "respondent_features.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "respondent_features.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "respondent_features.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "respondent_features.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "respondent_features.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "respondent_features.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "respondent_features.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "respondent_features.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "respondent_features.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "respondent_features.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "respondent_features.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "respondent_features.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "respondent_features.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "respondent_features.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "respondent_features.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "46f354c2-62b7-496c-bc17-c2dcd6003ec3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "respondent_features.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ebdaa8a2-0121-4272-93d3-d717ed89a0b8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "user_info_df[user_info_df['respondentPk'] == 'e043970a-f4a2-4a33-afdd-eccb63ec8271']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eed8d603-94cf-4aaf-9189-c994aed31e07",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Inconsitency flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3f43d528-6f2a-4804-bcbd-5a8368fc32c6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b401d6d6-4517-47fa-8862-25eb52a45ce0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Compare wonky task rates across demographic groups\n",
    "\n",
    "demographic_cols = ['platform_name', 'hardware_version', 'survey_locale']\n",
    "\n",
    "demographic_results = {}\n",
    "\n",
    "for demo_col in demographic_cols:\n",
    "    if demo_col in respondent_features.columns:\n",
    "        print(demo_col)\n",
    "        print(f\"\\n{'=' * 80}\")\n",
    "        print(f\"Demographic Comparison: {demo_col}\")\n",
    "        print('=' * 80)\n",
    "        \n",
    "        # Perform comparisons\n",
    "        demo_comparisons = compare_demographic_groups(\n",
    "            respondent_features,\n",
    "            demographic_col=demo_col,\n",
    "            target_col='wonky_task_ratio',\n",
    "            min_group_size=10,\n",
    "            significance_level=0.05\n",
    "        )\n",
    "        \n",
    "        if len(demo_comparisons) > 0:\n",
    "            demographic_results[demo_col] = demo_comparisons\n",
    "            \n",
    "            # Show summary statistics by group\n",
    "            group_summary = respondent_features.groupby(demo_col).agg({\n",
    "                'wonky_task_ratio': ['mean', 'median', 'count'],\n",
    "                'has_wonky_tasks': 'sum'\n",
    "            }).round(4)\n",
    "            group_summary.columns = ['mean_wonky_ratio', 'median_wonky_ratio', 'total_count', 'wonky_count']\n",
    "            group_summary['wonky_rate'] = (group_summary['wonky_count'] / group_summary['total_count'] * 100).round(2)\n",
    "            group_summary = group_summary.sort_values('mean_wonky_ratio', ascending=False)\n",
    "            \n",
    "            print(f\"\\nSummary by {demo_col}:\")\n",
    "            display(group_summary)\n",
    "            \n",
    "            # Show significant comparisons\n",
    "            significant_comps = demo_comparisons[demo_comparisons['mw_significant'] == True]\n",
    "            if len(significant_comps) > 0:\n",
    "                print(f\"\\nSignificant differences (p < 0.05): {len(significant_comps)}\")\n",
    "                display(significant_comps[['group1', 'group2', 'mean_difference', 'mw_p_value', 'welch_p_value', 'tests_agree']])\n",
    "            else:\n",
    "                print(\"\\nNo significant differences found between groups\")\n",
    "        else:\n",
    "            print(f\"Insufficient data for {demo_col} comparisons\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c7d8df9d-725b-4471-a1cd-8fc9cd56b9ef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# # Visualize demographic comparisons\n",
    "# # Why: Bar charts make it easy to see which demographic groups have higher wonky task rates\n",
    "# # Helps identify patterns that may inform modeling or business decisions\n",
    "\n",
    "# for demo_col in demographic_cols:\n",
    "#     if demo_col in respondent_features.columns and demo_col in demographic_results:\n",
    "#         # Create summary by group\n",
    "#         demo_summary = respondent_features.groupby(demo_col).agg({\n",
    "#             'wonky_task_ratio': 'mean',\n",
    "#             'has_wonky_tasks': ['sum', 'count']\n",
    "#         }).reset_index()\n",
    "#         demo_summary.columns = [demo_col, 'mean_wonky_ratio', 'wonky_count', 'total_count']\n",
    "#         demo_summary['wonky_rate'] = (demo_summary['wonky_count'] / demo_summary['total_count'] * 100)\n",
    "#         demo_summary = demo_summary.sort_values('mean_wonky_ratio', ascending=False)\n",
    "        \n",
    "#         # Bar chart of wonky rates by xdemographic group\n",
    "#         fig_demo = create_bar_plot(\n",
    "#             demo_summary,\n",
    "#             x=demo_col,\n",
    "#             y='wonky_rate',\n",
    "#             title=f'Wonky Task Rate by {demo_col.replace(\"_\", \" \").title()}',\n",
    "#             labels={demo_col: demo_col.replace(\"_\", \" \").title(), 'wonky_rate': 'Wonky Task Rate (%)'},\n",
    "#             color='wonky_rate',\n",
    "#             color_continuous_scale='Reds',\n",
    "#             text='wonky_rate',\n",
    "#             texttemplate='%{text:.1f}%',\n",
    "#             textposition='outside',\n",
    "#             tickangle=45\n",
    "#         )\n",
    "#         fig_demo.show()\n",
    "        \n",
    "#         # Box plot comparing wonky task ratios across groups\n",
    "#         fig_demo_box = create_box_plot(\n",
    "#             respondent_features,\n",
    "#             x=demo_col,\n",
    "#             y='wonky_task_ratio',\n",
    "#             title=f'Wonky Task Ratio Distribution by {demo_col.replace(\"_\", \" \").title()}',\n",
    "#             labels={demo_col: demo_col.replace(\"_\", \" \").title(), 'wonky_task_ratio': 'Wonky Task Ratio'},\n",
    "#             tickangle=45\n",
    "#         )\n",
    "#         fig_demo_box.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2207d4e0-25d4-426a-b7a4-0be2ed17a898",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Feature Selection Guidance\n",
    "\n",
    "Based on EDA results, identify which features show strongest discrimination and should be prioritized for modeling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9eb6b4d8-e308-45b1-9a1a-11adf1c44ce4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "24ab1cf7-8bdf-4909-a232-98c5007e163f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b00ae635-6bcc-453b-aef7-a91c9c3368b0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e5b62d8d-41b6-4739-a067-11428067dadc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Modeling Recommendations\n",
    "\n",
    "Based on EDA findings, recommendations for feature selection and modeling approach.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f4c5fd06-d754-4dfd-834a-d7ead7a30e11",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# # Generate modeling recommendations\n",
    "# # Why: Synthesizes EDA findings into actionable recommendations for model development\n",
    "# # Note: Requires statistical_results to be created first (run the statistical tests cell before this one)\n",
    "\n",
    "# recommendations = []\n",
    "\n",
    "# # Check statistical test results\n",
    "# if 'statistical_results' not in globals():\n",
    "#     recommendations.append(\"\u26a0\ufe0f  Warning: 'statistical_results' not found. Run the 'Hypothesis Testing' section first.\")\n",
    "# elif len(statistical_results) > 0:\n",
    "#     significant_features = statistical_results[\n",
    "#         (statistical_results['mw_significant'] == True) & \n",
    "#         (statistical_results.get('welch_significant', pd.Series([True] * len(statistical_results))) == True)\n",
    "#     ]\n",
    "    \n",
    "#     if len(significant_features) > 0:\n",
    "#         recommendations.append(f\"\u2713 {len(significant_features)} features show significant differences (both tests agree)\")\n",
    "#         recommendations.append(f\"  \u2192 Prioritize these features: {', '.join(significant_features['metric'].head(5).tolist())}\")\n",
    "    \n",
    "#     # Check effect sizes\n",
    "#     if 'mean_difference' in statistical_results.columns:\n",
    "#         large_effect = statistical_results[statistical_results['mean_difference'].abs() > statistical_results['mean_difference'].abs().quantile(0.75)]\n",
    "#         if len(large_effect) > 0:\n",
    "#             recommendations.append(f\"\u2713 {len(large_effect)} features show large effect sizes\")\n",
    "#             recommendations.append(f\"  \u2192 These features have practical significance: {', '.join(large_effect['metric'].head(3).tolist())}\")\n",
    "\n",
    "# # Check temporal features\n",
    "# if len(chi_square_results) > 0:\n",
    "#     sig_temporal = chi_square_results[chi_square_results['significant'] == True]\n",
    "#     if len(sig_temporal) > 0:\n",
    "#         recommendations.append(f\"\u2713 {len(sig_temporal)} temporal features are significantly associated with wonky studies\")\n",
    "#         recommendations.append(f\"  \u2192 Include temporal features: {', '.join(sig_temporal.index.tolist())}\")\n",
    "\n",
    "# # Check demographic differences\n",
    "# if demographic_results:\n",
    "#     total_sig_demo = sum(len(df[df['mw_significant'] == True]) for df in demographic_results.values())\n",
    "#     if total_sig_demo > 0:\n",
    "#         recommendations.append(f\"\u2713 Found {total_sig_demo} significant demographic group differences\")\n",
    "#         recommendations.append(f\"  \u2192 Consider including demographic features as interaction terms\")\n",
    "\n",
    "# print(\"=\" * 80)\n",
    "# print(\"MODELING RECOMMENDATIONS\")\n",
    "# print(\"=\" * 80)\n",
    "# print()\n",
    "# for rec in recommendations:\n",
    "#     print(rec)\n",
    "# print()\n",
    "# print(\"=\" * 80)\n",
    "# print(\"NEXT STEPS:\")\n",
    "# print(\"=\" * 80)\n",
    "# print(\"1. Use top-ranked features from feature ranking for initial model\")\n",
    "# print(\"2. Include temporal features that show significant associations\")\n",
    "# print(\"3. Consider demographic interactions if significant differences found\")\n",
    "# print(\"4. Validate feature importance using model-based methods (e.g., Random Forest feature importance)\")\n",
    "# print(\"5. Monitor model performance on features identified as significant in EDA\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "435a6a6b-7164-41a0-9085-c9d74afcb688",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# # Create fraud risk score using modular function\n",
    "# respondent_features = create_fraud_risk_score(\n",
    "#     respondent_features,\n",
    "#     config={\n",
    "#         'fraud_score_weights': feature_config['fraud_score_weights'],\n",
    "#         'fraud_score_thresholds': feature_config['fraud_score_thresholds'],\n",
    "#         'fraud_score_bins': feature_config['fraud_score_bins'],\n",
    "#         'fraud_score_labels': feature_config['fraud_score_labels'],\n",
    "#         'suspected_fraud_threshold': feature_config['suspected_fraud_threshold']\n",
    "#     }\n",
    "# )\n",
    "\n",
    "# # Create wonky risk score\n",
    "# respondent_features = create_wonky_risk_score(\n",
    "#     respondent_features,\n",
    "#     config={\n",
    "#         'wonky_score_weights': feature_config['wonky_score_weights'],\n",
    "#         'wonky_score_thresholds': feature_config['wonky_score_thresholds'],\n",
    "#         'wonky_score_bins': feature_config['wonky_score_bins'],\n",
    "#         'wonky_score_labels': feature_config['wonky_score_labels']\n",
    "#     }\n",
    "# )\n",
    "\n",
    "# print(\"Fraud risk distribution:\")\n",
    "# print(respondent_features['fraud_risk_tier'].value_counts().sort_index())\n",
    "# print(f\"Suspected fraud rate: {respondent_features['suspected_fraud'].mean()*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4deb5513-3592-44aa-8daf-2efb2d88965b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Hypothesis Testing\n",
    "\n",
    "Running Mann-Whitney U test and Welch's t-test for validation.\n",
    "\n",
    "Check if Mann-Whitney U and Welch's t-test agree on significance.\n",
    "When both tests agree, we have higher confidence in the results.\n",
    "When they disagree, it signals need for further investigation.\n",
    "\n",
    "Compare wonky vs non-wonky users using statistical tests.\n",
    "- Mann-Whitney U test (non-parametric, primary test)\n",
    "- Welch's t-test (parametric validator/sense check)\n",
    "Uses `compare_groups_with_both_tests()` to run both tests simultaneously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aab5bd3c-cefe-4d99-94db-16cae34cd01c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# # Create binary flag for wonky users\n",
    "# respondent_features['has_wonky_tasks'] = (respondent_features['wonky_task_ratio'] > 0).astype(int)\n",
    "\n",
    "# print(f\"Wonky users: {respondent_features['has_wonky_tasks'].sum():,} ({respondent_features['has_wonky_tasks'].mean()*100:.2f}%)\")\n",
    "# print(f\"Non-wonky users: {(respondent_features['has_wonky_tasks'] == 0).sum():,} ({(respondent_features['has_wonky_tasks'] == 0).mean()*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9f75530f-8e2f-4bda-8d7b-8f992a02acef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Statistical Test Results Visualization\n",
    "\n",
    "Visualizing statistical test results to identify features with strongest discrimination between wonky and non-wonky groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d208e815-db6e-4709-8182-7b42ad5af3dc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# # Perform statistical tests using modular function\n",
    "# statistical_results = compare_groups_with_both_tests(\n",
    "#     respondent_features,\n",
    "#     group_col=stats_config['group_comparison']['group_col'],\n",
    "#     metrics=stats_config['test_metrics'],\n",
    "#     group1_value=stats_config['group_comparison']['group1_value'],\n",
    "#     group2_value=stats_config['group_comparison']['group2_value'],\n",
    "#     significance_level=stats_config['significance_level']\n",
    "# )\n",
    "\n",
    "# print(\"Statistical Test Results (Mann-Whitney U + Welch's t-test):\")\n",
    "# print(\"=\" * 100)\n",
    "# display(statistical_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "81d26455-067f-4f22-8798-262aa08eb2fd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# # Create dual-axis chart showing count differences and Welch's t-statistic\n",
    "\n",
    "# # Check if statistical_results exists\n",
    "# if 'statistical_results' not in globals():\n",
    "#     print(\"Warning: 'statistical_results' not found.\")\n",
    "#     print(\"   Please run the 'Hypothesis Testing' section cells first to create statistical_results.\")\n",
    "#     print(\"   This visualization will be skipped.\")\n",
    "# elif len(statistical_results) > 0 and 'welch_statistic' in statistical_results.columns:\n",
    "#     # Calc normalized count differences\n",
    "#     testdf_2 = statistical_results.copy()\n",
    "#     testdf_2['count_difference'] = testdf_2['wonky_mean'] - testdf_2['non_wonky_mean']\n",
    "#     testdf_2['count_difference_nrm'] = testdf_2['count_difference'] / (testdf_2['non_wonky_mean'].replace(0, np.nan))\n",
    "    \n",
    "#     testdf_2 = testdf_2.set_index('metric')\n",
    "    \n",
    "#     fig_dual = create_dual_axis_statistical_chart(\n",
    "#         testdf_2,\n",
    "#         count_diff_col='count_difference_nrm',\n",
    "#         t_stat_col='welch_statistic',\n",
    "#         title=\"Ave Wonky Count Difference & Welch's t-statistic by Feature\"\n",
    "#     )\n",
    "#     fig_dual.show()\n",
    "# else:\n",
    "#     print(\"Statistical results not available for dual-axis chart\")\n",
    "#     if 'statistical_results' in globals():\n",
    "#         print(f\"   statistical_results exists but is empty or missing 'welch_statistic' column\")\n",
    "#         print(f\"   Available columns: {list(statistical_results.columns) if len(statistical_results) > 0 else 'N/A'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "efdf385d-5be8-4899-ab0f-f0fd82844641",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# # Analyze thresholds for key features\n",
    "# print(\"Threshold Analysis: Task Volume\")\n",
    "# print(\"=\" * 80)\n",
    "# volume_thresholds = analyze_thresholds(\n",
    "#     respondent_features,\n",
    "#     feature='total_tasks',\n",
    "#     bins=stats_config['threshold_analysis']['default_bins'],\n",
    "#     target_col='has_wonky_tasks'\n",
    "# )\n",
    "# display(volume_thresholds)\n",
    "\n",
    "# print(\"\\nThreshold Analysis: Suspicious Fast Rate\")\n",
    "# print(\"=\" * 80)\n",
    "# speed_thresholds = analyze_thresholds(\n",
    "#     respondent_features,\n",
    "#     feature='suspicious_fast_rate',\n",
    "#     bins=stats_config['threshold_analysis']['default_bins'],\n",
    "#     target_col='has_wonky_tasks'\n",
    "# )\n",
    "# display(speed_thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0b74a098-f760-43ae-9169-7bb54e2f3216",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# # Example visualizations using modular functions\n",
    "\n",
    "# # Histogram of fraud risk score\n",
    "# fig_fraud_risk = create_histogram(\n",
    "#     respondent_features,\n",
    "#     x='fraud_risk_score',\n",
    "#     color='fraud_risk_tier',\n",
    "#     nbins=11,\n",
    "#     title='Fraud Risk Score Distribution',\n",
    "#     labels={'fraud_risk_score': 'Fraud Risk Score (0-10)'}\n",
    "# )\n",
    "# fig_fraud_risk.show()\n",
    "\n",
    "# # Box plot comparing wonky vs non-wonky users\n",
    "# fig_speed = create_box_plot(\n",
    "#     respondent_features,\n",
    "#     x='has_wonky_tasks',\n",
    "#     y='avg_task_time',\n",
    "#     color='has_wonky_tasks',\n",
    "#     title='Average Task Time: Wonky vs Non-Wonky Users',\n",
    "#     labels={'has_wonky_tasks': 'Has Wonky Tasks (1=Yes, 0=No)', 'avg_task_time': 'Average Task Time (seconds)'},\n",
    "#     category_orders={'has_wonky_tasks': [0, 1]},\n",
    "#     boxmean='sd'\n",
    "# )\n",
    "# fig_speed.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fff57faa-c32f-4ce9-a388-d54e04f07247",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Summary\n",
    "\n",
    "**Key Findings:**\n",
    "- Statistical tests (Mann-Whitney U + Welch's t-test) identify significant differences between wonky and non-wonky users\n",
    "- Temporal features show strong associations with wonky study participation (chi-squared tests)\n",
    "- Feature engineering creates actionable behavioral indicators (task speed, volume, velocity)\n",
    "- Demographic groups (platforms, hardware, locales) show varying wonky task rates\n",
    "- Both statistical tests provide validation - agreement increases confidence in findings\n",
    "- Visualizations highlight features with strongest discrimination power\n",
    "\n",
    "**Feature Selection Insights:**\n",
    "- Top-ranked features combine statistical significance with practical effect sizes\n",
    "- Temporal patterns (business hours, night tasks) are strong discriminators\n",
    "- Behavioral features (task volume, speed) show consistent differences\n",
    "- Demographic features may be useful as interaction terms\n",
    "\n",
    "**Next Steps:**\n",
    "- Use top-ranked features from feature ranking for model training\n",
    "- Include temporal features that show significant chi-squared associations\n",
    "- Consider demographic interactions based on group comparison results\n",
    "- Apply fraud risk thresholds to filter suspicious users\n",
    "- Build models using features identified as significant in EDA\n",
    "- Validate feature importance using model-based methods (Random Forest feature importance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ec763b35-0e7f-4c22-99b0-30642a498194",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "respondent_eda_refactored",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "ds-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}