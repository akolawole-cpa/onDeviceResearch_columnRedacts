{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "68811a8d-1b53-4b40-a738-7f32c0ffd8bd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Exec Summary\n",
    "\n",
    "-\n",
    "-\n",
    "-\n",
    "-\n",
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "566aaab3-ec7f-4b46-b960-716fb14053ee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install pyyaml>=6.0 -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b7566b84-4277-4e34-8a4a-c7c8ea000116",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.join(os.path.dirname(os.getcwd()), 'src'))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "try:\n",
    "    import yaml\n",
    "except ImportError:\n",
    "    raise ImportError(\n",
    "        \"PyYAML is not installed. Please run the previous cell to install it, \"\n",
    "        \"or run: %pip install pyyaml>=6.0\"\n",
    "    )\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from eda.feature_engineering import (\n",
    "    create_time_features,\n",
    "    create_task_speed_features,\n",
    "    create_respondent_behavioral_features,\n",
    "    add_wonky_features,\n",
    "    create_fraud_risk_score,\n",
    "    create_wonky_risk_score\n",
    ")\n",
    "from eda.statistical_tests import (\n",
    "    compare_groups_statistically,\n",
    "    compare_groups_with_both_tests,\n",
    "    analyze_thresholds,\n",
    "    perform_chi_square_tests,\n",
    "    compare_demographic_groups\n",
    ")\n",
    "from eda.visualizations import (\n",
    "    create_histogram,\n",
    "    create_box_plot,\n",
    "    create_scatter_plot,\n",
    "    create_bar_plot,\n",
    "    create_temporal_breakdown_summary,\n",
    "    create_task_speed_breakdown_summary,\n",
    "    create_chi_squared_bar_chart,\n",
    "    create_dual_axis_statistical_chart,\n",
    "    create_feature_breakdown_table,\n",
    "    create_distribution_comparison,\n",
    "    calculate_temporal_feature_deltas,       \n",
    "    create_chi_squared_delta_dual_axis_chart,\n",
    ")\n",
    "\n",
    "# Load configs\n",
    "with open('../configs/feature_engineering.yaml', 'r') as f:\n",
    "    feature_config = yaml.safe_load(f)\n",
    "\n",
    "with open('../configs/statistical_tests.yaml', 'r') as f:\n",
    "    stats_config = yaml.safe_load(f)\n",
    "\n",
    "with open('../configs/data_paths.yaml', 'r') as f:\n",
    "    paths_config = yaml.safe_load(f)\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "print(\"✓ Imports and configs loaded successfully\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f1c38d56-93e9-4cb5-9bc2-ef786af50c36",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### File Definitions\n",
    "\n",
    "- **user_info_df**: DataFrame of respondent x task level data for all users (not just wonky studies)\n",
    "- **wonky_studies_df**: DataFrame of respondents involved in studies with unexpected outcomes (negative impacts when positive expected)\n",
    "\n",
    "A study is \"wonky\" if the outcome is unexpected (e.g., advertisement showed negative impacts of media, which is counter-intuitive).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "16f52c87-8b48-473a-9e72-fd6ffc9eff72",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7b39bb0f-203b-49c3-a86d-9d1ef0d84005",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "notebook_path = os.getcwd() \n",
    "repo_root = os.path.abspath(os.path.join(notebook_path, \"..\"))\n",
    "misc_dir = os.path.join(repo_root, \"misc\")\n",
    "\n",
    "output_path = os.path.join(misc_dir,\n",
    "                           os.path.basename(paths_config['output_files']['user_info_df']))\n",
    "wonky_counts_path = os.path.join(misc_dir,\n",
    "                          os.path.basename(paths_config['output_files']['wonky_user_counts']))\n",
    "wonky_respondent_df_path = os.path.join(misc_dir,\n",
    "                          os.path.basename(paths_config['output_files']['wonky_respondent_df']))\n",
    "wonky_respondent_summary_path = os.path.join(misc_dir,\n",
    "                          os.path.basename(paths_config['output_files']['wonky_respondent_summary']))\n",
    "\n",
    "user_info_df = pd.read_parquet(output_path) # total user info\n",
    "wonky_counts = pd.read_parquet(wonky_counts_path) # normal tasks and wonky tasks for wonky task respondents\n",
    "wonky_respondent_df = pd.read_parquet(wonky_respondent_df_path) # task level info for wonky task respondents\n",
    "wonky_respondent_summary = pd.read_parquet(wonky_respondent_summary_path) # summary of wonky task respondents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b6c3b8aa-d07f-4c91-9497-bca8081dcc90",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(user_info_df.head())\n",
    "\n",
    "print(wonky_respondent_df.head())\n",
    "\n",
    "df = pd.DataFrame(user_info_df.isnull().sum(), columns=['null_count'])\n",
    "display(df.reset_index())\n",
    "\n",
    "print(\"\\nwonky_studies_df - Missing values:\")\n",
    "missing_wonky = wonky_respondent_df.isnull().sum()\n",
    "print(missing_wonky[missing_wonky > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d86925fc-03d4-4041-a181-4ca8e5576e5c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "wonky_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "05abc98f-56cb-4741-97a6-2a9acdd9adee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "key_numeric_cols = ['task_time_taken_s', 'task_points', 'risk', 'quality', 'task_completed']\n",
    "available_cols = [col for col in key_numeric_cols if col in user_info_df.columns]\n",
    "print(user_info_df[available_cols].describe())\n",
    "\n",
    "if 'wonky_study_flag' in user_info_df.columns:\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"COMPARISON BY wonky_study_flag (Task Level)\")\n",
    "    print(\"=\" * 80)\n",
    "    comparison_cols = ['task_time_taken_s', 'task_points', 'risk', 'quality']\n",
    "    comparison_cols = [col for col in comparison_cols if col in user_info_df.columns]\n",
    "    \n",
    "    if len(comparison_cols) > 0:\n",
    "        wonky_study_tasks = user_info_df[user_info_df['wonky_study_flag'] == 1]\n",
    "        non_wonky_study_tasks = user_info_df[user_info_df['wonky_study_flag'] == 0]\n",
    "        \n",
    "        print(\"\\nWonky Study Tasks (wonky_study_flag=1):\")\n",
    "        print(wonky_study_tasks[comparison_cols].describe())\n",
    "        \n",
    "        print(\"\\nNon-Wonky Study Tasks (wonky_study_flag=0):\")\n",
    "        print(non_wonky_study_tasks[comparison_cols].describe())\n",
    "        \n",
    "        if 'wonky_studies_count' in user_info_df.columns:\n",
    "            wonky_user_tasks = user_info_df[user_info_df['wonky_studies_count'] > 0]\n",
    "            print(\"\\nTasks from Users with Wonky Studies (wonky_studies_count > 0):\")\n",
    "            print(wonky_user_tasks[comparison_cols].describe())\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STATISTICAL SUMMARY: wonky_studies_df\")\n",
    "print(\"=\" * 80)\n",
    "print(wonky_counts.describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cc086073-cde3-4547-8c26-d7dffaa84ab1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cb5cb33e-6d9d-44e6-a1ca-f3e0078d7899",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create time features using modular function\n",
    "user_info_df = create_time_features(user_info_df, date_col=\"date_completed\")\n",
    "\n",
    "print(f\"Night tasks: {user_info_df['is_night'].mean()*100:.1f}%\")\n",
    "print(f\"Weekend tasks: {user_info_df['is_weekend'].mean()*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cfc0ca80-9828-4bcf-9ddf-94bdba2beed8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "TODO TEST USING CHI2 and ZTEST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "70cf541f-80dd-42e7-a1a3-4a21aa22518a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Temporal Feature Analysis & Breakdowns\n",
    "\n",
    "Analyzing temporal patterns to identify differences between wonky and non-wonky study tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ef64d4d5-3f60-40f8-bb45-2e33aebffe8f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "user_info_df['wonky_task_instances'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d8f9f8ae-daa1-4275-ab4f-d88c5a94b630",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "temporal_features = [\n",
    "    \"is_weekday\",\n",
    "    \"is_weekend\",\n",
    "    \"is_night\",\n",
    "    \"is_business_hour\",\n",
    "    \"is_business_hour_weekday\",\n",
    "    \"is_business_hour_weekend\",\n",
    "    \"is_monday\",\n",
    "    \"is_tuesday\",\n",
    "    \"is_wednesday\",\n",
    "    \"is_thursday\",\n",
    "    \"is_friday\",\n",
    "    \"is_saturday\",\n",
    "    \"is_sunday\",\n",
    "]\n",
    "\n",
    "print(\n",
    "    create_temporal_breakdown_summary(\n",
    "        user_info_df,\n",
    "        temporal_features=temporal_features,\n",
    "        group_col=\"wonky_task_instances\",\n",
    "        group_threshold=0,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7de3c8b2-fc0f-4beb-9f21-972bd13c314b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Task complete time - definately good gauge. Majority takes place during business hours, relatively evenly spread across the work week LARGEST detla where wonky is more prevalent is in business hours suggesting professional behaviours\n",
    "**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d98f42a0-2879-495a-9ecb-5675f1628929",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Chi-Squared Tests for Temporal Features\n",
    "\n",
    "Testing independence between temporal features and wonky study participation.\n",
    "Chi-squared test determines if temporal patterns differ significantly between wonky and non-wonky groups.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ddf136e0-8a81-4f0f-96ca-a4e3f08ec403",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "chi_square_results = perform_chi_square_tests(\n",
    "    user_info_df,\n",
    "    feature_set=temporal_features,\n",
    "    group_var='wonky_task_instances',\n",
    "    significance_level=0.01\n",
    ")\n",
    "\n",
    "chi_square_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f4871aad-769d-462c-a4bf-4295673e5630",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Strong significance for all subsets but wednesday and friday although this doesn't taken into consideration directionality -> simple separators are business hours**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ac025e77-9b06-4028-878a-79c78c0a5605",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "STRONG SIGNIFICANT READ AT 99% LEVEL LARGEST MAGNITUDE FOUND AT NIGHT. LOWEST MAGNITUDE DURING WEEKEND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5251fa82-b4cb-4ed6-910c-4a9b9bca4ee3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Summary\n",
    "if len(chi_square_results) > 0:\n",
    "    significant_features = chi_square_results[chi_square_results['significant'] == True]\n",
    "    print(f\"\\nSignificant temporal features (p < 0.01): {len(significant_features)}\")\n",
    "    if len(significant_features) > 0:\n",
    "        print(\"Features:\", ', '.join(significant_features.index.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d779cd52-dfc4-4e68-87f9-bb87a5636e8d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Visualize chi-squared statistics\n",
    "if len(chi_square_results) > 0:\n",
    "    fig_chi2 = create_chi_squared_bar_chart(\n",
    "        chi_square_results,\n",
    "        chi2_col='chi2',\n",
    "        p_value_col='chi_p_value',\n",
    "        significance_level=0.01,\n",
    "        title=\"Chi-Squared Statistic by Temporal Feature\"\n",
    "    )\n",
    "    fig_chi2.show()\n",
    "else:\n",
    "    print(\"No chi-squared test results available for visualization\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e0336f6c-a4d5-403f-a558-542119dd3b68",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "if len(chi_square_results) > 0:\n",
    "    delta_results = calculate_temporal_feature_deltas(\n",
    "      user_info_df,\n",
    "      temporal_features=temporal_features,\n",
    "      group_col='wonky_task_instances',  \n",
    "      group_threshold=0 \n",
    ")\n",
    "    \n",
    "    if len(delta_results) > 0:\n",
    "        fig_dual = create_chi_squared_delta_dual_axis_chart(\n",
    "            chi_square_results,\n",
    "            delta_results,\n",
    "            chi2_col='chi2',\n",
    "            p_value_col='chi_p_value',\n",
    "            delta_col='delta_pct',\n",
    "            significance_level=0.01,\n",
    "            title=\"Chi-Squared Statistic and Delta % by Temporal Feature\"\n",
    "        )\n",
    "        fig_dual.show()\n",
    "    else:\n",
    "        print(\"No delta results available for visualization\")\n",
    "else:\n",
    "    print(\"No chi-squared test results available for visualization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7d89c1bc-3445-45af-98a3-d32efbfd4638",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Bar is the level of siginficance between the wonky and non wonky, the line are the delta's between wonky and non wonky in terms of when tasks are complete.\n",
    "\n",
    "positive delta means wonky participants are more prevalent and negative delta means they are less prevalent.\n",
    "\n",
    "Business hours, Night time, Saturdays look like the overall best separators between wonky and non wonky participants in terms of task complete time\n",
    "**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "437bdf73-4a93-4116-b26a-38493a0b2a96",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Task speed features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1b14d3ff-1a10-46e7-9b3e-9b912e58b234",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "user_info_df['task_time_taken_s_capped'] = np.where(user_info_df['task_time_taken_s'] < user_info_df['task_time_taken_s'].quantile(0.9999), user_info_df['task_time_taken_s'], user_info_df['task_time_taken_s'].quantile(0.9999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7d9063f8-4d25-4c98-a1ed-52ff6ecc56cc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "user_info_df = create_task_speed_features(\n",
    "    user_info_df,\n",
    "    task_time_col=\"task_time_taken_s_capped\",\n",
    "    use_std_dev=True\n",
    ")\n",
    "\n",
    "mean_time = user_info_df[\"task_time_taken_s_capped\"].mean()\n",
    "std_time = user_info_df[\"task_time_taken_s_capped\"].std()\n",
    "print(f\"Task time statistics:\")\n",
    "print(f\"  Mean: {mean_time:.2f} seconds ({mean_time/60:.2f} minutes)\")\n",
    "print(f\"  Std Dev: {std_time:.2f} seconds ({std_time/60:.2f} minutes)\")\n",
    "print(f\"  Fast threshold (mean - 1σ): {mean_time - std_time:.2f}s\")\n",
    "print(f\"  Suspiciously fast threshold (mean - 2σ): {mean_time - 2*std_time:.2f}s\")\n",
    "print(f\"  Slow threshold (mean + 1σ): {mean_time + std_time:.2f}s\")\n",
    "print(f\"  Suspiciously slow threshold (mean + 2σ): {mean_time + 2*std_time:.2f}s\")\n",
    "print()\n",
    "\n",
    "# Display breakdown with wonky vs non-wonky comparison\n",
    "print(create_task_speed_breakdown_summary(\n",
    "    user_info_df,\n",
    "    group_col='wonky_task_instances',\n",
    "    group_threshold=0\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0c58953f-e755-4a93-85df-e34fa15c7eb4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Wonky participants are usually suspcisouly fast to normal non wonky participants tend to be normal to supcisouly slow in terms of delta **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0f3fd6ea-c147-4dd5-9c6f-e765bcf7c132",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "user_info_df = create_task_speed_features(\n",
    "    user_info_df,\n",
    "    task_time_col=\"task_time_taken_s\",\n",
    "    use_std_dev=True\n",
    ")\n",
    "\n",
    "fast_threshold = user_info_df[\"task_time_taken_s\"].quantile(0.16)\n",
    "suspiciously_fast_threshold = user_info_df[\"task_time_taken_s\"].quantile(0.025)\n",
    "slow_threshold = user_info_df[\"task_time_taken_s\"].quantile(0.84)\n",
    "suspiciously_slow_threshold = user_info_df[\"task_time_taken_s\"].quantile(0.975)\n",
    "\n",
    "# Also calculate trimmed mean/std for reference (trimming extreme outliers)\n",
    "trimmed_data = user_info_df[\"task_time_taken_s\"].clip(\n",
    "    lower=user_info_df[\"task_time_taken_s\"].quantile(0.01),\n",
    "    upper=user_info_df[\"task_time_taken_s\"].quantile(0.99)\n",
    ")\n",
    "mean_time = trimmed_data.mean()\n",
    "std_time = trimmed_data.std()\n",
    "\n",
    "print(f\"Task time statistics (using percentiles, robust to outliers):\")\n",
    "print(f\"  Mean (trimmed 1%-99%): {mean_time:.2f} seconds ({mean_time/60:.2f} minutes)\")\n",
    "print(f\"  Std Dev (trimmed 1%-99%): {std_time:.2f} seconds ({std_time/60:.2f} minutes)\")\n",
    "print(f\"  Fast threshold (16th percentile): {fast_threshold:.2f}s ({fast_threshold/60:.2f} min)\")\n",
    "print(f\"  Suspiciously fast threshold (2.5th percentile): {suspiciously_fast_threshold:.2f}s ({suspiciously_fast_threshold/60:.2f} min)\")\n",
    "print(f\"  Slow threshold (84th percentile): {slow_threshold:.2f}s ({slow_threshold/60:.2f} min)\")\n",
    "print(f\"  Suspiciously slow threshold (97.5th percentile): {suspiciously_slow_threshold:.2f}s ({suspiciously_slow_threshold/60:.2f} min)\")\n",
    "print()\n",
    "\n",
    "# Display breakdown with wonky vs non-wonky comparison\n",
    "group_col_to_use = 'wonky_task_instances' if 'wonky_task_instances' in user_info_df.columns else 'wonky_study_count'\n",
    "print(create_task_speed_breakdown_summary(\n",
    "    user_info_df,\n",
    "    group_col=group_col_to_use,\n",
    "    group_threshold=0\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b715724b-3912-45af-854b-c4a999cb048f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from eda.statistical_tests import compare_speed_categories_proportions\n",
    "\n",
    "# Statistical tests for speed categories: Chi-squared and Two-Proportion Z-Test\n",
    "speed_features = ['is_suspiciously_fast', 'is_fast', 'is_normal_speed', 'is_slow', 'is_suspiciously_slow']\n",
    "\n",
    "# Ensure we have the correct group column\n",
    "group_col_to_use = 'wonky_task_instances' if 'wonky_task_instances' in user_info_df.columns else 'wonky_study_count'\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"STATISTICAL TESTS: Speed Categories vs Wonky Status\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "\n",
    "# 1. Chi-squared test (overall association)\n",
    "print(\"1. CHI-SQUARED TEST (Overall Association)\")\n",
    "print(\"-\" * 80)\n",
    "print(\"Tests if speed category distribution is independent of wonky task status\")\n",
    "print()\n",
    "\n",
    "chi2_speed_results = perform_chi_square_tests(\n",
    "    user_info_df,\n",
    "    feature_set=speed_features,\n",
    "    group_var=group_col_to_use,\n",
    "    significance_level=0.01\n",
    ")\n",
    "\n",
    "if len(chi2_speed_results) > 0:\n",
    "    print(\"Results:\")\n",
    "    display(chi2_speed_results)\n",
    "    print()\n",
    "    \n",
    "    significant_features = chi2_speed_results[chi2_speed_results['significant']]\n",
    "    if len(significant_features) > 0:\n",
    "        print(f\"✓ Significant association found for {len(significant_features)} speed category(ies)\")\n",
    "        print(f\"  Features: {', '.join(significant_features.index.tolist())}\")\n",
    "    else:\n",
    "        print(\"✗ No significant association found (p > 0.05)\")\n",
    "else:\n",
    "    print(\"No results available (check if speed features exist in DataFrame)\")\n",
    "print()\n",
    "\n",
    "# 2. Two-proportion Z-test (individual category comparisons)\n",
    "print(\"2. TWO-PROPORTION Z-TEST (Individual Category Comparisons)\")\n",
    "print(\"-\" * 80)\n",
    "print(\"Tests if proportion differs significantly for each speed category\")\n",
    "print()\n",
    "\n",
    "ztest_speed_results = compare_speed_categories_proportions(\n",
    "    user_info_df,\n",
    "    speed_features=speed_features,\n",
    "    group_col=group_col_to_use,\n",
    "    group_threshold=0,\n",
    "    significance_level=0.01\n",
    ")\n",
    "\n",
    "if len(ztest_speed_results) > 0:\n",
    "    print(\"Results:\")\n",
    "    display(ztest_speed_results.reset_index(drop=True))\n",
    "    print()\n",
    "    \n",
    "    # Format results for easier interpretation\n",
    "    print(\"Summary:\")\n",
    "    for _, row in ztest_speed_results.iterrows():\n",
    "        feature_name = row['feature'].replace('is_', '').replace('_', ' ').title()\n",
    "        sig_marker = \"***\" if row['significant'] else \"\"\n",
    "        print(f\"  {feature_name}:\")\n",
    "        print(f\"    Wonky: {row['wonky_proportion']*100:.2f}% ({row['wonky_count']:,}/{row['wonky_total']:,})\")\n",
    "        print(f\"    Non-wonky: {row['non_wonky_proportion']*100:.2f}% ({row['non_wonky_count']:,}/{row['non_wonky_total']:,})\")\n",
    "        print(f\"    Difference: {row['proportion_diff']*100:+.2f}%\")\n",
    "        print(f\"    Z-statistic: {row['z_statistic']:.3f}, p-value: {row['p_value']:.4f} {sig_marker}\")\n",
    "        print()\n",
    "    \n",
    "    significant_categories = ztest_speed_results[ztest_speed_results['significant']]\n",
    "    if len(significant_categories) > 0:\n",
    "        print(f\"✓ Significant differences found for {len(significant_categories)} category(ies):\")\n",
    "        for _, row in significant_categories.iterrows():\n",
    "            feature_name = row['feature'].replace('is_', '').replace('_', ' ').title()\n",
    "            direction = \"higher\" if row['proportion_diff'] > 0 else \"lower\"\n",
    "            print(f\"  - {feature_name}: Wonky tasks have {abs(row['proportion_diff']*100):.2f}% {direction} proportion\")\n",
    "    else:\n",
    "        print(\"✗ No significant differences found (p > 0.05 for all categories)\")\n",
    "else:\n",
    "    print(\"No results available (check if speed features exist in DataFrame)\")\n",
    "print()\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"Interpretation:\")\n",
    "print(\"- Chi-squared test: Overall test of independence (all categories together)\")\n",
    "print(\"- Two-proportion Z-test: Individual tests for each category\")\n",
    "print(\"- Significant results (p < 0.01) indicate wonky and non-wonky groups differ\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9bde2f0c-36da-460e-9051-0227a63f117e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "TODO -> rethink Viz for this section all significant across z test and chi squared test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f995edea-c859-45c3-bfb8-31994d052ea0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Task and Point categroy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d03c83fa-bcb0-4371-9260-2d67850e5f34",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "user_info_df['defined_task_category'] = user_info_df['taskCategory'].astype(str) + \"_points_\" + user_info_df['payoutPoints'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dddb3a08-1daa-491d-a7e8-000994f31c7e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "user_info_df['defined_task_category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dd9792b0-8c8c-44bf-9de9-3cd582f658c2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "201e2117-c66b-42d3-8dbe-8c56964f6f2d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "86534f50-c562-443e-a0e0-4663012ef1ee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3c2ffbd4-aa78-482b-ac8c-aee6f5decb67",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a6d4ca7c-c549-4c81-817a-d048aa8ebd70",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create task speed features using modular function\n",
    "user_info_df = create_task_speed_features(\n",
    "    user_info_df,\n",
    "    task_time_col=\"task_time_taken_s\",\n",
    "    suspicious_threshold=feature_config[\"time_thresholds\"][\"suspicious_fast_seconds\"],\n",
    "    very_fast_threshold=feature_config[\"time_thresholds\"][\"very_fast_seconds\"],\n",
    "    very_slow_threshold=feature_config[\"time_thresholds\"][\"very_slow_minutes\"] * 60,\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"Suspiciously fast (<{feature_config['time_thresholds']['suspicious_fast_seconds']}s): {user_info_df['is_suspiciously_fast'].sum():,} ({user_info_df['is_suspiciously_fast'].mean()*100:.2f}%)\"\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"very_fast_seconds fast (<{feature_config['time_thresholds']['very_fast_seconds']}s): {user_info_df['is_very_fast'].sum():,} ({user_info_df['is_very_fast'].mean()*100:.2f}%)\"\n",
    ")\n",
    "\n",
    "print(f\"very_slow_minutes fast (<{feature_config['time_thresholds']['very_slow_minutes']}s): {user_info_df['is_very_slow'].sum():,} ({user_info_df['is_very_slow'].mean()*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b286bc7e-a10b-4973-bf30-fcc42a367e97",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Respondent level features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0e81c78c-3e3e-463e-9615-2e5f83d5b8e0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create respondent-level behavioral features\n",
    "\n",
    "import importlib\n",
    "if 'eda.feature_engineering' in sys.modules:\n",
    "    importlib.reload(sys.modules['eda.feature_engineering'])\n",
    "    from eda.feature_engineering import create_respondent_behavioral_features\n",
    "\n",
    "respondent_features = create_respondent_behavioral_features(\n",
    "    user_info_df,\n",
    "    respondent_id_col=\"respondentPk\",\n",
    "    date_col=\"date_completed\",\n",
    "    config={\n",
    "        'high_volume_percentile': feature_config['volume_thresholds']['high_volume_percentile'],\n",
    "        'extreme_volume_percentile': feature_config['volume_thresholds']['extreme_volume_percentile'],\n",
    "        'velocity_bins': feature_config['velocity_bins'],\n",
    "        'velocity_labels': feature_config['velocity_labels']\n",
    "    },\n",
    "    demographic_cols=['platform_name', 'hardware_version', 'survey_locale'],\n",
    ")\n",
    "\n",
    "print(f\"Aggregated to {respondent_features.shape[0]:,} respondents\")\n",
    "print(f\"Avg tasks per respondent: {respondent_features['total_tasks'].mean():.2f}\")\n",
    "print(f\"Avg suspicious fast rate: {respondent_features['suspicious_fast_rate'].mean()*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cdf511ee-5fa5-4b09-9ad9-48924f6d25a9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "respondent_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5cb0bec3-ec25-4319-b561-151883ca5ee0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Add wonky features using modular function\n",
    "respondent_features = add_wonky_features(\n",
    "    respondent_features,\n",
    "    wonky_studies_df,\n",
    "    respondent_id_col=\"respondentPk\"\n",
    ")\n",
    "\n",
    "print(f\"Wonky features added\")\n",
    "print(f\"Respondents with wonky tasks: {(respondent_features['wonky_task_ratio'] > 0).sum():,}\")\n",
    "print(f\"High wonky concentration (>50%): {respondent_features['is_high_wonky'].sum():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d33a49c5-16de-4ae3-9738-c5aba068ca1a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Distribution Comparisons\n",
    "\n",
    "Comparing distributions of key features between wonky and non-wonky groups to visualize differences.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "522d0c75-ff48-40ea-93d7-d76a03ca3720",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "respondent_features['wonky_task_ratio_capped'] = np.where(respondent_features['wonky_task_ratio'] > 1, 1, respondent_features['wonky_task_ratio'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3d2170e4-e739-4439-8095-9a95a8a04ddb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Distribution comparisons for key features\n",
    "if 'respondent_features' not in globals():\n",
    "    raise ValueError(\"'respondent_features' DataFrame not found. Please run previous cells to create it.\")\n",
    "\n",
    "# Ensure has_wonky_tasks column exists\n",
    "if 'has_wonky_tasks' not in respondent_features.columns:\n",
    "    if 'wonky_task_ratio' in respondent_features.columns:\n",
    "        print(\"Warning: 'has_wonky_tasks' column not found. Creating it from 'wonky_task_ratio'...\")\n",
    "        respondent_features['has_wonky_tasks'] = (respondent_features['wonky_task_ratio_capped'] > 0).astype(int)\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            \"'has_wonky_tasks' column not found and 'wonky_task_ratio' is also missing. \"\n",
    "            \"Cannot create distribution comparisons. Available columns: \"\n",
    "            f\"{list(respondent_features.columns)[:30]}\"\n",
    "        )\n",
    "\n",
    "key_features_for_dist = ['total_tasks', 'suspicious_fast_rate', 'days_active', \n",
    "                         'avg_task_time', 'wonky_task_ratio_capped']\n",
    "\n",
    "# Filter to only features that exist\n",
    "available_features = [f for f in key_features_for_dist if f in respondent_features.columns]\n",
    "missing_features = [f for f in key_features_for_dist if f not in respondent_features.columns]\n",
    "\n",
    "if missing_features:\n",
    "    print(f\"Warning: Some features not found: {missing_features}\")\n",
    "    print(f\"   Available columns: {list(respondent_features.columns)[:30]}\")\n",
    "\n",
    "if len(available_features) == 0:\n",
    "    print(\"Error: None of the requested features are available in respondent_features.\")\n",
    "    print(f\"   Requested: {key_features_for_dist}\")\n",
    "    print(f\"   Available: {list(respondent_features.columns)[:30]}\")\n",
    "else:\n",
    "    print(f\"✓ Creating distribution comparisons for {len(available_features)} features: {available_features}\")\n",
    "\n",
    "for feature in available_features:\n",
    "    try:\n",
    "        # Create histogram comparison\n",
    "        fig_dist = create_distribution_comparison(\n",
    "            respondent_features,\n",
    "            feature=feature,\n",
    "            group_col='has_wonky_tasks',\n",
    "            group1_value=1,\n",
    "            group2_value=0,\n",
    "            plot_type='histogram',\n",
    "            group1_name='Wonky Users',\n",
    "            group2_name='Non-Wonky Users',\n",
    "            title=f'{feature.replace(\"_\", \" \").title()} Distribution: Wonky vs Non-Wonky Users'\n",
    "        )\n",
    "        fig_dist.show()\n",
    "        \n",
    "        # Create box plot comparison\n",
    "        fig_box = create_distribution_comparison(\n",
    "            respondent_features,\n",
    "            feature=feature,\n",
    "            group_col='has_wonky_tasks',\n",
    "            group1_value=1,\n",
    "            group2_value=0,\n",
    "            plot_type='box',\n",
    "            group1_name='Wonky Users',\n",
    "            group2_name='Non-Wonky Users',\n",
    "            title=f'{feature.replace(\"_\", \" \").title()} Distribution: Wonky vs Non-Wonky Users'\n",
    "        )\n",
    "        fig_box.show()\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating distribution comparison for '{feature}': {e}\")\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "127fc16c-2a48-4902-85b8-0959a479298a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "respondent_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "04e0fe61-3822-4fe1-a539-77b6ac95b967",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Feature summary tables\n",
    "\n",
    "feature_breakdown = create_feature_breakdown_table(\n",
    "    respondent_features,\n",
    "    feature_col='has_wonky_tasks',\n",
    "    group_col='has_wonky_tasks',\n",
    "    group1_value=1,\n",
    "    group2_value=0,\n",
    "    metrics=key_features_for_dist\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "adc61d30-19c2-4dcf-a2f7-a62a5911a70c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "feature_breakdown.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "78bd3c52-db11-4264-a4d3-581fe1295458",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Demographic Group Comparisons\n",
    "\n",
    "Comparing wonky task rates across demographic groups (platforms, hardware versions, locales) using statistical tests.\n",
    "This helps identify if certain demographics are more associated with wonky study participation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c3086936-8552-4088-bcf2-709e967436b8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "respondent_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b401d6d6-4517-47fa-8862-25eb52a45ce0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Compare wonky task rates across demographic groups\n",
    "\n",
    "demographic_cols = ['platform_name', 'hardware_version', 'survey_locale']\n",
    "\n",
    "demographic_results = {}\n",
    "\n",
    "for demo_col in demographic_cols:\n",
    "    if demo_col in respondent_features.columns:\n",
    "        print(demo_col)\n",
    "        print(f\"\\n{'=' * 80}\")\n",
    "        print(f\"Demographic Comparison: {demo_col}\")\n",
    "        print('=' * 80)\n",
    "        \n",
    "        # Perform comparisons\n",
    "        demo_comparisons = compare_demographic_groups(\n",
    "            respondent_features,\n",
    "            demographic_col=demo_col,\n",
    "            target_col='wonky_task_ratio',\n",
    "            min_group_size=10,\n",
    "            significance_level=0.05\n",
    "        )\n",
    "        \n",
    "        if len(demo_comparisons) > 0:\n",
    "            demographic_results[demo_col] = demo_comparisons\n",
    "            \n",
    "            # Show summary statistics by group\n",
    "            group_summary = respondent_features.groupby(demo_col).agg({\n",
    "                'wonky_task_ratio': ['mean', 'median', 'count'],\n",
    "                'has_wonky_tasks': 'sum'\n",
    "            }).round(4)\n",
    "            group_summary.columns = ['mean_wonky_ratio', 'median_wonky_ratio', 'total_count', 'wonky_count']\n",
    "            group_summary['wonky_rate'] = (group_summary['wonky_count'] / group_summary['total_count'] * 100).round(2)\n",
    "            group_summary = group_summary.sort_values('mean_wonky_ratio', ascending=False)\n",
    "            \n",
    "            print(f\"\\nSummary by {demo_col}:\")\n",
    "            display(group_summary)\n",
    "            \n",
    "            # Show significant comparisons\n",
    "            significant_comps = demo_comparisons[demo_comparisons['mw_significant'] == True]\n",
    "            if len(significant_comps) > 0:\n",
    "                print(f\"\\nSignificant differences (p < 0.05): {len(significant_comps)}\")\n",
    "                display(significant_comps[['group1', 'group2', 'mean_difference', 'mw_p_value', 'welch_p_value', 'tests_agree']])\n",
    "            else:\n",
    "                print(\"\\nNo significant differences found between groups\")\n",
    "        else:\n",
    "            print(f\"Insufficient data for {demo_col} comparisons\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c7d8df9d-725b-4471-a1cd-8fc9cd56b9ef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Visualize demographic comparisons\n",
    "# Why: Bar charts make it easy to see which demographic groups have higher wonky task rates\n",
    "# Helps identify patterns that may inform modeling or business decisions\n",
    "\n",
    "for demo_col in demographic_cols:\n",
    "    if demo_col in respondent_features.columns and demo_col in demographic_results:\n",
    "        # Create summary by group\n",
    "        demo_summary = respondent_features.groupby(demo_col).agg({\n",
    "            'wonky_task_ratio': 'mean',\n",
    "            'has_wonky_tasks': ['sum', 'count']\n",
    "        }).reset_index()\n",
    "        demo_summary.columns = [demo_col, 'mean_wonky_ratio', 'wonky_count', 'total_count']\n",
    "        demo_summary['wonky_rate'] = (demo_summary['wonky_count'] / demo_summary['total_count'] * 100)\n",
    "        demo_summary = demo_summary.sort_values('mean_wonky_ratio', ascending=False)\n",
    "        \n",
    "        # Bar chart of wonky rates by demographic group\n",
    "        fig_demo = create_bar_plot(\n",
    "            demo_summary,\n",
    "            x=demo_col,\n",
    "            y='wonky_rate',\n",
    "            title=f'Wonky Task Rate by {demo_col.replace(\"_\", \" \").title()}',\n",
    "            labels={demo_col: demo_col.replace(\"_\", \" \").title(), 'wonky_rate': 'Wonky Task Rate (%)'},\n",
    "            color='wonky_rate',\n",
    "            color_continuous_scale='Reds',\n",
    "            text='wonky_rate',\n",
    "            texttemplate='%{text:.1f}%',\n",
    "            textposition='outside',\n",
    "            tickangle=45\n",
    "        )\n",
    "        fig_demo.show()\n",
    "        \n",
    "        # Box plot comparing wonky task ratios across groups\n",
    "        fig_demo_box = create_box_plot(\n",
    "            respondent_features,\n",
    "            x=demo_col,\n",
    "            y='wonky_task_ratio',\n",
    "            title=f'Wonky Task Ratio Distribution by {demo_col.replace(\"_\", \" \").title()}',\n",
    "            labels={demo_col: demo_col.replace(\"_\", \" \").title(), 'wonky_task_ratio': 'Wonky Task Ratio'},\n",
    "            tickangle=45\n",
    "        )\n",
    "        fig_demo_box.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2207d4e0-25d4-426a-b7a4-0be2ed17a898",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Feature Selection Guidance\n",
    "\n",
    "Based on EDA results, identify which features show strongest discrimination and should be prioritized for modeling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9eb6b4d8-e308-45b1-9a1a-11adf1c44ce4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "24ab1cf7-8bdf-4909-a232-98c5007e163f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b00ae635-6bcc-453b-aef7-a91c9c3368b0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e5b62d8d-41b6-4739-a067-11428067dadc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Modeling Recommendations\n",
    "\n",
    "Based on EDA findings, recommendations for feature selection and modeling approach.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f4c5fd06-d754-4dfd-834a-d7ead7a30e11",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Generate modeling recommendations\n",
    "# Why: Synthesizes EDA findings into actionable recommendations for model development\n",
    "# Note: Requires statistical_results to be created first (run the statistical tests cell before this one)\n",
    "\n",
    "recommendations = []\n",
    "\n",
    "# Check statistical test results\n",
    "if 'statistical_results' not in globals():\n",
    "    recommendations.append(\"⚠️  Warning: 'statistical_results' not found. Run the 'Hypothesis Testing' section first.\")\n",
    "elif len(statistical_results) > 0:\n",
    "    significant_features = statistical_results[\n",
    "        (statistical_results['mw_significant'] == True) & \n",
    "        (statistical_results.get('welch_significant', pd.Series([True] * len(statistical_results))) == True)\n",
    "    ]\n",
    "    \n",
    "    if len(significant_features) > 0:\n",
    "        recommendations.append(f\"✓ {len(significant_features)} features show significant differences (both tests agree)\")\n",
    "        recommendations.append(f\"  → Prioritize these features: {', '.join(significant_features['metric'].head(5).tolist())}\")\n",
    "    \n",
    "    # Check effect sizes\n",
    "    if 'mean_difference' in statistical_results.columns:\n",
    "        large_effect = statistical_results[statistical_results['mean_difference'].abs() > statistical_results['mean_difference'].abs().quantile(0.75)]\n",
    "        if len(large_effect) > 0:\n",
    "            recommendations.append(f\"✓ {len(large_effect)} features show large effect sizes\")\n",
    "            recommendations.append(f\"  → These features have practical significance: {', '.join(large_effect['metric'].head(3).tolist())}\")\n",
    "\n",
    "# Check temporal features\n",
    "if len(chi_square_results) > 0:\n",
    "    sig_temporal = chi_square_results[chi_square_results['significant'] == True]\n",
    "    if len(sig_temporal) > 0:\n",
    "        recommendations.append(f\"✓ {len(sig_temporal)} temporal features are significantly associated with wonky studies\")\n",
    "        recommendations.append(f\"  → Include temporal features: {', '.join(sig_temporal.index.tolist())}\")\n",
    "\n",
    "# Check demographic differences\n",
    "if demographic_results:\n",
    "    total_sig_demo = sum(len(df[df['mw_significant'] == True]) for df in demographic_results.values())\n",
    "    if total_sig_demo > 0:\n",
    "        recommendations.append(f\"✓ Found {total_sig_demo} significant demographic group differences\")\n",
    "        recommendations.append(f\"  → Consider including demographic features as interaction terms\")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"MODELING RECOMMENDATIONS\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "for rec in recommendations:\n",
    "    print(rec)\n",
    "print()\n",
    "print(\"=\" * 80)\n",
    "print(\"NEXT STEPS:\")\n",
    "print(\"=\" * 80)\n",
    "print(\"1. Use top-ranked features from feature ranking for initial model\")\n",
    "print(\"2. Include temporal features that show significant associations\")\n",
    "print(\"3. Consider demographic interactions if significant differences found\")\n",
    "print(\"4. Validate feature importance using model-based methods (e.g., Random Forest feature importance)\")\n",
    "print(\"5. Monitor model performance on features identified as significant in EDA\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "435a6a6b-7164-41a0-9085-c9d74afcb688",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create fraud risk score using modular function\n",
    "respondent_features = create_fraud_risk_score(\n",
    "    respondent_features,\n",
    "    config={\n",
    "        'fraud_score_weights': feature_config['fraud_score_weights'],\n",
    "        'fraud_score_thresholds': feature_config['fraud_score_thresholds'],\n",
    "        'fraud_score_bins': feature_config['fraud_score_bins'],\n",
    "        'fraud_score_labels': feature_config['fraud_score_labels'],\n",
    "        'suspected_fraud_threshold': feature_config['suspected_fraud_threshold']\n",
    "    }\n",
    ")\n",
    "\n",
    "# Create wonky risk score\n",
    "respondent_features = create_wonky_risk_score(\n",
    "    respondent_features,\n",
    "    config={\n",
    "        'wonky_score_weights': feature_config['wonky_score_weights'],\n",
    "        'wonky_score_thresholds': feature_config['wonky_score_thresholds'],\n",
    "        'wonky_score_bins': feature_config['wonky_score_bins'],\n",
    "        'wonky_score_labels': feature_config['wonky_score_labels']\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"Fraud risk distribution:\")\n",
    "print(respondent_features['fraud_risk_tier'].value_counts().sort_index())\n",
    "print(f\"Suspected fraud rate: {respondent_features['suspected_fraud'].mean()*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4deb5513-3592-44aa-8daf-2efb2d88965b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Hypothesis Testing\n",
    "\n",
    "Running Mann-Whitney U test and Welch's t-test for validation.\n",
    "\n",
    "Check if Mann-Whitney U and Welch's t-test agree on significance.\n",
    "When both tests agree, we have higher confidence in the results.\n",
    "When they disagree, it signals need for further investigation.\n",
    "\n",
    "Compare wonky vs non-wonky users using statistical tests.\n",
    "- Mann-Whitney U test (non-parametric, primary test)\n",
    "- Welch's t-test (parametric validator/sense check)\n",
    "Uses `compare_groups_with_both_tests()` to run both tests simultaneously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aab5bd3c-cefe-4d99-94db-16cae34cd01c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create binary flag for wonky users\n",
    "respondent_features['has_wonky_tasks'] = (respondent_features['wonky_task_ratio'] > 0).astype(int)\n",
    "\n",
    "print(f\"Wonky users: {respondent_features['has_wonky_tasks'].sum():,} ({respondent_features['has_wonky_tasks'].mean()*100:.2f}%)\")\n",
    "print(f\"Non-wonky users: {(respondent_features['has_wonky_tasks'] == 0).sum():,} ({(respondent_features['has_wonky_tasks'] == 0).mean()*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9f75530f-8e2f-4bda-8d7b-8f992a02acef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Statistical Test Results Visualization\n",
    "\n",
    "Visualizing statistical test results to identify features with strongest discrimination between wonky and non-wonky groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d208e815-db6e-4709-8182-7b42ad5af3dc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Perform statistical tests using modular function\n",
    "statistical_results = compare_groups_with_both_tests(\n",
    "    respondent_features,\n",
    "    group_col=stats_config['group_comparison']['group_col'],\n",
    "    metrics=stats_config['test_metrics'],\n",
    "    group1_value=stats_config['group_comparison']['group1_value'],\n",
    "    group2_value=stats_config['group_comparison']['group2_value'],\n",
    "    significance_level=stats_config['significance_level']\n",
    ")\n",
    "\n",
    "print(\"Statistical Test Results (Mann-Whitney U + Welch's t-test):\")\n",
    "print(\"=\" * 100)\n",
    "display(statistical_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "81d26455-067f-4f22-8798-262aa08eb2fd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create dual-axis chart showing count differences and Welch's t-statistic\n",
    "\n",
    "# Check if statistical_results exists\n",
    "if 'statistical_results' not in globals():\n",
    "    print(\"Warning: 'statistical_results' not found.\")\n",
    "    print(\"   Please run the 'Hypothesis Testing' section cells first to create statistical_results.\")\n",
    "    print(\"   This visualization will be skipped.\")\n",
    "elif len(statistical_results) > 0 and 'welch_statistic' in statistical_results.columns:\n",
    "    # Calc normalized count differences\n",
    "    testdf_2 = statistical_results.copy()\n",
    "    testdf_2['count_difference'] = testdf_2['wonky_mean'] - testdf_2['non_wonky_mean']\n",
    "    testdf_2['count_difference_nrm'] = testdf_2['count_difference'] / (testdf_2['non_wonky_mean'].replace(0, np.nan))\n",
    "    \n",
    "    testdf_2 = testdf_2.set_index('metric')\n",
    "    \n",
    "    fig_dual = create_dual_axis_statistical_chart(\n",
    "        testdf_2,\n",
    "        count_diff_col='count_difference_nrm',\n",
    "        t_stat_col='welch_statistic',\n",
    "        title=\"Ave Wonky Count Difference & Welch's t-statistic by Feature\"\n",
    "    )\n",
    "    fig_dual.show()\n",
    "else:\n",
    "    print(\"Statistical results not available for dual-axis chart\")\n",
    "    if 'statistical_results' in globals():\n",
    "        print(f\"   statistical_results exists but is empty or missing 'welch_statistic' column\")\n",
    "        print(f\"   Available columns: {list(statistical_results.columns) if len(statistical_results) > 0 else 'N/A'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ce807f0f-35e7-433f-a73e-87bda6d637a4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Feature importance summary\n",
    "# Why: Ranks features by statistical significance, effect size, and test agreement\n",
    "# Helps prioritize which features to include in models\n",
    "# Note: Requires statistical_results to be created first (run the statistical tests cell before this one)\n",
    "\n",
    "if 'statistical_results' not in globals():\n",
    "    print(\"⚠️  Warning: 'statistical_results' not found.\")\n",
    "    print(\"   Please run the 'Hypothesis Testing' section cells first to create statistical_results.\")\n",
    "elif len(statistical_results) > 0:\n",
    "    # Create feature ranking\n",
    "    feature_ranking = statistical_results.copy()\n",
    "    \n",
    "    # Calculate composite score (combining significance and effect size)\n",
    "    if 'welch_statistic' in feature_ranking.columns:\n",
    "        # Use absolute t-statistic as effect size indicator\n",
    "        feature_ranking['effect_size'] = feature_ranking['welch_statistic'].abs()\n",
    "    else:\n",
    "        feature_ranking['effect_size'] = feature_ranking['mean_difference'].abs()\n",
    "    \n",
    "    # Create ranking score (lower p-value + higher effect size = better)\n",
    "    feature_ranking['ranking_score'] = (\n",
    "        (1 - feature_ranking['mw_p_value'].clip(0, 1)) * 0.5 +  # Significance component\n",
    "        (feature_ranking['effect_size'] / feature_ranking['effect_size'].max()) * 0.5  # Effect size component\n",
    "    )\n",
    "    \n",
    "    # Add test agreement indicator\n",
    "    if 'tests_agree' in feature_ranking.columns:\n",
    "        feature_ranking['both_tests_agree'] = feature_ranking['tests_agree']\n",
    "    else:\n",
    "        feature_ranking['both_tests_agree'] = True\n",
    "    \n",
    "    # Sort by ranking score\n",
    "    feature_ranking = feature_ranking.sort_values('ranking_score', ascending=False)\n",
    "    \n",
    "    # Select key columns for display\n",
    "    display_cols = ['metric', 'mean_difference', 'mw_p_value', 'welch_p_value']\n",
    "    if 'welch_statistic' in feature_ranking.columns:\n",
    "        display_cols.append('welch_statistic')\n",
    "    if 'both_tests_agree' in feature_ranking.columns:\n",
    "        display_cols.append('both_tests_agree')\n",
    "    display_cols.append('ranking_score')\n",
    "    \n",
    "    available_cols = [col for col in display_cols if col in feature_ranking.columns]\n",
    "    \n",
    "    print(\"Feature Ranking for Modeling (Top Features)\")\n",
    "    print(\"=\" * 100)\n",
    "    print(\"Ranked by: Statistical significance + Effect size\")\n",
    "    print(\"Higher ranking_score = better feature for modeling\")\n",
    "    print()\n",
    "    display(feature_ranking[available_cols].head(20))\n",
    "    \n",
    "    # Identify top features\n",
    "    top_features = feature_ranking.head(10)['metric'].tolist()\n",
    "    print(f\"\\nTop 10 Features Recommended for Modeling:\")\n",
    "    for i, feat in enumerate(top_features, 1):\n",
    "        print(f\"  {i}. {feat}\")\n",
    "else:\n",
    "    print(\"Statistical results not available for feature ranking\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d1ad1333-68b3-42f9-9c7f-5434af9e2c3a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Analyze test agreement\n",
    "# Note: Requires statistical_results to be created first (run the statistical tests cell before this one)\n",
    "\n",
    "if 'statistical_results' not in globals():\n",
    "    print(\"⚠️  Warning: 'statistical_results' not found.\")\n",
    "    print(\"   Please run the 'Hypothesis Testing' section cells first to create statistical_results.\")\n",
    "elif 'tests_agree' in statistical_results.columns:\n",
    "    agreement_stats = statistical_results['tests_agree'].value_counts()\n",
    "    print(\"Test Agreement Analysis:\")\n",
    "    print(f\"Metrics where tests agree: {agreement_stats.get(True, 0)}\")\n",
    "    print(f\"Metrics where tests disagree: {agreement_stats.get(False, 0)}\")\n",
    "    \n",
    "    # Show metrics where tests disagree\n",
    "    disagree = statistical_results[statistical_results['tests_agree'] == False]\n",
    "    if len(disagree) > 0:\n",
    "        print(\"\\nMetrics where tests disagree (need investigation):\")\n",
    "        display(disagree[['metric', 'mw_p_value', 'welch_p_value', 'mw_significant', 'welch_significant']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "efdf385d-5be8-4899-ab0f-f0fd82844641",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Analyze thresholds for key features\n",
    "print(\"Threshold Analysis: Task Volume\")\n",
    "print(\"=\" * 80)\n",
    "volume_thresholds = analyze_thresholds(\n",
    "    respondent_features,\n",
    "    feature='total_tasks',\n",
    "    bins=stats_config['threshold_analysis']['default_bins'],\n",
    "    target_col='has_wonky_tasks'\n",
    ")\n",
    "display(volume_thresholds)\n",
    "\n",
    "print(\"\\nThreshold Analysis: Suspicious Fast Rate\")\n",
    "print(\"=\" * 80)\n",
    "speed_thresholds = analyze_thresholds(\n",
    "    respondent_features,\n",
    "    feature='suspicious_fast_rate',\n",
    "    bins=stats_config['threshold_analysis']['default_bins'],\n",
    "    target_col='has_wonky_tasks'\n",
    ")\n",
    "display(speed_thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0b74a098-f760-43ae-9169-7bb54e2f3216",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Example visualizations using modular functions\n",
    "\n",
    "# Histogram of fraud risk score\n",
    "fig_fraud_risk = create_histogram(\n",
    "    respondent_features,\n",
    "    x='fraud_risk_score',\n",
    "    color='fraud_risk_tier',\n",
    "    nbins=11,\n",
    "    title='Fraud Risk Score Distribution',\n",
    "    labels={'fraud_risk_score': 'Fraud Risk Score (0-10)'}\n",
    ")\n",
    "fig_fraud_risk.show()\n",
    "\n",
    "# Box plot comparing wonky vs non-wonky users\n",
    "fig_speed = create_box_plot(\n",
    "    respondent_features,\n",
    "    x='has_wonky_tasks',\n",
    "    y='avg_task_time',\n",
    "    color='has_wonky_tasks',\n",
    "    title='Average Task Time: Wonky vs Non-Wonky Users',\n",
    "    labels={'has_wonky_tasks': 'Has Wonky Tasks (1=Yes, 0=No)', 'avg_task_time': 'Average Task Time (seconds)'},\n",
    "    category_orders={'has_wonky_tasks': [0, 1]},\n",
    "    boxmean='sd'\n",
    ")\n",
    "fig_speed.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fff57faa-c32f-4ce9-a388-d54e04f07247",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Summary\n",
    "\n",
    "**Key Findings:**\n",
    "- Statistical tests (Mann-Whitney U + Welch's t-test) identify significant differences between wonky and non-wonky users\n",
    "- Temporal features show strong associations with wonky study participation (chi-squared tests)\n",
    "- Feature engineering creates actionable behavioral indicators (task speed, volume, velocity)\n",
    "- Demographic groups (platforms, hardware, locales) show varying wonky task rates\n",
    "- Both statistical tests provide validation - agreement increases confidence in findings\n",
    "- Visualizations highlight features with strongest discrimination power\n",
    "\n",
    "**Feature Selection Insights:**\n",
    "- Top-ranked features combine statistical significance with practical effect sizes\n",
    "- Temporal patterns (business hours, night tasks) are strong discriminators\n",
    "- Behavioral features (task volume, speed) show consistent differences\n",
    "- Demographic features may be useful as interaction terms\n",
    "\n",
    "**Next Steps:**\n",
    "- Use top-ranked features from feature ranking for model training\n",
    "- Include temporal features that show significant chi-squared associations\n",
    "- Consider demographic interactions based on group comparison results\n",
    "- Apply fraud risk thresholds to filter suspicious users\n",
    "- Build models using features identified as significant in EDA\n",
    "- Validate feature importance using model-based methods (Random Forest feature importance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ec763b35-0e7f-4c22-99b0-30642a498194",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "respondent_eda_refactored",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "ds-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
