{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a5d6590e-0203-4cf4-9a08-c41386641223",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "!pip install shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "208d2215-c24b-4a29-a832-53969d83cc23",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": "import pprint\nimport yaml\nimport sys\nimport os\nsys.path.append(os.path.join(os.path.dirname(os.getcwd()), 'src'))\n\nimport numpy as np\nimport pandas as pd\n\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\nfrom sklearn.preprocessing import StandardScaler\n\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n\nfrom modelling.modelling import (\n    build_linear_baseline,\n    build_logistic_regression_model,\n    build_random_forest_model,\n    build_ensemble_random_forest,\n    run_all_models,\n    create_user_level_train_test_split,\n    evaluate_on_holdout,\n    EnsembleRandomForest,\n)\n\nfrom modelling.modelling_utils import (\n    remove_collinear_features,\n    calculate_vif_detailed,\n    run_shap_analysis,\n    analyze_feature_interactions,\n    create_stakeholder_report,\n    create_model_scorecard,\n    analyze_logistic_calibration,\n    generate_modelling_executive_summary,\n    print_model_summary,\n    get_significant_features,\n    export_results,\n    plot_shap_summary,\n    plot_shap_bar,\n    plot_shap_dependence,\n)\n\n# Load configs\nwith open('../configs/statistical_tests.yaml', 'r') as f:\n    stats_config = yaml.safe_load(f)\n\nwith open('../configs/data_paths.yaml', 'r') as f:\n    paths_config = yaml.safe_load(f)\n\npd.set_option('display.max_columns', None)\nprint(\"‚úì Imports and configs loaded successfully\")"
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "72a8e1ea-438f-4c00-87a3-340c6fe9e07c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Loading user level dataframe\n",
    "notebook_path = os.getcwd()\n",
    "repo_root = os.path.abspath(os.path.join(notebook_path, \"..\"))\n",
    "misc_dir = os.path.join(repo_root, \"misc\")\n",
    "\n",
    "user_df_input_path = os.path.join(misc_dir,\n",
    "                           os.path.basename(paths_config['output_files']['user_info_df_post_eda']))\n",
    "\n",
    "test_results_df_input_path = os.path.join(misc_dir,\n",
    "                           os.path.basename(paths_config['output_files']['test_results_df']))\n",
    "\n",
    "user_info_df = pd.read_parquet(user_df_input_path)\n",
    "test_results_df = pd.read_parquet(test_results_df_input_path)\n",
    "\n",
    "user_info_df = user_info_df[~user_info_df['wonky_study_count'].isna()]\n",
    "print(f\"‚úì Data loaded: {user_info_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5800f82b-116e-427a-8255-49c0341318be",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "user_info_df = user_info_df[~user_info_df['wonky_study_count'].isna()]\n",
    "user_info_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "09cc26ec-906e-4c86-a037-bbbf902122ef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Stage 1 - VIF & Correlation checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6b000020-188f-4983-adef-641713285fe1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "test_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8fb8e3ef-16fc-48c8-81b1-1c6b15f2f419",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "significant_features = test_results_df['feature'].tolist()\n",
    "significant_features = [item for item in significant_features if 'is_weekend' not in item]\n",
    "\n",
    "print(f\"Significant features from testing: {len(significant_features)}\")\n",
    "pprint.pprint(significant_features)"
   ]
  },
  {
   "cell_type": "code",
   "source": "# VIF Analysis - Identify multicollinearity risk for ALL features\nvif_df = calculate_vif_detailed(\n    df=user_info_df,\n    feature_cols=significant_features,\n    vif_threshold_high=10.0,\n    vif_threshold_moderate=5.0,\n)\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"VIF ANALYSIS - ALL FEATURES BY MULTICOLLINEARITY RISK\")\nprint(\"=\"*80)\nprint(\"\"\"\nVIF Interpretation:\n  - VIF = 1:    No correlation with other features\n  - VIF < 5:    Low correlation (acceptable)\n  - VIF 5-10:   Moderate correlation (monitor)\n  - VIF > 10:   High correlation (consider removal)\n  - VIF = inf:  Perfect multicollinearity (must remove)\n\"\"\")\ndisplay(vif_df[['feature', 'VIF', 'vif_flag', 'recommendation']])",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Visualize correlation between high-VIF (colinear) features\nhigh_vif_features = vif_df[vif_df['VIF'] >= 5]['feature'].tolist()\n\nif len(high_vif_features) >= 2:\n    print(f\"Plotting correlation matrix for {len(high_vif_features)} features with VIF >= 5\")\n    \n    # Correlation heatmap of high-VIF features\n    corr_matrix = user_info_df[high_vif_features].corr()\n\n    fig = px.imshow(\n        corr_matrix,\n        text_auto='.2f',\n        color_continuous_scale='RdBu_r',\n        title='Correlation Matrix: High VIF Features (VIF >= 5)',\n        aspect='auto',\n    )\n    fig.update_layout(\n        width=800,\n        height=800,\n    )\n    fig.show()\nelif len(high_vif_features) == 1:\n    print(f\"Only 1 feature with high VIF: {high_vif_features[0]}\")\n    print(\"Cannot create correlation matrix with single feature\")\nelse:\n    print(\"No highly colinear features found (all VIF < 5) - no correlation chart needed\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# OPTIONAL: Drop features with high multicollinearity\n# Uncomment and modify the list below to exclude features before modelling\n\n# features_to_drop = [\n#     # Add feature names to drop here based on VIF analysis above, e.g.:\n#     # 'is_weekend',\n#     # 'is_business_hour',\n# ]\n\n# # Uncomment to apply the feature dropping:\n# significant_features = [f for f in significant_features if f not in features_to_drop]\n# print(f\"Dropped {len(features_to_drop)} features: {features_to_drop}\")\n# print(f\"Remaining features: {len(significant_features)}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8538a319-7a57-40f0-90a4-6618a3b4f2e4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": "# Run Random Forest + Logistic Regression (without Linear Regression due to multicollinearity)\n# Clean features first\ncleaned_features = remove_collinear_features(significant_features)\n\n# Build Random Forest\nrf_model, rf_importance, rf_cv_results = build_random_forest_model(\n    df=user_info_df,\n    feature_cols=cleaned_features,\n    outcome_var=\"wonky_study_count\",\n    user_id_var=\"respondentPk\",\n    n_estimators=100,\n)\n\n# Build Logistic Regression with stronger Ridge (L2) regularization\n# C=0.1 provides 10x stronger regularization than default (C=1.0)\n# This helps stabilize coefficients when features are correlated\nlr_model, lr_importance, lr_cv_results = build_logistic_regression_model(\n    df=user_info_df,\n    feature_cols=cleaned_features,\n    outcome_var=\"wonky_study_count\",\n    user_id_var=\"respondentPk\",\n    regularization_C=0.1,  # Stronger Ridge penalty for multicollinearity\n)\n\n# Create results dict for compatibility with downstream cells\nresults = {\n    'rf_model': rf_model,\n    'rf_importance': rf_importance,\n    'rf_cv_results': rf_cv_results,\n    'lr_model': lr_model,\n    'lr_importance': lr_importance,\n    'lr_cv_results': lr_cv_results,\n    'vif_data': vif_df,\n    'feature_cols': cleaned_features,\n}\n\n# Create comparison table (RF + LR only)\ncomparison = rf_importance.merge(\n    lr_importance[['feature', 'lr_coefficient', 'lr_odds_ratio', 'lr_p_value', 'lr_significant']],\n    on='feature',\n    how='outer'\n)\ncomparison = comparison.merge(vif_df[['feature', 'VIF']], on='feature', how='left')\n\n# Add rankings\ncomparison['rf_rank'] = comparison['rf_importance'].rank(ascending=False)\ncomparison['lr_rank'] = comparison['lr_coefficient'].abs().rank(ascending=False)\ncomparison['avg_rank'] = (comparison['rf_rank'] + comparison['lr_rank']) / 2\n\nresults['comparison'] = comparison.sort_values('avg_rank')\n\nprint(f\"Models built with {len(cleaned_features)} features\")\nprint(f\"  - Random Forest CV R2: {rf_cv_results['cv_r2_mean']:.3f} (+/- {rf_cv_results['cv_r2_std']:.3f})\")\nprint(f\"  - Logistic Regression CV AUC: {lr_cv_results['cv_auc_mean']:.3f} (+/- {lr_cv_results['cv_auc_std']:.3f})\")"
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cf7eb54a-04ff-42b3-8b06-a43721a90d1a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "results = run_shap_analysis(\n",
    "    results=results,\n",
    "    df=user_info_df,\n",
    "    sample_size=1000,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "06fb1b65-c9f7-497c-b217-84d3b0b5490d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Model Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ce41b5d7-2f51-4ee7-bbc7-a7248a217bb0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "if 'lr_importance' in results:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üéØ LOGISTIC REGRESSION - ODDS RATIOS\")\n",
    "    print(\"=\"*80)\n",
    "    print(\"\"\"\n",
    "Odds Ratio Interpretation:\n",
    "  ‚Ä¢ OR = 1.0:  No effect\n",
    "  ‚Ä¢ OR = 1.5:  50% more likely to be wonky when feature=1\n",
    "  ‚Ä¢ OR = 2.0:  2x more likely (100% increase)\n",
    "  ‚Ä¢ OR = 0.5:  50% less likely (half the odds)\n",
    "\"\"\")\n",
    "    \n",
    "    lr_df = results['lr_importance'].copy()\n",
    "    \n",
    "    # Add interpretation\n",
    "    def interpret_or(x):\n",
    "        if pd.isna(x) or x <= 0 or x > 100 or x < 0.01:\n",
    "            return \"‚ö†Ô∏è Extreme\"\n",
    "        if abs(x - 1) < 0.05:\n",
    "            return \"No effect\"\n",
    "        if x > 1:\n",
    "            pct = (x - 1) * 100\n",
    "            return f\"‚Üë {pct:.0f}% more likely\" if pct <= 100 else f\"‚Üë {x:.1f}x\"\n",
    "        else:\n",
    "            return f\"‚Üì {(1-x)*100:.0f}% less likely\"\n",
    "    \n",
    "    lr_df['interpretation'] = lr_df['lr_odds_ratio'].apply(interpret_or)\n",
    "    \n",
    "    # Filter valid odds ratios\n",
    "    valid_lr = lr_df[(lr_df['lr_odds_ratio'] >= 0.01) & (lr_df['lr_odds_ratio'] <= 100)]\n",
    "    \n",
    "    display(valid_lr.head(20)[['feature', 'lr_coefficient', 'lr_odds_ratio', \n",
    "                               'interpretation', 'lr_p_value']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "69ebc8db-f6cb-4ced-a409-baa71588d115",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üå≤ RANDOM FOREST IMPORTANCE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "rf_df = results['rf_importance'].copy()\n",
    "display(rf_df.head(20)[['feature', 'rf_importance', 'rf_importance_pct']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2c75ee02-7c6b-4d46-b280-fdf1f10d6fb2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "if 'shap_importance' in results:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üîÆ SHAP FEATURE IMPORTANCE\")\n",
    "    print(\"=\"*80)\n",
    "    print(\"\"\"\n",
    "SHAP shows HOW features affect predictions:\n",
    "  ‚Ä¢ shap_importance: How much the feature matters\n",
    "  ‚Ä¢ shap_mean: Direction (+ increases wonky, - decreases)\n",
    "  ‚Ä¢ shap_direction: Plain English interpretation\n",
    "\"\"\")\n",
    "    \n",
    "    shap_df = results['shap_importance'].copy()\n",
    "    display(shap_df.head(20)[['feature', 'shap_importance', 'shap_mean', 'shap_direction']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f03ef07a-5676-400f-8311-9e81300cecbb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Beeswarm plot - shows direction and distribution\n",
    "plot_shap_summary(results, max_display=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "84284a27-b070-4543-bdd2-ddd9c1f8b6d9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "plot_shap_bar(results, max_display=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b9b962ea-a736-4ece-86c5-6ea7ae36d4ee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# # to explore specific features using shap\n",
    "\n",
    "# # How does is_saturday affect predictions?\n",
    "# plot_shap_dependence(results, 'is_saturday')\n",
    "\n",
    "# # With interaction coloring\n",
    "# plot_shap_dependence(results, 'is_saturday', interaction_feature='is_early_morning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "34092118-0410-42ac-b88f-4ba23c0349c4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üîç MULTICOLLINEARITY CHECK (VIF)\")\n",
    "print(\"=\"*80)\n",
    "print(\"\"\"\n",
    "VIF Interpretation:\n",
    "  ‚Ä¢ VIF < 5:  ‚úì No concern\n",
    "  ‚Ä¢ VIF 5-10: ‚ö° Moderate\n",
    "  ‚Ä¢ VIF > 10: ‚ö†Ô∏è High - consider removing\n",
    "\"\"\")\n",
    "\n",
    "vif_df = results['vif_data'].copy()\n",
    "vif_df['status'] = vif_df['VIF'].apply(\n",
    "    lambda x: '‚úì OK' if x < 5 else ('‚ö° Moderate' if x < 10 else '‚ö†Ô∏è HIGH')\n",
    ")\n",
    "\n",
    "high_vif = vif_df[vif_df['VIF'] >= 5]\n",
    "if len(high_vif) > 0:\n",
    "    print(f\"Features with VIF >= 5:\")\n",
    "    display(high_vif[['feature', 'VIF', 'status']])\n",
    "else:\n",
    "    print(\"‚úì All features have VIF < 5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e0fe930c-f0b8-45a2-90a0-005fcb5c1520",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìã STAKEHOLDER REPORT\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "stakeholder_report = create_stakeholder_report(results)\n",
    "display(stakeholder_report.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e0083687-0fc8-41b4-9b44-42d87744e821",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": "print(\"\\n\" + \"=\"*80)\nprint(\"KEY INSIGHTS\")\nprint(\"=\"*80)\n\n# Top consensus features (based on RF + Logistic Regression)\nprint(\"\\nTOP 5 CONSENSUS FEATURES (RF + LR):\")\nfor i, (_, row) in enumerate(results['comparison'].head(5).iterrows(), 1):\n    print(f\"\\n{i}. {row['feature']}\")\n    print(f\"   RF importance: {row['rf_importance_pct']:.2f}%\")\n    if 'lr_odds_ratio' in row and pd.notna(row['lr_odds_ratio']):\n        print(f\"   Odds Ratio: {row['lr_odds_ratio']:.3f}\")\n    if 'lr_p_value' in row and pd.notna(row['lr_p_value']):\n        print(f\"   LR p-value: {row['lr_p_value']:.4e}\")\n    if 'shap_direction' in row and pd.notna(row.get('shap_direction')):\n        print(f\"   SHAP: {row['shap_direction']}\")\n\n# Features that increase vs decrease wonky\nif 'shap_importance' in results:\n    shap_df = results['shap_importance']\n    \n    increases = shap_df[shap_df['shap_mean'] > 0.001].head(5)\n    decreases = shap_df[shap_df['shap_mean'] < -0.001].head(5)\n    \n    print(\"\\nFEATURES THAT INCREASE WONKY:\")\n    for _, row in increases.iterrows():\n        print(f\"   {row['feature']}: +{row['shap_mean']:.4f}\")\n    \n    print(\"\\nFEATURES THAT DECREASE WONKY:\")\n    for _, row in decreases.iterrows():\n        print(f\"   {row['feature']}: {row['shap_mean']:.4f}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "99dcc917-e8a8-41c2-9d1f-f589d8f0b24f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": "print(\"\\n\" + \"=\"*80)\nprint(\"HIGH-CONFIDENCE FEATURES\")\nprint(\"=\"*80)\n\n# Features with high RF importance and significant in logistic regression\nhigh_rf = set(results['rf_importance'][results['rf_importance']['rf_importance'] >= 0.01]['feature'].tolist())\nsig_lr = set(results['lr_importance'][results['lr_importance']['lr_p_value'] < 0.05]['feature'].tolist())\nhigh_confidence = high_rf.intersection(sig_lr)\n\nprint(f\"\\nFeatures with high RF importance + significant LR (p<0.05): {len(high_confidence)}\")\nfor f in sorted(high_confidence):\n    print(f\"  - {f}\")"
  },
  {
   "cell_type": "markdown",
   "source": "#### Model Quality Assessment\n\nCompare all models with a unified scorecard and calibration analysis.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Model Scorecard - compare all models at a glance\nscorecard = create_model_scorecard(results)\ndisplay(scorecard)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Logistic Regression Calibration Analysis\n# Check if predicted probabilities match actual frequencies\ncalibration_df, calibration_fig = analyze_logistic_calibration(\n    results=results,\n    df=user_info_df,\n    n_bins=10,\n)\n\nif calibration_fig is not None:\n    calibration_fig.show()\n    \ndisplay(calibration_df)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "#### Feature Interactions\n\nAnalyze how pairs of features work together to affect predictions.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Feature Interaction Analysis (can be slow - uses SHAP interaction values)\n# Uncomment to run:\n# interactions_df = analyze_feature_interactions(\n#     results=results,\n#     df=user_info_df,\n#     top_n=10,\n#     sample_size=500,\n# )\n# display(interactions_df)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "#### Executive Summary\n\nComprehensive summary of modelling results for stakeholders.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Generate Executive Summary for Stakeholders\nexecutive_summary = generate_modelling_executive_summary(\n    results=results,\n    outcome_description=\"wonkiness\",\n)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f452d88b-1403-492c-9315-e69a202106a0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üíæ EXPORT\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Export to CSV\n",
    "export_df = export_results(results, 'feature_importance_results.csv')\n",
    "\n",
    "# Also save as parquet for downstream use\n",
    "results['comparison'].to_parquet('modelling_comparison.parquet', index=False)\n",
    "print(\"‚úì Results saved to modelling_comparison.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "135ef453-424b-481f-935a-35dd427f27af",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": "# Interactive Plotly chart comparing RF importance vs LR Odds Ratios\n\ncomparison_df = results['comparison'].head(20).copy()\n\nfig = go.Figure()\n\n# RF importance\nfig.add_trace(go.Bar(\n    x=comparison_df['rf_importance_pct'],\n    y=comparison_df['feature'],\n    orientation='h',\n    name='RF Importance (%)',\n    marker=dict(color='#ff7f0e'),\n))\n\n# LR Odds Ratio (log scale for visualization, centered at 1)\n# Convert OR to log scale so OR=0.5 and OR=2 are equidistant from OR=1\ncomparison_df['lr_or_log'] = np.log(comparison_df['lr_odds_ratio'].clip(lower=0.01, upper=100))\nor_scale = comparison_df['rf_importance_pct'].max() / comparison_df['lr_or_log'].abs().max()\n\nfig.add_trace(go.Bar(\n    x=comparison_df['lr_or_log'] * or_scale,\n    y=comparison_df['feature'],\n    orientation='h',\n    name='LR log(Odds Ratio) (scaled)',\n    marker=dict(color='#2ca02c'),\n))\n\nfig.update_layout(\n    title=\"Top 20 Features: RF Importance vs LR Odds Ratios\",\n    xaxis_title='Value (RF: %, LR: scaled log OR)',\n    yaxis_title='Feature',\n    barmode='group',\n    yaxis=dict(autorange='reversed'),\n    height=600,\n    margin=dict(l=200),\n)\n\nfig.show()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc3b2246-b4df-44a0-897d-d858b225de87",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": "# The 'results' dictionary contains everything:\n# - results['rf_model']: Random Forest model  \n# - results['lr_model']: Logistic Regression model\n# - results['rf_importance']: RF feature importance DataFrame\n# - results['lr_importance']: LR coefficients and odds ratios DataFrame\n# - results['vif_data']: VIF analysis DataFrame\n# - results['comparison']: Unified comparison table (RF + LR)\n# - results['shap_values']: SHAP values array\n# - results['shap_explainer']: SHAP explainer object"
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "respondent_modelling - WIP v2",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}