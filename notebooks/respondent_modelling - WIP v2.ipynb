{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a5d6590e-0203-4cf4-9a08-c41386641223",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "!pip install shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "208d2215-c24b-4a29-a832-53969d83cc23",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pprint\n",
    "import yaml\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.join(os.path.dirname(os.getcwd()), 'src'))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from modelling.modelling import (\n",
    "    build_linear_baseline,\n",
    "    build_logistic_regression_model,\n",
    "    build_random_forest_model,\n",
    "    run_all_models,\n",
    ")\n",
    "\n",
    "from modelling.modelling_utils import (\n",
    "    remove_collinear_features,\n",
    "    run_shap_analysis,\n",
    "    create_stakeholder_report,\n",
    "    print_model_summary,\n",
    "    get_significant_features,\n",
    "    export_results,\n",
    "    plot_shap_summary,\n",
    "    plot_shap_bar,\n",
    "    plot_shap_dependence,\n",
    ")\n",
    "\n",
    "# Load configs\n",
    "with open('../configs/statistical_tests.yaml', 'r') as f:\n",
    "    stats_config = yaml.safe_load(f)\n",
    "\n",
    "with open('../configs/data_paths.yaml', 'r') as f:\n",
    "    paths_config = yaml.safe_load(f)\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "print(\"‚úì Imports and configs loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "72a8e1ea-438f-4c00-87a3-340c6fe9e07c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Loading user level dataframe\n",
    "notebook_path = os.getcwd()\n",
    "repo_root = os.path.abspath(os.path.join(notebook_path, \"..\"))\n",
    "misc_dir = os.path.join(repo_root, \"misc\")\n",
    "\n",
    "user_df_input_path = os.path.join(misc_dir,\n",
    "                           os.path.basename(paths_config['output_files']['user_info_df_post_eda']))\n",
    "\n",
    "test_results_df_input_path = os.path.join(misc_dir,\n",
    "                           os.path.basename(paths_config['output_files']['test_results_df']))\n",
    "\n",
    "user_info_df = pd.read_parquet(user_df_input_path)\n",
    "test_results_df = pd.read_parquet(test_results_df_input_path)\n",
    "\n",
    "user_info_df = user_info_df[~user_info_df['wonky_study_count'].isna()]\n",
    "print(f\"‚úì Data loaded: {user_info_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5800f82b-116e-427a-8255-49c0341318be",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "user_info_df = user_info_df[~user_info_df['wonky_study_count'].isna()]\n",
    "user_info_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "09cc26ec-906e-4c86-a037-bbbf902122ef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Stage 1 - VIF & Correlation checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6b000020-188f-4983-adef-641713285fe1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "test_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "25800751-335e-4c96-b213-abc5cfd1ed8b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# significant_features = test_results_df[test_results_df['significant_both']]['feature'].tolist()\n",
    "# significant_features = [item for item in significant_features if 'is_weekend' not in item]\n",
    "# significant_features = significant_features + ['risk', 'quality']\n",
    "\n",
    "# print(f\"Significant features from testing: {len(significant_features)}\")\n",
    "# pprint.pprint(significant_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8fb8e3ef-16fc-48c8-81b1-1c6b15f2f419",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "significant_features = test_results_df['feature'].tolist()\n",
    "significant_features = [item for item in significant_features if 'is_weekend' not in item]\n",
    "\n",
    "print(f\"Significant features from testing: {len(significant_features)}\")\n",
    "pprint.pprint(significant_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d374c0bf-2426-4a55-b66f-9c78853f5445",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "significcant_features_to_remove = [\n",
    "  # 'share_location_data_False',\n",
    "  # 'email_verified_False',\n",
    "  # 'is_6am',\n",
    "  # 'is_business_hour',\n",
    "  # 'is_business_hour_weekend',\n",
    "  # 'is_business_hour_weekend',\n",
    "  # 'is_weekend',\n",
    "  # 'is_early_morning',\n",
    "  # 'is_morning',\n",
    "  # 'is_night', \n",
    "  # 'is_afternoon',\n",
    "  # 'is_evening',\n",
    "  # 'risk_round10_100',\n",
    "  # 'risk_round10_70',\n",
    "  # 'risk_round10_0',\n",
    "  # 'quality_round10_100',\n",
    "  # 'quality_round10_70',\n",
    "  # 'quality_round10_0',\n",
    "  # 'days_active_11_to_20',\n",
    "  # 'days_active_76_to_100',\n",
    "  # 'days_active_151_to_200',\n",
    "  # 'days_active_101_to_125',\n",
    "  # 'days_active_51_to_75',\n",
    "  # 'days_active_21_to_30',\n",
    "  # 'days_active_0_to_2',\n",
    "  # 'days_active_3_to_10',\n",
    "  # 'days_active_126_to_150',\n",
    "  # 'days_active_before_task',\n",
    "  # 'days_active_201_to_250',\n",
    "  # 'days_active_31_to_50',\n",
    "  # 'days_active_251_plus',\n",
    "  # 'total_tasks_126_175',\n",
    "  # 'total_tasks_26_75',\n",
    "  # 'total_tasks_11_25',\n",
    "  # 'total_tasks_176_225',\n",
    "  # 'total_tasks_226_plus',\n",
    "  # 'total_tasks_1_10',\n",
    "  # 'total_tasks_76_125',\n",
    "  # 'ditr_os_ios',\n",
    "  # 'is_monday',\n",
    "  # 'hardware_category_unknown',\n",
    "  # 'manufacturer_category_unknown',\n",
    "  # 'is_fast'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d0516ca8-005c-48c4-b2f8-50b27d8298c7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "significant_features = [feature for feature in significant_features if feature not in significcant_features_to_remove]\n",
    "\n",
    "pprint.pprint(significant_features)\n",
    "print(\"--\"*50)\n",
    "print(\"  \"*50)\n",
    "print(\"--\"*50)\n",
    "print(f\"Number of significant features after removing collinear features:{len(significant_features)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "286bb115-63ff-486b-bfd1-3fbfaac6cec8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# STEP 1: Calculate VIF for all features\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"üîç VIF MULTICOLLINEARITY ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "X = user_info_df[significant_features].copy()\n",
    "X_clean = X.dropna()\n",
    "\n",
    "print(f\"\\nFeatures: {len(significant_features)}\")\n",
    "print(f\"Observations: {len(X_clean)} (dropped {len(X) - len(X_clean)} with NaN)\")\n",
    "\n",
    "# Calculate VIF\n",
    "vif_results = []\n",
    "for i, col in enumerate(significant_features):\n",
    "    try:\n",
    "        vif_value = variance_inflation_factor(X_clean.values, i)\n",
    "    except Exception as e:\n",
    "        vif_value = np.inf\n",
    "    vif_results.append({'feature': col, 'VIF': vif_value})\n",
    "\n",
    "vif_df = pd.DataFrame(vif_results)\n",
    "\n",
    "# Add flags\n",
    "def get_flag(vif):\n",
    "    if np.isinf(vif):\n",
    "        return 'üö® INFINITE'\n",
    "    elif vif > 10:\n",
    "        return '‚ö†Ô∏è HIGH'\n",
    "    elif vif > 5:\n",
    "        return '‚ö° MODERATE'\n",
    "    else:\n",
    "        return '‚úì OK'\n",
    "\n",
    "vif_df['flag'] = vif_df['VIF'].apply(get_flag)\n",
    "vif_df = vif_df.sort_values('VIF', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b3ed242f-57d4-4d33-93ed-bd9348e41b69",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# STEP 2: Summary and flagged features\n",
    "\n",
    "n_infinite = np.isinf(vif_df['VIF']).sum()\n",
    "n_high = ((vif_df['VIF'] > 10) & ~np.isinf(vif_df['VIF'])).sum()\n",
    "n_moderate = ((vif_df['VIF'] > 5) & (vif_df['VIF'] <= 10)).sum()\n",
    "n_ok = (vif_df['VIF'] <= 5).sum()\n",
    "\n",
    "print(f\"\\nüìä VIF Summary:\")\n",
    "print(f\"   üö® Infinite (perfect multicollinearity): {n_infinite}\")\n",
    "print(f\"   ‚ö†Ô∏è  High (VIF > 10):                      {n_high}\")\n",
    "print(f\"   ‚ö° Moderate (VIF 5-10):                   {n_moderate}\")\n",
    "print(f\"   ‚úì  OK (VIF ‚â§ 5):                          {n_ok}\")\n",
    "\n",
    "# Show problematic features\n",
    "print(\"\\n\" + \"-\"*60)\n",
    "print(\"FEATURES TO REVIEW:\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "if n_infinite > 0:\n",
    "    print(\"\\nüö® INFINITE VIF (must remove one from each correlated group):\")\n",
    "    display(vif_df[np.isinf(vif_df['VIF'])][['feature', 'VIF', 'flag']])\n",
    "\n",
    "if n_high > 0:\n",
    "    print(\"\\n‚ö†Ô∏è  HIGH VIF (consider removing):\")\n",
    "    display(vif_df[(vif_df['VIF'] > 10) & ~np.isinf(vif_df['VIF'])][['feature', 'VIF', 'flag']])\n",
    "\n",
    "if n_moderate > 0:\n",
    "    print(\"\\n‚ö° MODERATE VIF (monitor, usually OK to keep):\")\n",
    "    display(vif_df[(vif_df['VIF'] > 5) & (vif_df['VIF'] <= 10)][['feature', 'VIF', 'flag']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5de8e03e-9ee4-4ef4-882a-2db5bcc8d53d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Stage 2 Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8538a319-7a57-40f0-90a4-6618a3b4f2e4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "results = run_all_models(\n",
    "    df=user_info_df,\n",
    "    feature_cols=significant_features,\n",
    "    outcome_var=\"wonky_study_count\",\n",
    "    user_id_var=\"respondentPk\",\n",
    "    include_logistic=True,\n",
    "    include_vif=True,\n",
    "    rf_n_estimators=100,\n",
    "    lr_regularization_C=1.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cf7eb54a-04ff-42b3-8b06-a43721a90d1a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "results = run_shap_analysis(\n",
    "    results=results,\n",
    "    df=user_info_df,\n",
    "    sample_size=1000,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "06fb1b65-c9f7-497c-b217-84d3b0b5490d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Model Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d83d5ff2-e306-4937-a02f-fd7273e16292",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìà LINEAR REGRESSION RESULTS\")\n",
    "print(\"=\"*80)\n",
    "print(\"Interpretation: Coefficient = change in wonky_study_count when feature=1 vs 0\")\n",
    "print(\"Stars: *** p<0.001, ** p<0.01, * p<0.05\\n\")\n",
    "\n",
    "linear_df = results['linear_importance'].copy()\n",
    "linear_df['sig'] = linear_df['p_value'].apply(\n",
    "    lambda x: '***' if x < 0.001 else ('**' if x < 0.01 else ('*' if x < 0.05 else ''))\n",
    ")\n",
    "linear_df['coef_display'] = linear_df.apply(\n",
    "    lambda row: f\"{row['coefficient']:+.4f}{row['sig']}\", axis=1\n",
    ")\n",
    "\n",
    "display(linear_df.head(20)[['feature', 'coef_display', 'p_value', 'importance']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ce41b5d7-2f51-4ee7-bbc7-a7248a217bb0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "if 'lr_importance' in results:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üéØ LOGISTIC REGRESSION - ODDS RATIOS\")\n",
    "    print(\"=\"*80)\n",
    "    print(\"\"\"\n",
    "Odds Ratio Interpretation:\n",
    "  ‚Ä¢ OR = 1.0:  No effect\n",
    "  ‚Ä¢ OR = 1.5:  50% more likely to be wonky when feature=1\n",
    "  ‚Ä¢ OR = 2.0:  2x more likely (100% increase)\n",
    "  ‚Ä¢ OR = 0.5:  50% less likely (half the odds)\n",
    "\"\"\")\n",
    "    \n",
    "    lr_df = results['lr_importance'].copy()\n",
    "    \n",
    "    # Add interpretation\n",
    "    def interpret_or(x):\n",
    "        if pd.isna(x) or x <= 0 or x > 100 or x < 0.01:\n",
    "            return \"‚ö†Ô∏è Extreme\"\n",
    "        if abs(x - 1) < 0.05:\n",
    "            return \"No effect\"\n",
    "        if x > 1:\n",
    "            pct = (x - 1) * 100\n",
    "            return f\"‚Üë {pct:.0f}% more likely\" if pct <= 100 else f\"‚Üë {x:.1f}x\"\n",
    "        else:\n",
    "            return f\"‚Üì {(1-x)*100:.0f}% less likely\"\n",
    "    \n",
    "    lr_df['interpretation'] = lr_df['lr_odds_ratio'].apply(interpret_or)\n",
    "    \n",
    "    # Filter valid odds ratios\n",
    "    valid_lr = lr_df[(lr_df['lr_odds_ratio'] >= 0.01) & (lr_df['lr_odds_ratio'] <= 100)]\n",
    "    \n",
    "    display(valid_lr.head(20)[['feature', 'lr_coefficient', 'lr_odds_ratio', \n",
    "                               'interpretation', 'lr_p_value']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "69ebc8db-f6cb-4ced-a409-baa71588d115",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üå≤ RANDOM FOREST IMPORTANCE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "rf_df = results['rf_importance'].copy()\n",
    "display(rf_df.head(20)[['feature', 'rf_importance', 'rf_importance_pct']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2c75ee02-7c6b-4d46-b280-fdf1f10d6fb2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "if 'shap_importance' in results:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üîÆ SHAP FEATURE IMPORTANCE\")\n",
    "    print(\"=\"*80)\n",
    "    print(\"\"\"\n",
    "SHAP shows HOW features affect predictions:\n",
    "  ‚Ä¢ shap_importance: How much the feature matters\n",
    "  ‚Ä¢ shap_mean: Direction (+ increases wonky, - decreases)\n",
    "  ‚Ä¢ shap_direction: Plain English interpretation\n",
    "\"\"\")\n",
    "    \n",
    "    shap_df = results['shap_importance'].copy()\n",
    "    display(shap_df.head(20)[['feature', 'shap_importance', 'shap_mean', 'shap_direction']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f03ef07a-5676-400f-8311-9e81300cecbb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Beeswarm plot - shows direction and distribution\n",
    "plot_shap_summary(results, max_display=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "84284a27-b070-4543-bdd2-ddd9c1f8b6d9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "plot_shap_bar(results, max_display=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b9b962ea-a736-4ece-86c5-6ea7ae36d4ee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# # to explore specific features using shap\n",
    "\n",
    "# # How does is_saturday affect predictions?\n",
    "# plot_shap_dependence(results, 'is_saturday')\n",
    "\n",
    "# # With interaction coloring\n",
    "# plot_shap_dependence(results, 'is_saturday', interaction_feature='is_early_morning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "34092118-0410-42ac-b88f-4ba23c0349c4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üîç MULTICOLLINEARITY CHECK (VIF)\")\n",
    "print(\"=\"*80)\n",
    "print(\"\"\"\n",
    "VIF Interpretation:\n",
    "  ‚Ä¢ VIF < 5:  ‚úì No concern\n",
    "  ‚Ä¢ VIF 5-10: ‚ö° Moderate\n",
    "  ‚Ä¢ VIF > 10: ‚ö†Ô∏è High - consider removing\n",
    "\"\"\")\n",
    "\n",
    "vif_df = results['vif_data'].copy()\n",
    "vif_df['status'] = vif_df['VIF'].apply(\n",
    "    lambda x: '‚úì OK' if x < 5 else ('‚ö° Moderate' if x < 10 else '‚ö†Ô∏è HIGH')\n",
    ")\n",
    "\n",
    "high_vif = vif_df[vif_df['VIF'] >= 5]\n",
    "if len(high_vif) > 0:\n",
    "    print(f\"Features with VIF >= 5:\")\n",
    "    display(high_vif[['feature', 'VIF', 'status']])\n",
    "else:\n",
    "    print(\"‚úì All features have VIF < 5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e0fe930c-f0b8-45a2-90a0-005fcb5c1520",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìã STAKEHOLDER REPORT\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "stakeholder_report = create_stakeholder_report(results)\n",
    "display(stakeholder_report.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e0083687-0fc8-41b4-9b44-42d87744e821",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üí° KEY INSIGHTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Top consensus features\n",
    "print(\"\\nüèÜ TOP 5 CONSENSUS FEATURES:\")\n",
    "for i, (_, row) in enumerate(results['comparison'].head(5).iterrows(), 1):\n",
    "    print(f\"\\n{i}. {row['feature']}\")\n",
    "    print(f\"   Linear coef: {row['linear_coef']:+.4f} (p={row['linear_p_value']:.4e})\")\n",
    "    print(f\"   RF importance: {row['rf_importance_pct']:.2f}%\")\n",
    "    if 'lr_odds_ratio' in row and pd.notna(row['lr_odds_ratio']):\n",
    "        print(f\"   Odds Ratio: {row['lr_odds_ratio']:.3f}\")\n",
    "    if 'shap_direction' in row:\n",
    "        print(f\"   SHAP: {row['shap_direction']}\")\n",
    "\n",
    "# Features that increase vs decrease wonky\n",
    "if 'shap_importance' in results:\n",
    "    shap_df = results['shap_importance']\n",
    "    \n",
    "    increases = shap_df[shap_df['shap_mean'] > 0.001].head(5)\n",
    "    decreases = shap_df[shap_df['shap_mean'] < -0.001].head(5)\n",
    "    \n",
    "    print(\"\\nüî¥ FEATURES THAT INCREASE WONKY:\")\n",
    "    for _, row in increases.iterrows():\n",
    "        print(f\"   {row['feature']}: +{row['shap_mean']:.4f}\")\n",
    "    \n",
    "    print(\"\\nüîµ FEATURES THAT DECREASE WONKY:\")\n",
    "    for _, row in decreases.iterrows():\n",
    "        print(f\"   {row['feature']}: {row['shap_mean']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "99dcc917-e8a8-41c2-9d1f-f589d8f0b24f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üéØ HIGH-CONFIDENCE FEATURES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "high_confidence = get_significant_features(results, p_threshold=0.05, min_rf_importance=0.01)\n",
    "print(f\"\\nFeatures significant in Linear + top RF importance: {len(high_confidence)}\")\n",
    "for f in sorted(high_confidence):\n",
    "    print(f\"  ‚úì {f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f452d88b-1403-492c-9315-e69a202106a0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üíæ EXPORT\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Export to CSV\n",
    "export_df = export_results(results, 'feature_importance_results.csv')\n",
    "\n",
    "# Also save as parquet for downstream use\n",
    "results['comparison'].to_parquet('modelling_comparison.parquet', index=False)\n",
    "print(\"‚úì Results saved to modelling_comparison.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "135ef453-424b-481f-935a-35dd427f27af",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Interactive Plotly chart comparing Linear vs RF importance\n",
    "\n",
    "comparison_df = results['comparison'].head(20).copy()\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "# Linear coefficients\n",
    "fig.add_trace(go.Bar(\n",
    "    x=comparison_df['linear_coef'],\n",
    "    y=comparison_df['feature'],\n",
    "    orientation='h',\n",
    "    name='Linear Coefficient',\n",
    "    marker=dict(color='#1f77b4'),\n",
    "))\n",
    "\n",
    "# RF importance (scaled for visibility)\n",
    "rf_scale = comparison_df['linear_coef'].abs().max() / comparison_df['rf_importance'].max()\n",
    "fig.add_trace(go.Bar(\n",
    "    x=comparison_df['rf_importance'] * rf_scale,\n",
    "    y=comparison_df['feature'],\n",
    "    orientation='h',\n",
    "    name=f'RF Importance (scaled)',\n",
    "    marker=dict(color='#ff7f0e'),\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Top 20 Features: Linear Coefficient vs RF Importance\",\n",
    "    xaxis_title='Value',\n",
    "    yaxis_title='Feature',\n",
    "    barmode='group',\n",
    "    yaxis=dict(autorange='reversed'),\n",
    "    height=600,\n",
    "    margin=dict(l=200),\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc3b2246-b4df-44a0-897d-d858b225de87",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# The 'results' dictionary contains everything:\n",
    "# - results['linear_model']: OLS model\n",
    "# - results['rf_model']: Random Forest model  \n",
    "# - results['lr_model']: Logistic Regression model\n",
    "# - results['comparison']: Unified comparison table\n",
    "# - results['shap_values']: SHAP values array\n",
    "# - results['shap_explainer']: SHAP explainer object"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "respondent_modelling - WIP v2",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
