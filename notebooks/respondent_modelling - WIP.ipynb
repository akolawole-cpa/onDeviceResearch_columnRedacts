{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a5d6590e-0203-4cf4-9a08-c41386641223",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "!pip install shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "208d2215-c24b-4a29-a832-53969d83cc23",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import yaml\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.join(os.path.dirname(os.getcwd()), 'src'))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from modelling.modelling import (\n",
    "    run_full_feature_importance_analysis_fixed,\n",
    ")\n",
    "\n",
    "# Load configs\n",
    "with open('../configs/statistical_tests.yaml', 'r') as f:\n",
    "    stats_config = yaml.safe_load(f)\n",
    "\n",
    "with open('../configs/data_paths.yaml', 'r') as f:\n",
    "    paths_config = yaml.safe_load(f)\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "print(\"✓ Imports and configs loaded successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "72a8e1ea-438f-4c00-87a3-340c6fe9e07c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Loading user level dataframe\n",
    "notebook_path = os.getcwd() \n",
    "repo_root = os.path.abspath(os.path.join(notebook_path, \"..\"))\n",
    "misc_dir = os.path.join(repo_root, \"misc\")\n",
    "\n",
    "user_df_input_path = os.path.join(misc_dir,\n",
    "                           os.path.basename(paths_config['output_files']['user_info_df_post_eda']))\n",
    "\n",
    "wonky_df_input_path = os.path.join(misc_dir,\n",
    "                           os.path.basename(paths_config['output_files']['wonky_respondent_df']))\n",
    "\n",
    "test_results_df_input_path = os.path.join(misc_dir,\n",
    "                           os.path.basename(paths_config['output_files']['test_results_df']))\n",
    "\n",
    "user_info_df = pd.read_parquet(user_df_input_path) # user level dataframe\n",
    "wonky_respondent_df = pd.read_parquet(wonky_df_input_path) # user level dataframe wonky_respondents\n",
    "test_results_df = pd.read_parquet(test_results_df_input_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5800f82b-116e-427a-8255-49c0341318be",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# user_info_df = user_info_df[~user_info_df['exposure_band'].isna()]\n",
    "user_info_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "25800751-335e-4c96-b213-abc5cfd1ed8b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "significant_features = test_results_df[test_results_df['significant']]['feature'].tolist()\n",
    "significant_features = [item for item in significant_features if 'is_weekend' not in item]\n",
    "significant_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5cfa8b96-54de-483d-a5e3-ad56c8dfa061",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# # Run analysis\n",
    "# results = run_full_feature_importance_analysis(\n",
    "#     df=user_info_df,\n",
    "#     feature_cols=feature_columns,\n",
    "#     outcome_var='wonky_study_count',\n",
    "#     user_id_var='respondentPk'\n",
    "# )\n",
    "\n",
    "# # Access individual results\n",
    "# print(\"\\nLinear model R²:\", results['linear_model'].rsquared)\n",
    "# print(\"Random Forest CV R²:\", results['cv_results']['test_r2'].mean())\n",
    "# print(\"\\nFeature consensus rankings:\")\n",
    "# print(results['comparison'][['feature', 'avg_rank']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5de8e03e-9ee4-4ef4-882a-2db5bcc8d53d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### stage 1 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8538a319-7a57-40f0-90a4-6618a3b4f2e4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Run fixed analysis\n",
    "results = run_full_feature_importance_analysis_fixed(\n",
    "    df=user_info_df,\n",
    "    feature_cols=significant_features,\n",
    "    outcome_var='wonky_study_count',\n",
    "    user_id_var='respondentPk'\n",
    ")\n",
    "\n",
    "# Access results\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nLinear Model R²: {results['linear_model'].rsquared:.4f}\")\n",
    "print(f\"Random Forest CV R²: {np.mean(results['cv_results']['test_r2']):.4f}\")\n",
    "\n",
    "print(\"\\nTop 5 Features (consensus):\")\n",
    "print(results['comparison'][['feature', 'avg_rank', 'p_value']].head(5).to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "11eccc46-5f54-4391-80d0-9640783dc776",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d83d5ff2-e306-4937-a02f-fd7273e16292",
     "showTitle": false,
     "tableResultSettingsMap": {
      "5": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1767861925379}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 5
      },
      "6": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1767872904610}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 6
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# results is your dictionary with all the model outputs\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"MODEL RESULTS SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ============================================================================\n",
    "# 1. LINEAR MODEL SUMMARY\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"1. LINEAR MODEL PERFORMANCE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "linear_model = results['linear_model']\n",
    "print(f\"R²: {linear_model.rsquared:.4f}\")\n",
    "print(f\"Adjusted R²: {linear_model.rsquared_adj:.4f}\")\n",
    "print(f\"F-statistic: {linear_model.fvalue:.4f}\")\n",
    "print(f\"F-statistic p-value: {linear_model.f_pvalue:.4e}\")\n",
    "print(f\"Number of observations: {linear_model.nobs:.0f}\")\n",
    "print(f\"Number of features: {linear_model.df_model:.0f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# 2. LINEAR FEATURE IMPORTANCE\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"2. LINEAR MODEL FEATURE IMPORTANCE (Top 15)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "linear_importance = results['linear_importance'].copy()\n",
    "linear_importance['p_value_formatted'] = linear_importance['p_value'].apply(lambda x: f\"{x:.4e}\")\n",
    "linear_importance['coef_formatted'] = linear_importance['coefficient'].apply(lambda x: f\"{x:+.4f}\")\n",
    "\n",
    "display(linear_importance.head(15)[['feature', 'coef_formatted', 'p_value_formatted', 'importance']])\n",
    "\n",
    "# Show only significant features\n",
    "sig_linear = linear_importance[linear_importance['p_value'] < 0.01]\n",
    "print(f\"\\nSignificant features (p < 0.01): {len(sig_linear)} out of {len(linear_importance)}\")\n",
    "if len(sig_linear) > 0:\n",
    "    display(sig_linear[['feature', 'coefficient', 'p_value', 't_stat']])\n",
    "\n",
    "# ============================================================================\n",
    "# 3. MULTICOLLINEARITY CHECK (VIF)\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"3. MULTICOLLINEARITY DIAGNOSTICS (VIF)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "vif_data = results['vif_data'].copy()\n",
    "print(\"\\nFeatures with high VIF (> 10 indicates multicollinearity):\")\n",
    "\n",
    "# Filter problematic VIF\n",
    "vif_high = vif_data[vif_data['VIF'] > 10].copy()\n",
    "if len(vif_high) > 0:\n",
    "    print(f\"WARNING: {len(vif_high)} features with VIF > 10\")\n",
    "    display(vif_high.head(20))\n",
    "else:\n",
    "    print(\"✓ No severe multicollinearity detected\")\n",
    "\n",
    "print(\"\\nTop 10 features by VIF:\")\n",
    "display(vif_data.head(10))\n",
    "\n",
    "# ============================================================================\n",
    "# 4. RANDOM FOREST PERFORMANCE\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"4. RANDOM FOREST PERFORMANCE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "cv_results = results['cv_results']\n",
    "print(f\"Cross-Validation Results (5-fold, cluster-based):\")\n",
    "print(f\"  Mean Test R²: {np.mean(cv_results['test_r2']):.4f} ± {np.std(cv_results['test_r2']):.4f}\")\n",
    "print(f\"  Mean Train R²: {np.mean(cv_results['train_r2']):.4f} ± {np.std(cv_results['train_r2']):.4f}\")\n",
    "print(f\"  Mean Test RMSE: {np.sqrt(np.mean(cv_results['test_mse'])):.4f}\")\n",
    "print(f\"  Mean Test MAE: {np.mean(cv_results['test_mae']):.4f}\")\n",
    "\n",
    "# Overfitting check\n",
    "overfit_gap = np.mean(cv_results['train_r2']) - np.mean(cv_results['test_r2'])\n",
    "if overfit_gap > 0.1:\n",
    "    print(f\"  WARNING: Possible overfitting detected (gap = {overfit_gap:.4f})\")\n",
    "else:\n",
    "    print(f\"  Overfitting check: OK (gap = {overfit_gap:.4f})\")\n",
    "\n",
    "# Show fold-by-fold results\n",
    "cv_summary = pd.DataFrame({\n",
    "    'Fold': range(1, 6),\n",
    "    'Train R²': cv_results['train_r2'],\n",
    "    'Test R²': cv_results['test_r2'],\n",
    "    'Test RMSE': np.sqrt(cv_results['test_mse']),\n",
    "    'Test MAE': cv_results['test_mae']\n",
    "})\n",
    "print(\"\\nFold-by-fold results:\")\n",
    "display(cv_summary)\n",
    "\n",
    "# ============================================================================\n",
    "# 5. RANDOM FOREST FEATURE IMPORTANCE\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"5. RANDOM FOREST FEATURE IMPORTANCE (Top 15)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "rf_importance = results['rf_importance'].copy()\n",
    "rf_importance['importance_pct'] = (rf_importance['importance'] * 100).round(2)\n",
    "\n",
    "display(rf_importance.head(73))\n",
    "\n",
    "# Show features with zero importance\n",
    "zero_importance = rf_importance[rf_importance['importance'] == 0]\n",
    "print(f\"\\nFeatures with zero importance: {len(zero_importance)} out of {len(rf_importance)}\")\n",
    "\n",
    "# ============================================================================\n",
    "# 6. FEATURE COMPARISON (CONSENSUS RANKING)\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"6. FEATURE IMPORTANCE COMPARISON (Consensus Ranking)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "comparison = results['comparison'].copy()\n",
    "comparison['p_value_formatted'] = comparison['p_value'].apply(lambda x: f\"{x:.4e}\")\n",
    "comparison['coef_formatted'] = comparison['coefficient'].apply(lambda x: f\"{x:+.4f}\")\n",
    "comparison['rf_imp_pct'] = (comparison['rf_importance'] * 100).round(2)\n",
    "\n",
    "print(\"\\nTop 20 features by average rank (consensus across both models):\")\n",
    "display(comparison.head(20)[['feature', 'coef_formatted', 'p_value_formatted', \n",
    "                             'rf_imp_pct', 'linear_rank', 'rf_rank', 'avg_rank']])\n",
    "\n",
    "# ============================================================================\n",
    "# 7. KEY INSIGHTS\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"7. KEY INSIGHTS & RECOMMENDATIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Model performance comparison\n",
    "linear_r2 = results['linear_model'].rsquared\n",
    "rf_r2 = np.mean(cv_results['test_r2'])\n",
    "\n",
    "print(f\"\\nModel Performance Comparison:\")\n",
    "print(f\"  Linear Model R²: {linear_r2:.4f}\")\n",
    "print(f\"  Random Forest R² (CV): {rf_r2:.4f}\")\n",
    "\n",
    "if rf_r2 > linear_r2:\n",
    "    print(f\"  Random Forest performs better (+{rf_r2-linear_r2:.4f} R²)\")\n",
    "    print(f\"  Suggests non-linear relationships in the data\")\n",
    "else:\n",
    "    print(f\"  Linear model performs similarly (difference: {linear_r2-rf_r2:.4f})\")\n",
    "    print(f\"  Linear relationships dominate\")\n",
    "\n",
    "# Feature consistency\n",
    "top_linear = set(linear_importance.head(10)['feature'].values)\n",
    "top_rf = set(rf_importance.head(10)['feature'].values)\n",
    "overlap = top_linear & top_rf\n",
    "\n",
    "print(f\"\\nFeature Importance Consistency:\")\n",
    "print(f\"  Top 10 features overlap: {len(overlap)} features\")\n",
    "print(f\"  Overlapping features: {', '.join(sorted(overlap))}\")\n",
    "\n",
    "if len(overlap) >= 5:\n",
    "    print(f\"  Good agreement between models\")\n",
    "else:\n",
    "    print(f\"  Low agreement - models capture different patterns\")\n",
    "\n",
    "# Top consensus features\n",
    "print(f\"\\nTop 5 Consensus Features (by avg_rank):\")\n",
    "for idx, row in comparison.head(20).iterrows():\n",
    "    print(f\"  {idx+1}. {row['feature']}\")\n",
    "    print(f\"     Linear coef: {row['coefficient']:+.4f} (p={row['p_value']:.4e})\")\n",
    "    print(f\"     RF importance: {row['rf_importance']:.4f}\")\n",
    "    print(f\"     Average rank: {row['avg_rank']:.1f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# 8. SAVE RESULTS FOR LATER\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"8. EXPORT OPTIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "comparison_export = comparison[['feature', 'coefficient', 'p_value', 'rf_importance', \n",
    "                                'linear_rank', 'rf_rank', 'avg_rank']].copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c05f8380-712b-4fcc-b7e9-4efbcd2e8864",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### stage 2 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "69ebc8db-f6cb-4ced-a409-baa71588d115",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "important_features = rf_importance[rf_importance['importance_pct']>0]['feature']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2c75ee02-7c6b-4d46-b280-fdf1f10d6fb2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "important_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f03ef07a-5676-400f-8311-9e81300cecbb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "importance = rf_importance[rf_importance['importance_pct']>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "84284a27-b070-4543-bdd2-ddd9c1f8b6d9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "34092118-0410-42ac-b88f-4ba23c0349c4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "imp_df = importance.sort_values(\"importance_pct\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Helper to build a bar trace for top N\n",
    "def make_trace(df, top_n, name):\n",
    "    sub = df.head(top_n)\n",
    "    return go.Bar(\n",
    "        x=sub[\"importance_pct\"],\n",
    "        y=sub[\"feature\"],\n",
    "        orientation=\"h\",\n",
    "        name=name,\n",
    "        text=sub[\"importance_pct\"].round(2).astype(str) + \"%\",\n",
    "        textposition=\"outside\"\n",
    "    )\n",
    "\n",
    "# Different views\n",
    "sizes = [5, 10, 20, len(imp_df)]\n",
    "labels = [f\"Top {n}\" if n < len(imp_df) else \"All\" for n in sizes]\n",
    "\n",
    "traces = [make_trace(imp_df, n, labels[i]) for i, n in enumerate(sizes)]\n",
    "\n",
    "# Start with Top 10\n",
    "fig = go.Figure(data=[traces[1]])\n",
    "\n",
    "# Dropdown to switch number of features\n",
    "updatemenus = [\n",
    "    dict(\n",
    "        type=\"dropdown\",\n",
    "        x=1.15,\n",
    "        y=1.0,\n",
    "        xanchor=\"left\",\n",
    "        buttons=[\n",
    "            dict(\n",
    "                label=labels[i],\n",
    "                method=\"update\",\n",
    "                args=[\n",
    "                    {\"x\": [imp_df.head(sizes[i])[\"importance_pct\"]],\n",
    "                     \"y\": [imp_df.head(sizes[i])[\"feature\"]],\n",
    "                     \"text\": [imp_df.head(sizes[i])[\"importance_pct\"].round(2).astype(str) + \"%\"]},\n",
    "                    {\"title\": f\"Feature Importance (% of total) - {labels[i]}\"}\n",
    "                ],\n",
    "            )\n",
    "            for i in range(len(sizes))\n",
    "        ],\n",
    "        showactive=True,\n",
    "        direction=\"down\"\n",
    "    )\n",
    "]\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Feature Importance (% of total)\",\n",
    "    xaxis_title=\"Importance (%)\",\n",
    "    yaxis_title=\"Feature\",\n",
    "    yaxis=dict(autorange=\"reversed\"),\n",
    "    margin=dict(l=200, r=20, t=60, b=40),\n",
    "    updatemenus=updatemenus\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e0fe930c-f0b8-45a2-90a0-005fcb5c1520",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "comparison_export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e0083687-0fc8-41b4-9b44-42d87744e821",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "\n",
    "comparison_df = comparison_export.sort_values('rf_rank').reset_index(drop=True)\n",
    "\n",
    "# Different views\n",
    "sizes = [5, 10, 20, len(comparison_df)]\n",
    "labels = [f\"Top {n}\" if n < len(comparison_df) else \"All\" for n in sizes]\n",
    "\n",
    "# Build initial figure with Top 10\n",
    "sub = comparison_df.head(sizes[1]).copy()\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "# Coefficient bars (simple blue)\n",
    "fig.add_trace(go.Bar(\n",
    "    x=sub['coefficient'],\n",
    "    y=sub['feature'],\n",
    "    orientation='h',\n",
    "    name='Coefficient',\n",
    "    marker=dict(color='#1f77b4'),\n",
    "    text=[f\"{x:+.3f}\" for x in sub['coefficient']],\n",
    "    textposition='outside'\n",
    "))\n",
    "\n",
    "# RF importance bars (simple orange)\n",
    "fig.add_trace(go.Bar(\n",
    "    x=sub['rf_importance'],\n",
    "    y=sub['feature'],\n",
    "    orientation='h',\n",
    "    name='RF Importance',\n",
    "    marker=dict(color='#ff7f0e'),\n",
    "    text=[f\"{x:.4f}\" for x in sub['rf_importance']],\n",
    "    textposition='outside'\n",
    "))\n",
    "\n",
    "# Dropdown\n",
    "updatemenus = [\n",
    "    dict(\n",
    "        type=\"dropdown\",\n",
    "        x=1.15,\n",
    "        y=1.0,\n",
    "        xanchor=\"left\",\n",
    "        buttons=[\n",
    "            dict(\n",
    "                label=labels[i],\n",
    "                method=\"update\",\n",
    "                args=[\n",
    "                    {\n",
    "                        'x': [\n",
    "                            comparison_df.head(sizes[i])['coefficient'].values,\n",
    "                            comparison_df.head(sizes[i])['rf_importance'].values\n",
    "                        ],\n",
    "                        'y': [\n",
    "                            comparison_df.head(sizes[i])['feature'].values,\n",
    "                            comparison_df.head(sizes[i])['feature'].values\n",
    "                        ],\n",
    "                        'text': [\n",
    "                            [f\"{x:+.3f}\" for x in comparison_df.head(sizes[i])['coefficient']],\n",
    "                            [f\"{x:.4f}\" for x in comparison_df.head(sizes[i])['rf_importance']]\n",
    "                        ]\n",
    "                    },\n",
    "                    {'title': f\"Feature Analysis - {labels[i]}\"}\n",
    "                ],\n",
    "            )\n",
    "            for i in range(len(sizes))\n",
    "        ],\n",
    "        showactive=True,\n",
    "        direction=\"down\"\n",
    "    )\n",
    "]\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Feature Analysis - Top 10\",\n",
    "    xaxis_title='Value',\n",
    "    yaxis_title='Feature',\n",
    "    updatemenus=updatemenus,\n",
    "    barmode='group',\n",
    "    yaxis=dict(autorange='reversed'),\n",
    "    margin=dict(l=200, r=100, t=80, b=60),\n",
    "    height=700,\n",
    "    hovermode='closest',\n",
    "    legend=dict(x=1.15, y=0.95)\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f452d88b-1403-492c-9315-e69a202106a0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "respondent_modelling - WIP",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
