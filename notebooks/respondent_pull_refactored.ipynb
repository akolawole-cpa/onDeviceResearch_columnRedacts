{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "10090529-6ec9-4a3b-883d-15ffa243ab7f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.join(os.path.dirname(os.getcwd()), 'src'))\n",
    "\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Custom funcs\n",
    "from data_pull.loaders import (\n",
    "    load_user_table,\n",
    "    load_task_complete_table,\n",
    "    load_respondent_info_table,\n",
    "    load_task_table,\n",
    "    load_all_wonky_studies\n",
    ")\n",
    "from data_pull.joiners import (\n",
    "    join_user_task_respondent,\n",
    "    join_wonky_balance_with_task,\n",
    "    merge_wonky_data_with_user_info\n",
    ")\n",
    "from data_pull.aggregators import (\n",
    "    enrich_user_info_with_task_counts,\n",
    "    union_wonky_study_dataframes,\n",
    "    aggregate_wonky_respondent_summary,\n",
    "    create_wonky_respondent_summary,\n",
    "    calculate_wonky_task_ratio\n",
    ")\n",
    "\n",
    "# Configs\n",
    "with open('../configs/data_paths.yaml', 'r') as f:\n",
    "    paths_config = yaml.safe_load(f)\n",
    "\n",
    "with open('../configs/wonky_studies.yaml', 'r') as f:\n",
    "    wonky_config = yaml.safe_load(f)\n",
    "\n",
    "print(\"Imports and configs loaded successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d6c01486-b86d-4ff1-accb-5ff6de03ea13",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.catalog.clearCache()\n",
    "print(\"Cache cleared\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7e956f94-b411-4793-9785-81da6f2ecc0f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "s_u = load_user_table(\n",
    "    spark,\n",
    "    paths_config['silver_path'],\n",
    "    country=paths_config['filters']['country']\n",
    ")\n",
    "\n",
    "s_tc_odr = load_task_complete_table(\n",
    "    spark,\n",
    "    paths_config['silver_path'],\n",
    "    min_date=paths_config['filters']['min_date'],\n",
    "    task_origin=paths_config['filters']['task_origin']\n",
    ")\n",
    "\n",
    "s_ri = load_respondent_info_table(\n",
    "    spark,\n",
    "    paths_config['silver_path'],\n",
    "    country=paths_config['filters']['country']\n",
    ")\n",
    "\n",
    "print(f\"s_u (users {paths_config['filters']['country']}) count: {s_u.count():,}\")\n",
    "print(f\"s_tc_odr (tasks completed >= {paths_config['filters']['min_date']}, origin={paths_config['filters']['task_origin']}) count: {s_tc_odr.count():,}\")\n",
    "print(f\"s_ri (respondent_info {paths_config['filters']['country']}) count: {s_ri.count():,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "91e7ef06-94d4-4531-8348-40838cec6188",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "user_info = join_user_task_respondent(s_u, s_tc_odr, s_ri)\n",
    "\n",
    "print(f\"\\nAfter INNER joins count: {user_info.count():,}\")\n",
    "print(f\"Unique respondents in joined data: {user_info.select('respondentPk').distinct().count():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "06594725-360c-4966-80c6-2566b71a6516",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "user_info_enriched = enrich_user_info_with_task_counts(user_info)\n",
    "user_info_enriched.cache()\n",
    "\n",
    "print(f\"Task-level records (rows): {user_info_enriched.count():,}\")\n",
    "print(f\"Unique respondents: {user_info_enriched.select('respondentPk').distinct().count():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4b2d57a3-0acf-430e-a533-32aaf941a1b7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "user_info_df = user_info_enriched.toPandas()\n",
    "\n",
    "print(f\"\\nHierarchical Structure Validation:\")\n",
    "print(f\"  - Task-level rows: {len(user_info_df):,}\")\n",
    "print(f\"  - Unique respondents: {user_info_df['respondentPk'].nunique():,}\")\n",
    "print(f\"  - Avg tasks per respondent: {len(user_info_df) / user_info_df['respondentPk'].nunique():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3a11c804-f476-437a-98db-79cbc5d3ee25",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "balance_dfs, failed_uuids = load_all_wonky_studies(\n",
    "    spark,\n",
    "    wonky_config['wonky_study_uuids'],\n",
    "    base_path=paths_config['project_repository_path'],\n",
    "    cols_to_include=wonky_config['cols_to_include_subset'],\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(f\"\\nSuccessfully loaded {len(balance_dfs)} out of {len(wonky_config['wonky_study_uuids'])} studies\")\n",
    "if failed_uuids:\n",
    "    print(f\"Failed UUIDs ({len(failed_uuids)}): {failed_uuids}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4b79a15a-edc4-4ebd-865a-0d1634376c3b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "task = load_task_table(spark, paths_config['silver_path'])\n",
    "\n",
    "wonky_dfs_joined = []\n",
    "for balance_df in balance_dfs:\n",
    "    joined = join_wonky_balance_with_task(balance_df, task)\n",
    "    wonky_dfs_joined.append(joined)\n",
    "\n",
    "wonky_spark = union_wonky_study_dataframes(wonky_dfs_joined)\n",
    "wonky_map = wonky_spark.toPandas()\n",
    "\n",
    "print(f\"Wonky map shape: {wonky_map.shape}\")\n",
    "print(f\"Unique respondents in wonky studies: {wonky_map['respondent_pk'].nunique():,}\")\n",
    "print(f\"Unique tasks in wonky studies: {wonky_map['task_pk'].nunique():,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "54360286-6e87-404c-ade5-e70e78f1a509",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "wonky_respondent_summary = create_wonky_respondent_summary(\n",
    "    wonky_map,\n",
    "    respondent_id_col=\"respondent_pk\"\n",
    ")\n",
    "\n",
    "task_completed = (\n",
    "    user_info_df[['respondentPk', 'taskPk']]\n",
    "    .groupby('respondentPk')\n",
    "    .count()\n",
    "    .rename(columns={'taskPk': 'task_completed'})\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "wonky_counts = calculate_wonky_task_ratio(\n",
    "    task_completed,\n",
    "    wonky_respondent_summary\n",
    ")\n",
    "\n",
    "print(f\"Wonky counts final shape: {wonky_counts.shape}\")\n",
    "print(f\"Respondents in wonky_counts: {len(wonky_counts):,}\")\n",
    "print(f\"Avg total tasks per respondent: {wonky_counts['task_completed'].mean():.2f}\")\n",
    "print(f\"Avg wonky tasks per respondent: {wonky_counts['wonky_task_instances'].mean():.2f}\")\n",
    "print(f\"Avg wonky task ratio: {wonky_counts['wonky_task_ratio'].mean():.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7155de11-93e2-487e-8924-f7e77bec7153",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Merge wonky data with user info\n",
    "user_info_df_vstudy = merge_wonky_data_with_user_info(\n",
    "    user_info_df,\n",
    "    wonky_respondent_summary,\n",
    "    left_on=[\"respondentPk\", \"taskPk\"],\n",
    "    right_on=[\"balance_respondentPk\", \"task_pk\"]\n",
    ")\n",
    "\n",
    "# Add wonky flag\n",
    "wonky_respondent_list = wonky_counts['respondentPk'].unique().tolist()\n",
    "user_info_df_vstudy[\"wonky_study_flag\"] = np.where(\n",
    "    user_info_df_vstudy[\"respondentPk\"].isin(wonky_respondent_list), 1, 0\n",
    ")\n",
    "\n",
    "print(f\"Final user_info_df_vstudy shape: {user_info_df_vstudy.shape}\")\n",
    "print(f\"Records with wonky flag: {(user_info_df_vstudy['wonky_study_flag']==1).sum():,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8a9b8c73-c50d-4aa2-8baf-9135ce549510",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "output_local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7c83496c-ca5a-4b1c-aa3e-7e271bfe81c4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "output_path = paths_config['output_files']['user_info_df']\n",
    "wonky_path = paths_config['output_files']['wonky_user_counts']\n",
    "\n",
    "# Convert to dbfs local for pandas\n",
    "output_local = output_path.replace(\"dbfs:\", \"/dbfs\")\n",
    "wonky_local = wonky_path.replace(\"dbfs:\", \"/dbfs\")\n",
    "\n",
    "os.makedirs(os.path.dirname(output_local), exist_ok=True)\n",
    "\n",
    "wonky_counts.to_parquet(wonky_path, index=False)\n",
    "user_info_df_vstudy.to_parquet(output_path, index=False)\n",
    "\n",
    "print(f\"âœ“ Files saved successfully:\")\n",
    "print(f\"  - {output_path}\")\n",
    "print(f\"  - {wonky_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ae406555-95dc-4aaf-89e3-13f13274dd62",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "notebook_path = os.getcwd() \n",
    "repo_root = os.path.abspath(os.path.join(notebook_path, \"..\"))\n",
    "misc_dir = os.path.join(repo_root, \"misc\")\n",
    "os.makedirs(misc_dir, exist_ok=True)\n",
    "\n",
    "output_path = os.path.join(misc_dir,\n",
    "                           os.path.basename(paths_config['output_files']['user_info_df']))\n",
    "wonky_path = os.path.join(misc_dir,\n",
    "                          os.path.basename(paths_config['output_files']['wonky_user_counts']))\n",
    "\n",
    "wonky_counts.to_parquet(wonky_path, index=False)\n",
    "\n",
    "user_info_df_vstudy = user_info_df_vstudy.loc[:, ~user_info_df_vstudy.columns.duplicated()]\n",
    "user_info_df_vstudy.to_parquet(output_path, index=False)\n",
    "\n",
    "print(\"Files saved successfully:\")\n",
    "print(f\"  - {output_path}\")\n",
    "print(f\"  - {wonky_path}\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "respondent_pull_refactored",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
