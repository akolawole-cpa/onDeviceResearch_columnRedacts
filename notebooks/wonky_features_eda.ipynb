{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Identify numeric columns (exclude IDs, dates, and target variables)\n",
        "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "exclude_cols = ['respondentPk', 'has_wonky_study', 'has_wonky_task', \n",
        "                'wonky_study_count', 'wonky_task_instances']\n",
        "numeric_cols = [col for col in numeric_cols if col not in exclude_cols]\n",
        "\n",
        "# Calculate correlations with target variables\n",
        "# Include target variables separately to avoid duplicates\n",
        "corr_study_count = df[numeric_cols + ['wonky_study_count']].corr()['wonky_study_count'].sort_values(ascending=False)\n",
        "corr_task_instances = df[numeric_cols + ['wonky_task_instances']].corr()['wonky_task_instances'].sort_values(ascending=False)\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"TOP CORRELATIONS WITH wonky_study_count\")\n",
        "print(\"=\" * 80)\n",
        "print(\"\\nTop 20 positive correlations:\")\n",
        "display(corr_study_count.head(21)[1:])  # Exclude self-correlation\n",
        "print(\"\\nTop 20 negative correlations:\")\n",
        "display(corr_study_count.tail(20))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Statistical tests for wonky_study_count (binary: has_wonky_study)\n",
        "print(\"=\" * 80)\n",
        "print(\"STATISTICAL TESTS: Features vs has_wonky_study\")\n",
        "print(\"=\" * 80)\n",
        "print(\"\\nComparing respondents with wonky studies (1) vs without (0)\")\n",
        "\n",
        "stats_results_study = compare_groups_statistically(\n",
        "    df=df,\n",
        "    group_col='has_wonky_study',\n",
        "    metrics=test_features,\n",
        "    group1_value=1,\n",
        "    group2_value=0,\n",
        "    significance_level=0.05,\n",
        "    include_welch=True\n",
        ")\n",
        "\n",
        "# Sort by p-value\n",
        "stats_results_study = stats_results_study.sort_values('mw_p_value')\n",
        "\n",
        "print(f\"\\n✓ Completed tests on {len(stats_results_study)} features\")\n",
        "print(f\"\\nSignificant features (p < 0.05): {stats_results_study['mw_significant'].sum()}\")\n",
        "\n",
        "display(stats_results_study.head(20))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Statistical tests for wonky_task_instances (binary: has_wonky_task)\n",
        "print(\"=\" * 80)\n",
        "print(\"STATISTICAL TESTS: Features vs has_wonky_task\")\n",
        "print(\"=\" * 80)\n",
        "print(\"\\nComparing respondents with wonky tasks (1) vs without (0)\")\n",
        "\n",
        "stats_results_task = compare_groups_statistically(\n",
        "    df=df,\n",
        "    group_col='has_wonky_task',\n",
        "    metrics=test_features,\n",
        "    group1_value=1,\n",
        "    group2_value=0,\n",
        "    significance_level=0.05,\n",
        "    include_welch=True\n",
        ")\n",
        "\n",
        "# Sort by p-value\n",
        "stats_results_task = stats_results_task.sort_values('mw_p_value')\n",
        "\n",
        "print(f\"\\n✓ Completed tests on {len(stats_results_task)} features\")\n",
        "print(f\"\\nSignificant features (p < 0.05): {stats_results_task['mw_significant'].sum()}\")\n",
        "\n",
        "display(stats_results_task.head(20))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize statistical test results\n",
        "fig = make_subplots(\n",
        "    rows=1, cols=2,\n",
        "    subplot_titles=('Statistical Significance: has_wonky_study',\n",
        "                    'Statistical Significance: has_wonky_task'),\n",
        "    specs=[[{\"secondary_y\": False}, {\"secondary_y\": False}]]\n",
        ")\n",
        "\n",
        "# Top significant features for wonky_study\n",
        "# Check if DataFrame exists, is not empty, and has the required column\n",
        "if (len(stats_results_study) > 0 and \n",
        "    'mw_significant' in stats_results_study.columns and \n",
        "    'mw_p_value' in stats_results_study.columns and\n",
        "    'metric' in stats_results_study.columns):\n",
        "    top_sig_study = stats_results_study[stats_results_study['mw_significant']].head(15)\n",
        "    if len(top_sig_study) > 0:\n",
        "        fig.add_trace(\n",
        "            go.Bar(x=-np.log10(top_sig_study['mw_p_value']), \n",
        "                   y=top_sig_study['metric'],\n",
        "                   orientation='h',\n",
        "                   marker_color='steelblue',\n",
        "                   name='wonky_study'),\n",
        "            row=1, col=1\n",
        "        )\n",
        "else:\n",
        "    print(\"Warning: stats_results_study is empty or missing required columns\")\n",
        "\n",
        "# Top significant features for wonky_task\n",
        "# Check if DataFrame exists, is not empty, and has the required column\n",
        "if (len(stats_results_task) > 0 and \n",
        "    'mw_significant' in stats_results_task.columns and \n",
        "    'mw_p_value' in stats_results_task.columns and\n",
        "    'metric' in stats_results_task.columns):\n",
        "    top_sig_task = stats_results_task[stats_results_task['mw_significant']].head(15)\n",
        "    if len(top_sig_task) > 0:\n",
        "        fig.add_trace(\n",
        "            go.Bar(x=-np.log10(top_sig_task['mw_p_value']),\n",
        "                   y=top_sig_task['metric'],\n",
        "                   orientation='h',\n",
        "                   marker_color='coral',\n",
        "                   name='wonky_task'),\n",
        "            row=1, col=2\n",
        "        )\n",
        "else:\n",
        "    print(\"Warning: stats_results_task is empty or missing required columns\")\n",
        "\n",
        "fig.update_layout(\n",
        "    height=600,\n",
        "    title_text=\"Top Significant Features (-log10 p-value)\",\n",
        "    showlegend=False\n",
        ")\n",
        "\n",
        "fig.update_xaxes(title_text=\"-log10(p-value)\", row=1, col=1)\n",
        "fig.update_xaxes(title_text=\"-log10(p-value)\", row=1, col=2)\n",
        "\n",
        "# Add significance line\n",
        "fig.add_hline(y=-np.log10(0.05), line_dash=\"dash\", line_color=\"red\", \n",
        "              annotation_text=\"p=0.05\", row=1, col=1)\n",
        "fig.add_hline(y=-np.log10(0.05), line_dash=\"dash\", line_color=\"red\",\n",
        "              annotation_text=\"p=0.05\", row=1, col=2)\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get top significant features for visualization\n",
        "top_features_study = []\n",
        "top_features_task = []\n",
        "\n",
        "if (len(stats_results_study) > 0 and \n",
        "    'mw_significant' in stats_results_study.columns and \n",
        "    'metric' in stats_results_study.columns):\n",
        "    top_features_study = stats_results_study[stats_results_study['mw_significant']].head(6)['metric'].tolist()\n",
        "\n",
        "if (len(stats_results_task) > 0 and \n",
        "    'mw_significant' in stats_results_task.columns and \n",
        "    'metric' in stats_results_task.columns):\n",
        "    top_features_task = stats_results_task[stats_results_task['mw_significant']].head(6)['metric'].tolist()\n",
        "\n",
        "print(f\"Top features for wonky_study analysis: {top_features_study}\")\n",
        "print(f\"Top features for wonky_task analysis: {top_features_task}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Box plots comparing distributions for wonky_study\n",
        "print(\"=\" * 80)\n",
        "print(\"DISTRIBUTION COMPARISONS: has_wonky_study\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Use significant features if available, otherwise use top correlated features\n",
        "if len(top_features_study) == 0:\n",
        "    print(\"No significant features found. Using top correlated features instead...\")\n",
        "    if len(corr_study_count) > 0:\n",
        "        top_features_study = corr_study_count.head(7)[1:].index.tolist()[:6]  # Exclude self, get top 6\n",
        "        print(f\"Using top correlated features: {top_features_study}\")\n",
        "\n",
        "if len(top_features_study) > 0:\n",
        "    for feature in top_features_study[:6]:\n",
        "        if feature in df.columns:\n",
        "            try:\n",
        "                # Check if feature has valid numeric data\n",
        "                if df[feature].dtype not in [np.int64, np.float64]:\n",
        "                    print(f\"Skipping {feature}: not numeric\")\n",
        "                    continue\n",
        "                \n",
        "                # Remove NaN values for plotting\n",
        "                plot_df = df[['has_wonky_study', feature]].dropna()\n",
        "                if len(plot_df) == 0:\n",
        "                    print(f\"Skipping {feature}: no valid data after removing NaNs\")\n",
        "                    continue\n",
        "                \n",
        "                fig = create_box_plot(\n",
        "                    df=plot_df,\n",
        "                    x='has_wonky_study',\n",
        "                    y=feature,\n",
        "                    title=f'{feature} by Wonky Study Status',\n",
        "                    labels={'has_wonky_study': 'Has Wonky Study', feature: feature}\n",
        "                )\n",
        "                fig.update_xaxes(tickmode='linear', tick0=0, dtick=1)\n",
        "                fig.update_layout(height=500)\n",
        "                fig.show()\n",
        "            except Exception as e:\n",
        "                print(f\"Error creating plot for {feature}: {e}\")\n",
        "                continue\n",
        "else:\n",
        "    print(\"No features available for plotting\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Box plots comparing distributions for wonky_task\n",
        "print(\"=\" * 80)\n",
        "print(\"DISTRIBUTION COMPARISONS: has_wonky_task\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Use significant features if available, otherwise use top correlated features\n",
        "if len(top_features_task) == 0:\n",
        "    print(\"No significant features found. Using top correlated features instead...\")\n",
        "    if len(corr_task_instances) > 0:\n",
        "        top_features_task = corr_task_instances.head(7)[1:].index.tolist()[:6]  # Exclude self, get top 6\n",
        "        print(f\"Using top correlated features: {top_features_task}\")\n",
        "\n",
        "if len(top_features_task) > 0:\n",
        "    for feature in top_features_task[:6]:\n",
        "        if feature in df.columns:\n",
        "            try:\n",
        "                # Check if feature has valid numeric data\n",
        "                if df[feature].dtype not in [np.int64, np.float64]:\n",
        "                    print(f\"Skipping {feature}: not numeric\")\n",
        "                    continue\n",
        "                \n",
        "                # Remove NaN values for plotting\n",
        "                plot_df = df[['has_wonky_task', feature]].dropna()\n",
        "                if len(plot_df) == 0:\n",
        "                    print(f\"Skipping {feature}: no valid data after removing NaNs\")\n",
        "                    continue\n",
        "                \n",
        "                fig = create_box_plot(\n",
        "                    df=plot_df,\n",
        "                    x='has_wonky_task',\n",
        "                    y=feature,\n",
        "                    title=f'{feature} by Wonky Task Status',\n",
        "                    labels={'has_wonky_task': 'Has Wonky Task', feature: feature}\n",
        "                )\n",
        "                fig.update_xaxes(tickmode='linear', tick0=0, dtick=1)\n",
        "                fig.update_layout(height=500)\n",
        "                fig.show()\n",
        "            except Exception as e:\n",
        "                print(f\"Error creating plot for {feature}: {e}\")\n",
        "                continue\n",
        "else:\n",
        "    print(\"No features available for plotting\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Combine correlation and statistical test results for wonky_study_count\n",
        "print(\"=\" * 80)\n",
        "print(\"FEATURE IMPORTANCE SUMMARY: wonky_study_count\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "if len(stats_results_study) > 0 and 'metric' in stats_results_study.columns:\n",
        "    # Convert correlation Series to DataFrame properly\n",
        "    if len(corr_study_count) > 0:\n",
        "        corr_df = corr_study_count.to_frame(name='correlation').reset_index()\n",
        "        corr_df.columns = ['metric', 'correlation']\n",
        "        \n",
        "        # Merge correlation and statistical test results\n",
        "        importance_study = stats_results_study.merge(\n",
        "            corr_df,\n",
        "            on='metric',\n",
        "            how='left'\n",
        "        )\n",
        "        \n",
        "        print(f\"Merged {len(importance_study)} features\")\n",
        "        print(f\"Features with correlation data: {importance_study['correlation'].notna().sum()}\")\n",
        "        \n",
        "        # Calculate importance score (combination of correlation magnitude and statistical significance)\n",
        "        if 'mw_p_value' in importance_study.columns:\n",
        "            # Fill NaN correlations with 0 for calculation\n",
        "            importance_study['correlation'] = importance_study['correlation'].fillna(0)\n",
        "            \n",
        "            importance_study['importance_score'] = (\n",
        "                np.abs(importance_study['correlation']) * \n",
        "                (-np.log10(importance_study['mw_p_value'] + 1e-10))\n",
        "            )\n",
        "            importance_study = importance_study.sort_values('importance_score', ascending=False)\n",
        "            \n",
        "            # Select columns that exist\n",
        "            display_cols = ['metric', 'correlation', 'mean_difference', 'importance_score']\n",
        "            if 'mw_p_value' in importance_study.columns:\n",
        "                display_cols.insert(2, 'mw_p_value')\n",
        "            if 'mw_significant' in importance_study.columns:\n",
        "                display_cols.insert(3, 'mw_significant')\n",
        "            \n",
        "            print(\"\\nTop 20 Most Important Features:\")\n",
        "            result_df = importance_study[[col for col in display_cols if col in importance_study.columns]].head(20)\n",
        "            if len(result_df) > 0:\n",
        "                display(result_df)\n",
        "            else:\n",
        "                print(\"No results to display\")\n",
        "        else:\n",
        "            print(\"Warning: mw_p_value column not found in stats_results_study\")\n",
        "            print(f\"Available columns: {list(stats_results_study.columns)}\")\n",
        "    else:\n",
        "        print(\"Warning: corr_study_count is empty\")\n",
        "else:\n",
        "    print(\"Warning: stats_results_study is empty or missing required columns\")\n",
        "    if len(stats_results_study) == 0:\n",
        "        print(\"stats_results_study is empty\")\n",
        "    elif 'metric' not in stats_results_study.columns:\n",
        "        print(f\"Available columns: {list(stats_results_study.columns)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Combine correlation and statistical test results for wonky_task_instances\n",
        "print(\"=\" * 80)\n",
        "print(\"FEATURE IMPORTANCE SUMMARY: wonky_task_instances\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "if len(stats_results_task) > 0 and 'metric' in stats_results_task.columns:\n",
        "    # Merge correlation and statistical test results\n",
        "    importance_task = stats_results_task.merge(\n",
        "        corr_task_instances.reset_index().rename(columns={'index': 'metric', 'wonky_task_instances': 'correlation'}),\n",
        "        on='metric',\n",
        "        how='left'\n",
        "    )\n",
        "    \n",
        "    # Calculate importance score\n",
        "    if 'mw_p_value' in importance_task.columns:\n",
        "        importance_task['importance_score'] = (\n",
        "            np.abs(importance_task['correlation']) * \n",
        "            (-np.log10(importance_task['mw_p_value'] + 1e-10))\n",
        "        )\n",
        "        importance_task = importance_task.sort_values('importance_score', ascending=False)\n",
        "        \n",
        "        # Select columns that exist\n",
        "        display_cols = ['metric', 'correlation', 'mean_difference', 'importance_score']\n",
        "        if 'mw_p_value' in importance_task.columns:\n",
        "            display_cols.insert(2, 'mw_p_value')\n",
        "        if 'mw_significant' in importance_task.columns:\n",
        "            display_cols.insert(3, 'mw_significant')\n",
        "        \n",
        "        print(\"\\nTop 20 Most Important Features:\")\n",
        "        display(importance_task[[col for col in display_cols if col in importance_task.columns]].head(20))\n",
        "    else:\n",
        "        print(\"Warning: mw_p_value column not found in stats_results_task\")\n",
        "else:\n",
        "    print(\"Warning: stats_results_task is empty or missing required columns\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\" * 80)\n",
        "print(\"EXECUTIVE SUMMARY\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "print(\"\\n1. TARGET VARIABLE STATISTICS:\")\n",
        "print(f\"   - Respondents with wonky studies: {df['has_wonky_study'].sum():,} ({df['has_wonky_study'].mean()*100:.2f}%)\")\n",
        "print(f\"   - Respondents with wonky tasks: {df['has_wonky_task'].sum():,} ({df['has_wonky_task'].mean()*100:.2f}%)\")\n",
        "print(f\"   - Mean wonky_study_count: {df['wonky_study_count'].mean():.3f}\")\n",
        "print(f\"   - Mean wonky_task_instances: {df['wonky_task_instances'].mean():.3f}\")\n",
        "\n",
        "print(\"\\n2. STATISTICAL SIGNIFICANCE:\")\n",
        "print(f\"   - Significant features for wonky_study: {stats_results_study['mw_significant'].sum()}/{len(stats_results_study)}\")\n",
        "print(f\"   - Significant features for wonky_task: {stats_results_task['mw_significant'].sum()}/{len(stats_results_task)}\")\n",
        "\n",
        "print(\"\\n3. TOP CORRELATED FEATURES (wonky_study_count):\")\n",
        "top_corr_study = corr_study_count.head(6)[1:]\n",
        "for idx, (feature, corr) in enumerate(top_corr_study.items(), 1):\n",
        "    print(f\"   {idx}. {feature}: {corr:.3f}\")\n",
        "\n",
        "print(\"\\n4. TOP CORRELATED FEATURES (wonky_task_instances):\")\n",
        "top_corr_task = corr_task_instances.head(6)[1:]\n",
        "for idx, (feature, corr) in enumerate(top_corr_task.items(), 1):\n",
        "    print(f\"   {idx}. {feature}: {corr:.3f}\")\n",
        "\n",
        "print(\"\\n5. TOP STATISTICALLY SIGNIFICANT FEATURES (wonky_study_count):\")\n",
        "top_sig_study = stats_results_study[stats_results_study['mw_significant']].head(5)\n",
        "for idx, row in enumerate(top_sig_study.itertuples(), 1):\n",
        "    print(f\"   {idx}. {row.metric}: p={row.mw_p_value:.4f}, mean_diff={row.mean_difference:.3f}\")\n",
        "\n",
        "print(\"\\n6. TOP STATISTICALLY SIGNIFICANT FEATURES (wonky_task_instances):\")\n",
        "top_sig_task = stats_results_task[stats_results_task['mw_significant']].head(5)\n",
        "for idx, row in enumerate(top_sig_task.itertuples(), 1):\n",
        "    print(f\"   {idx}. {row.metric}: p={row.mw_p_value:.4f}, mean_diff={row.mean_difference:.3f}\")\n",
        "\n",
        "if len(chi2_results_study) > 0 and 'significant' in chi2_results_study.columns:\n",
        "    print(\"\\n7. SIGNIFICANT CATEGORICAL FEATURES (wonky_study_count):\")\n",
        "    sig_cat_study = chi2_results_study[chi2_results_study['significant']].head(5)\n",
        "    for idx, row in enumerate(sig_cat_study.itertuples(), 1):\n",
        "        print(f\"   {idx}. {row.feature}: p={row.chi_p_value:.4f}\")\n",
        "\n",
        "if len(chi2_results_task) > 0 and 'significant' in chi2_results_task.columns:\n",
        "    print(\"\\n8. SIGNIFICANT CATEGORICAL FEATURES (wonky_task_instances):\")\n",
        "    sig_cat_task = chi2_results_task[chi2_results_task['significant']].head(5)\n",
        "    for idx, row in enumerate(sig_cat_task.itertuples(), 1):\n",
        "        print(f\"   {idx}. {row.feature}: p={row.chi_p_value:.4f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)"
      ]
    }
  ],
  "metadata": {
    "application/vnd.databricks.v1+notebook": {
      "notebookMetadata": {
        "name": "wonky_features_eda"
      }
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
